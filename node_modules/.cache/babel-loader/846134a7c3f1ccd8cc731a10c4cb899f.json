{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Max } from '@tensorflow/tfjs-core';\nimport { backend_util, util } from '@tensorflow/tfjs-core';\nimport { maxImplCPU } from '../kernel_utils/shared';\nimport { maxImpl } from './Max_impl';\nimport { transposeImpl, transposeImplCPU } from './Transpose_impl';\nexport function max(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    reductionIndices,\n    keepDims\n  } = attrs;\n  const xRank = x.shape.length;\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const maxInputIsTransposed = permutedAxes != null;\n  const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n  let maxInput = x;\n\n  if (maxInputIsTransposed) {\n    if (shouldExecuteOnCPU) {\n      const xTexData = backend.texData.get(maxInput.dataId);\n      const values = xTexData.values;\n      const newShape = new Array(xRank);\n\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = x.shape[permutedAxes[i]];\n      }\n\n      const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n      maxInput = backend.makeTensorInfo(newShape, x.dtype);\n      const maxInputData = backend.texData.get(maxInput.dataId);\n      maxInputData.values = maxInputValues;\n    } else {\n      maxInput = transposeImpl(x, permutedAxes, backend);\n    }\n\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n  let outShape = maxOutShape;\n\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n  }\n\n  let out;\n\n  if (shouldExecuteOnCPU) {\n    const xTexData = backend.texData.get(maxInput.dataId);\n    const values = xTexData.values;\n    const outValues = maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n    out = backend.makeTensorInfo(outShape, x.dtype);\n    const outData = backend.texData.get(out.dataId);\n    outData.values = outValues;\n  } else {\n    out = maxImpl(maxInput, reduceShape, outShape, backend);\n  }\n\n  if (maxInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(maxInput);\n  }\n\n  return out;\n}\nexport const maxConfig = {\n  kernelName: Max,\n  backendName: 'webgl',\n  kernelFunc: max\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-webgl/src/kernels/Max.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAoB,GAApB,QAA+D,uBAA/D;AACA,SAAQ,YAAR,EAAgD,IAAhD,QAA2D,uBAA3D;AAGA,SAAQ,UAAR,QAAyB,wBAAzB;AAEA,SAAQ,OAAR,QAAsB,YAAtB;AACA,SAAQ,aAAR,EAAuB,gBAAvB,QAA8C,kBAA9C;AAEA,OAAM,SAAU,GAAV,CACF,IADE,EACmE;EAEvE,MAAM;IAAC,MAAD;IAAS,OAAT;IAAkB;EAAlB,IAA2B,IAAjC;EACA,MAAM;IAAC;EAAD,IAAM,MAAZ;EACA,MAAM;IAAC,gBAAD;IAAmB;EAAnB,IAA+B,KAArC;EAEA,MAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;EAEA,MAAM,QAAQ,GAAG,IAAI,CAAC,cAAL,CAAoB,gBAApB,EAAsC,CAAC,CAAC,KAAxC,CAAjB;EACA,IAAI,IAAI,GAAG,QAAX;EACA,MAAM,YAAY,GAAG,YAAY,CAAC,kBAAb,CAAgC,IAAhC,EAAsC,KAAtC,CAArB;EACA,MAAM,oBAAoB,GAAG,YAAY,IAAI,IAA7C;EACA,MAAM,kBAAkB,GAAG,OAAO,CAAC,kBAAR,CAA2B,CAAC,CAAD,CAA3B,CAA3B;EAEA,IAAI,QAAQ,GAAG,CAAf;;EACA,IAAI,oBAAJ,EAA0B;IACxB,IAAI,kBAAJ,EAAwB;MACtB,MAAM,QAAQ,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,QAAQ,CAAC,MAA7B,CAAjB;MACA,MAAM,MAAM,GAAG,QAAQ,CAAC,MAAxB;MAEA,MAAM,QAAQ,GAAa,IAAI,KAAJ,CAAU,KAAV,CAA3B;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,QAAQ,CAAC,MAA7B,EAAqC,CAAC,EAAtC,EAA0C;QACxC,QAAQ,CAAC,CAAD,CAAR,GAAc,CAAC,CAAC,KAAF,CAAQ,YAAY,CAAC,CAAD,CAApB,CAAd;MACD;;MACD,MAAM,cAAc,GAChB,gBAAgB,CAAC,MAAD,EAAS,CAAC,CAAC,KAAX,EAAkB,CAAC,CAAC,KAApB,EAA2B,YAA3B,EAAyC,QAAzC,CADpB;MAGA,QAAQ,GAAG,OAAO,CAAC,cAAR,CAAuB,QAAvB,EAAiC,CAAC,CAAC,KAAnC,CAAX;MACA,MAAM,YAAY,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,QAAQ,CAAC,MAA7B,CAArB;MACA,YAAY,CAAC,MAAb,GAAsB,cAAtB;IACD,CAdD,MAcO;MACL,QAAQ,GAAG,aAAa,CAAC,CAAD,EAAI,YAAJ,EAAkB,OAAlB,CAAxB;IACD;;IAED,IAAI,GAAG,YAAY,CAAC,gBAAb,CAA8B,IAAI,CAAC,MAAnC,EAA2C,KAA3C,CAAP;EACD;;EAED,YAAY,CAAC,0BAAb,CAAwC,KAAxC,EAA+C,IAA/C,EAAqD,KAArD;EACA,MAAM,CAAC,WAAD,EAAc,WAAd,IACF,YAAY,CAAC,yBAAb,CAAuC,QAAQ,CAAC,KAAhD,EAAuD,IAAvD,CADJ;EAGA,IAAI,QAAQ,GAAG,WAAf;;EACA,IAAI,QAAJ,EAAc;IACZ;IACA,QAAQ,GAAG,YAAY,CAAC,oBAAb,CAAkC,WAAlC,EAA+C,QAA/C,CAAX;EACD;;EAED,IAAI,GAAJ;;EACA,IAAI,kBAAJ,EAAwB;IACtB,MAAM,QAAQ,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,QAAQ,CAAC,MAA7B,CAAjB;IACA,MAAM,MAAM,GAAG,QAAQ,CAAC,MAAxB;IAEA,MAAM,SAAS,GACX,UAAU,CAAC,MAAD,EAAS,IAAI,CAAC,aAAL,CAAmB,WAAnB,CAAT,EAA0C,QAA1C,EAAoD,CAAC,CAAC,KAAtD,CADd;IAGA,GAAG,GAAG,OAAO,CAAC,cAAR,CAAuB,QAAvB,EAAiC,CAAC,CAAC,KAAnC,CAAN;IACA,MAAM,OAAO,GAAG,OAAO,CAAC,OAAR,CAAgB,GAAhB,CAAoB,GAAG,CAAC,MAAxB,CAAhB;IACA,OAAO,CAAC,MAAR,GAAiB,SAAjB;EACD,CAVD,MAUO;IACL,GAAG,GAAG,OAAO,CAAC,QAAD,EAAW,WAAX,EAAwB,QAAxB,EAAkC,OAAlC,CAAb;EACD;;EAED,IAAI,oBAAJ,EAA0B;IACxB,OAAO,CAAC,6BAAR,CAAsC,QAAtC;EACD;;EAED,OAAO,GAAP;AACD;AAED,OAAO,MAAM,SAAS,GAAiB;EACrC,UAAU,EAAE,GADyB;EAErC,WAAW,EAAE,OAFwB;EAGrC,UAAU,EAAE;AAHyB,CAAhC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {maxImplCPU} from '../kernel_utils/shared';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl, transposeImplCPU} from './Transpose_impl';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: MathBackendWebGL, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n\n  const xRank = x.shape.length;\n\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const maxInputIsTransposed = permutedAxes != null;\n  const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n\n  let maxInput = x;\n  if (maxInputIsTransposed) {\n    if (shouldExecuteOnCPU) {\n      const xTexData = backend.texData.get(maxInput.dataId);\n      const values = xTexData.values as TypedArray;\n\n      const newShape: number[] = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = x.shape[permutedAxes[i]];\n      }\n      const maxInputValues =\n          transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n\n      maxInput = backend.makeTensorInfo(newShape, x.dtype);\n      const maxInputData = backend.texData.get(maxInput.dataId);\n      maxInputData.values = maxInputValues;\n    } else {\n      maxInput = transposeImpl(x, permutedAxes, backend);\n    }\n\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n  }\n\n  let out;\n  if (shouldExecuteOnCPU) {\n    const xTexData = backend.texData.get(maxInput.dataId);\n    const values = xTexData.values as TypedArray;\n\n    const outValues =\n        maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n\n    out = backend.makeTensorInfo(outShape, x.dtype);\n    const outData = backend.texData.get(out.dataId);\n    outData.values = outValues;\n  } else {\n    out = maxImpl(maxInput, reduceShape, outShape, backend);\n  }\n\n  if (maxInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(maxInput);\n  }\n\n  return out;\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'webgl',\n  kernelFunc: max as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}