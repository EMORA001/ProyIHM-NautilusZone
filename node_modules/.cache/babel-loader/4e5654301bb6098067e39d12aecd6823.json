{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Cumsum, upcastType, util } from '@tensorflow/tfjs-core';\nimport { assertNotComplex } from '../cpu_util';\nimport { transpose } from './Transpose';\nexport function cumsum(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x\n  } = inputs;\n  const {\n    axis,\n    exclusive,\n    reverse\n  } = attrs;\n  assertNotComplex(x, 'cumsum');\n  const permutation = backend_util.getAxesPermutation([axis], x.shape.length);\n  let $x = x;\n\n  if (permutation != null) {\n    $x = transpose({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        perm: permutation\n      }\n    });\n  }\n\n  const permutedAxis = backend_util.getInnerMostAxes(1, x.shape.length)[0];\n\n  if (permutedAxis !== $x.shape.length - 1) {\n    throw new Error(`backend.cumsum in CPU expects an inner-most ` + `axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);\n  }\n\n  const resultDtype = upcastType($x.dtype, 'int32');\n  const vals = util.makeZerosTypedArray(util.sizeFromShape($x.shape), resultDtype);\n  const aVals = backend.data.get($x.dataId).values;\n  const finalDim = $x.shape[$x.shape.length - 1];\n  const indexAdjuster = reverse ? (i, j) => i + finalDim - j - 1 : (i, j) => i + j;\n\n  for (let i = 0; i < aVals.length; i += finalDim) {\n    for (let j = 0; j < finalDim; j++) {\n      const idx = indexAdjuster(i, j);\n\n      if (j === 0) {\n        vals[idx] = exclusive ? 0 : aVals[idx];\n      } else {\n        const prevIdx = indexAdjuster(i, j - 1);\n        vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] : aVals[idx] + vals[prevIdx];\n      }\n    }\n  }\n\n  const result = backend.makeTensorInfo($x.shape, resultDtype, vals);\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose({\n      inputs: {\n        x: result\n      },\n      backend,\n      attrs: {\n        perm: reversePermutation\n      }\n    });\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo($x);\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\nexport const cumsumConfig = {\n  kernelName: Cumsum,\n  backendName: 'cpu',\n  kernelFunc: cumsum\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-cpu/src/kernels/Cumsum.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAR,EAAsB,MAAtB,EAA2G,UAA3G,EAAuH,IAAvH,QAAkI,uBAAlI;AAGA,SAAQ,gBAAR,QAA+B,aAA/B;AACA,SAAQ,SAAR,QAAwB,aAAxB;AAEA,OAAM,SAAU,MAAV,CACF,IADE,EACuE;EAE3E,MAAM;IAAC,MAAD;IAAS,OAAT;IAAkB;EAAlB,IAA2B,IAAjC;EACA,MAAM;IAAC;EAAD,IAAM,MAAZ;EACA,MAAM;IAAC,IAAD;IAAO,SAAP;IAAkB;EAAlB,IAA6B,KAAnC;EAEA,gBAAgB,CAAC,CAAD,EAAI,QAAJ,CAAhB;EAEA,MAAM,WAAW,GAAG,YAAY,CAAC,kBAAb,CAAgC,CAAC,IAAD,CAAhC,EAAwC,CAAC,CAAC,KAAF,CAAQ,MAAhD,CAApB;EACA,IAAI,EAAE,GAAG,CAAT;;EACA,IAAI,WAAW,IAAI,IAAnB,EAAyB;IACvB,EAAE,GAAG,SAAS,CAAC;MAAC,MAAM,EAAE;QAAC;MAAD,CAAT;MAAc,OAAd;MAAuB,KAAK,EAAE;QAAC,IAAI,EAAE;MAAP;IAA9B,CAAD,CAAd;EACD;;EACD,MAAM,YAAY,GAAG,YAAY,CAAC,gBAAb,CAA8B,CAA9B,EAAiC,CAAC,CAAC,KAAF,CAAQ,MAAzC,EAAiD,CAAjD,CAArB;;EAEA,IAAI,YAAY,KAAK,EAAE,CAAC,KAAH,CAAS,MAAT,GAAkB,CAAvC,EAA0C;IACxC,MAAM,IAAI,KAAJ,CACF,8CAAA,GACA,QAAQ,EAAE,CAAC,KAAH,CAAS,MAAT,GAAkB,CAAC,iBAAiB,YAAY,EAFtD,CAAN;EAGD;;EAED,MAAM,WAAW,GAAG,UAAU,CAAC,EAAE,CAAC,KAAJ,EAAW,OAAX,CAA9B;EACA,MAAM,IAAI,GAAG,IAAI,CAAC,mBAAL,CACI,IAAI,CAAC,aAAL,CAAmB,EAAE,CAAC,KAAtB,CADJ,EACkC,WADlC,CAAb;EAGA,MAAM,KAAK,GAAG,OAAO,CAAC,IAAR,CAAa,GAAb,CAAiB,EAAE,CAAC,MAApB,EAA4B,MAA1C;EACA,MAAM,QAAQ,GAAG,EAAE,CAAC,KAAH,CAAS,EAAE,CAAC,KAAH,CAAS,MAAT,GAAkB,CAA3B,CAAjB;EACA,MAAM,aAAa,GAAG,OAAO,GACzB,CAAC,CAAD,EAAY,CAAZ,KAA0B,CAAC,GAAG,QAAJ,GAAe,CAAf,GAAmB,CADpB,GAEzB,CAAC,CAAD,EAAY,CAAZ,KAA0B,CAAC,GAAG,CAFlC;;EAGA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,CAAC,MAA1B,EAAkC,CAAC,IAAI,QAAvC,EAAiD;IAC/C,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,QAApB,EAA8B,CAAC,EAA/B,EAAmC;MACjC,MAAM,GAAG,GAAG,aAAa,CAAC,CAAD,EAAI,CAAJ,CAAzB;;MACA,IAAI,CAAC,KAAK,CAAV,EAAa;QACX,IAAI,CAAC,GAAD,CAAJ,GAAY,SAAS,GAAG,CAAH,GAAO,KAAK,CAAC,GAAD,CAAjC;MACD,CAFD,MAEO;QACL,MAAM,OAAO,GAAG,aAAa,CAAC,CAAD,EAAI,CAAC,GAAG,CAAR,CAA7B;QACA,IAAI,CAAC,GAAD,CAAJ,GAAY,SAAS,GAAG,KAAK,CAAC,OAAD,CAAL,GAAiB,IAAI,CAAC,OAAD,CAAxB,GACG,KAAK,CAAC,GAAD,CAAL,GAAa,IAAI,CAAC,OAAD,CADzC;MAED;IACF;EACF;;EAED,MAAM,MAAM,GAAG,OAAO,CAAC,cAAR,CAAuB,EAAE,CAAC,KAA1B,EAAiC,WAAjC,EAA8C,IAA9C,CAAf;;EAEA,IAAI,WAAW,IAAI,IAAnB,EAAyB;IACvB,MAAM,kBAAkB,GAAG,YAAY,CAAC,sBAAb,CAAoC,WAApC,CAA3B;IACA,MAAM,uBAAuB,GAAG,SAAS,CACrC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE;MAAJ,CAAT;MAAsB,OAAtB;MAA+B,KAAK,EAAE;QAAC,IAAI,EAAE;MAAP;IAAtC,CADqC,CAAzC;IAGA,OAAO,CAAC,6BAAR,CAAsC,MAAtC;IACA,OAAO,CAAC,6BAAR,CAAsC,EAAtC;IAEA,OAAO,uBAAP;EACD;;EAED,OAAO,MAAP;AACD;AAED,OAAO,MAAM,YAAY,GAAiB;EACxC,UAAU,EAAE,MAD4B;EAExC,WAAW,EAAE,KAF2B;EAGxC,UAAU,EAAE;AAH4B,CAAnC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Cumsum, CumsumAttrs, CumsumInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function cumsum(\n    args: {inputs: CumsumInputs, backend: MathBackendCPU, attrs: CumsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n\n  assertNotComplex(x, 'cumsum');\n\n  const permutation = backend_util.getAxesPermutation([axis], x.shape.length);\n  let $x = x;\n  if (permutation != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, x.shape.length)[0];\n\n  if (permutedAxis !== $x.shape.length - 1) {\n    throw new Error(\n        `backend.cumsum in CPU expects an inner-most ` +\n        `axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);\n  }\n\n  const resultDtype = upcastType($x.dtype, 'int32');\n  const vals = util.makeZerosTypedArray(\n                   util.sizeFromShape($x.shape), resultDtype) as TypedArray;\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  const finalDim = $x.shape[$x.shape.length - 1];\n  const indexAdjuster = reverse ?\n      (i: number, j: number) => i + finalDim - j - 1 :\n      (i: number, j: number) => i + j;\n  for (let i = 0; i < aVals.length; i += finalDim) {\n    for (let j = 0; j < finalDim; j++) {\n      const idx = indexAdjuster(i, j);\n      if (j === 0) {\n        vals[idx] = exclusive ? 0 : aVals[idx];\n      } else {\n        const prevIdx = indexAdjuster(i, j - 1);\n        vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                                aVals[idx] + vals[prevIdx];\n      }\n    }\n  }\n\n  const result = backend.makeTensorInfo($x.shape, resultDtype, vals);\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo($x);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'cpu',\n  kernelFunc: cumsum as {} as KernelFunc\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}