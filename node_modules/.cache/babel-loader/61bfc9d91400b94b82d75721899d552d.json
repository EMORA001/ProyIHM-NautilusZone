{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { eye, linalg, mul, ones, randomUniform, scalar, serialization, tidy, transpose, truncatedNormal, zeros } from '@tensorflow/tfjs-core';\nimport * as K from './backend/tfjs_backend';\nimport { checkDataFormat } from './common';\nimport { NotImplementedError, ValueError } from './errors';\nimport { VALID_DISTRIBUTION_VALUES, VALID_FAN_MODE_VALUES } from './keras_format/initializer_config';\nimport { checkStringTypeUnionValue, deserializeKerasObject, serializeKerasObject } from './utils/generic_utils';\nimport { arrayProd } from './utils/math_utils';\nexport function checkFanMode(value) {\n  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\nexport function checkDistribution(value) {\n  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\n\nexport class Initializer extends serialization.Serializable {\n  fromConfigUsesCustomObjects() {\n    return false;\n  }\n\n  getConfig() {\n    return {};\n  }\n\n}\nexport class Zeros extends Initializer {\n  apply(shape, dtype) {\n    return zeros(shape, dtype);\n  }\n\n}\n/** @nocollapse */\n\nZeros.className = 'Zeros';\nserialization.registerClass(Zeros);\nexport class Ones extends Initializer {\n  apply(shape, dtype) {\n    return ones(shape, dtype);\n  }\n\n}\n/** @nocollapse */\n\nOnes.className = 'Ones';\nserialization.registerClass(Ones);\nexport class Constant extends Initializer {\n  constructor(args) {\n    super();\n\n    if (typeof args !== 'object') {\n      throw new ValueError(`Expected argument of type ConstantConfig but got ${args}`);\n    }\n\n    if (args.value === undefined) {\n      throw new ValueError(`config must have value set but got ${args}`);\n    }\n\n    this.value = args.value;\n  }\n\n  apply(shape, dtype) {\n    return tidy(() => mul(scalar(this.value), ones(shape, dtype)));\n  }\n\n  getConfig() {\n    return {\n      value: this.value\n    };\n  }\n\n}\n/** @nocollapse */\n\nConstant.className = 'Constant';\nserialization.registerClass(Constant);\nexport class RandomUniform extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_MINVAL = -0.05;\n    this.DEFAULT_MAXVAL = 0.05;\n    this.minval = args.minval || this.DEFAULT_MINVAL;\n    this.maxval = args.maxval || this.DEFAULT_MAXVAL;\n    this.seed = args.seed;\n  }\n\n  apply(shape, dtype) {\n    return randomUniform(shape, this.minval, this.maxval, dtype);\n  }\n\n  getConfig() {\n    return {\n      minval: this.minval,\n      maxval: this.maxval,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nRandomUniform.className = 'RandomUniform';\nserialization.registerClass(RandomUniform);\nexport class RandomNormal extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_MEAN = 0.;\n    this.DEFAULT_STDDEV = 0.05;\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape, dtype) {\n    dtype = dtype || 'float32';\n\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(`randomNormal does not support dType ${dtype}.`);\n    }\n\n    return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nRandomNormal.className = 'RandomNormal';\nserialization.registerClass(RandomNormal);\nexport class TruncatedNormal extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_MEAN = 0.;\n    this.DEFAULT_STDDEV = 0.05;\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape, dtype) {\n    dtype = dtype || 'float32';\n\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(`truncatedNormal does not support dType ${dtype}.`);\n    }\n\n    return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig() {\n    return {\n      mean: this.mean,\n      stddev: this.stddev,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nTruncatedNormal.className = 'TruncatedNormal';\nserialization.registerClass(TruncatedNormal);\nexport class Identity extends Initializer {\n  constructor(args) {\n    super();\n    this.gain = args.gain != null ? args.gain : 1.0;\n  }\n\n  apply(shape, dtype) {\n    return tidy(() => {\n      if (shape.length !== 2 || shape[0] !== shape[1]) {\n        throw new ValueError('Identity matrix initializer can only be used for' + ' 2D square matrices.');\n      } else {\n        return mul(this.gain, eye(shape[0]));\n      }\n    });\n  }\n\n  getConfig() {\n    return {\n      gain: this.gain\n    };\n  }\n\n}\n/** @nocollapse */\n\nIdentity.className = 'Identity';\nserialization.registerClass(Identity);\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\n\nfunction computeFans(shape) {\n  let dataFormat = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'channelsLast';\n  let fanIn;\n  let fanOut;\n  checkDataFormat(dataFormat);\n\n  if (shape.length === 2) {\n    fanIn = shape[0];\n    fanOut = shape[1];\n  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n    if (dataFormat === 'channelsFirst') {\n      const receptiveFieldSize = arrayProd(shape, 2);\n      fanIn = shape[1] * receptiveFieldSize;\n      fanOut = shape[0] * receptiveFieldSize;\n    } else if (dataFormat === 'channelsLast') {\n      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);\n      fanIn = shape[shape.length - 2] * receptiveFieldSize;\n      fanOut = shape[shape.length - 1] * receptiveFieldSize;\n    }\n  } else {\n    const shapeProd = arrayProd(shape);\n    fanIn = Math.sqrt(shapeProd);\n    fanOut = Math.sqrt(shapeProd);\n  }\n\n  return [fanIn, fanOut];\n}\n\nexport class VarianceScaling extends Initializer {\n  /**\n   * Constructor of VarianceScaling.\n   * @throws ValueError for invalid value in scale.\n   */\n  constructor(args) {\n    super();\n\n    if (args.scale < 0.0) {\n      throw new ValueError(`scale must be a positive float. Got: ${args.scale}`);\n    }\n\n    this.scale = args.scale == null ? 1.0 : args.scale;\n    this.mode = args.mode == null ? 'fanIn' : args.mode;\n    checkFanMode(this.mode);\n    this.distribution = args.distribution == null ? 'normal' : args.distribution;\n    checkDistribution(this.distribution);\n    this.seed = args.seed;\n  }\n\n  apply(shape, dtype) {\n    const fans = computeFans(shape);\n    const fanIn = fans[0];\n    const fanOut = fans[1];\n    let scale = this.scale;\n\n    if (this.mode === 'fanIn') {\n      scale /= Math.max(1, fanIn);\n    } else if (this.mode === 'fanOut') {\n      scale /= Math.max(1, fanOut);\n    } else {\n      scale /= Math.max(1, (fanIn + fanOut) / 2);\n    }\n\n    if (this.distribution === 'normal') {\n      const stddev = Math.sqrt(scale);\n      dtype = dtype || 'float32';\n\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(`${this.getClassName()} does not support dType ${dtype}.`);\n      }\n\n      return truncatedNormal(shape, 0, stddev, dtype, this.seed);\n    } else {\n      const limit = Math.sqrt(3 * scale);\n      return randomUniform(shape, -limit, limit, dtype);\n    }\n  }\n\n  getConfig() {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nVarianceScaling.className = 'VarianceScaling';\nserialization.registerClass(VarianceScaling);\nexport class GlorotUniform extends VarianceScaling {\n  /**\n   * Constructor of GlorotUniform\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, GlorotUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nGlorotUniform.className = 'GlorotUniform';\nserialization.registerClass(GlorotUniform);\nexport class GlorotNormal extends VarianceScaling {\n  /**\n   * Constructor of GlorotNormal.\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, GlorotNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nGlorotNormal.className = 'GlorotNormal';\nserialization.registerClass(GlorotNormal);\nexport class HeNormal extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, HeNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nHeNormal.className = 'HeNormal';\nserialization.registerClass(HeNormal);\nexport class HeUniform extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, HeUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nHeUniform.className = 'HeUniform';\nserialization.registerClass(HeUniform);\nexport class LeCunNormal extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, LeCunNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nLeCunNormal.className = 'LeCunNormal';\nserialization.registerClass(LeCunNormal);\nexport class LeCunUniform extends VarianceScaling {\n  constructor(args) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName() {\n    // In Python Keras, LeCunUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n\n}\n/** @nocollapse */\n\nLeCunUniform.className = 'LeCunNormal';\nserialization.registerClass(LeCunUniform);\nexport class Orthogonal extends Initializer {\n  constructor(args) {\n    super();\n    this.DEFAULT_GAIN = 1;\n    this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;\n    this.seed = args.seed;\n\n    if (this.seed != null) {\n      throw new NotImplementedError('Random seed is not implemented for Orthogonal Initializer yet.');\n    }\n  }\n\n  apply(shape, dtype) {\n    return tidy(() => {\n      if (shape.length < 2) {\n        throw new NotImplementedError('Shape must be at least 2D.');\n      }\n\n      if (shape[0] * shape[1] > 2000) {\n        console.warn(`Orthogonal initializer is being called on a matrix with more ` + `than 2000 (${shape[0] * shape[1]}) elements: ` + `Slowness may result.`);\n      } // TODO(cais): Add seed support.\n\n\n      const normalizedShape = shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n      const a = K.randomNormal(normalizedShape, 0, 1, 'float32');\n      let q = linalg.gramSchmidt(a);\n\n      if (shape[0] > shape[1]) {\n        q = transpose(q);\n      }\n\n      return mul(this.gain, q);\n    });\n  }\n\n  getConfig() {\n    return {\n      gain: this.gain,\n      seed: this.seed\n    };\n  }\n\n}\n/** @nocollapse */\n\nOrthogonal.className = 'Orthogonal';\nserialization.registerClass(Orthogonal); // Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\n\nexport const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {\n  'constant': 'Constant',\n  'glorotNormal': 'GlorotNormal',\n  'glorotUniform': 'GlorotUniform',\n  'heNormal': 'HeNormal',\n  'heUniform': 'HeUniform',\n  'identity': 'Identity',\n  'leCunNormal': 'LeCunNormal',\n  'leCunUniform': 'LeCunUniform',\n  'ones': 'Ones',\n  'orthogonal': 'Orthogonal',\n  'randomNormal': 'RandomNormal',\n  'randomUniform': 'RandomUniform',\n  'truncatedNormal': 'TruncatedNormal',\n  'varianceScaling': 'VarianceScaling',\n  'zeros': 'Zeros'\n};\n\nfunction deserializeInitializer(config) {\n  let customObjects = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  return deserializeKerasObject(config, serialization.SerializationMap.getMap().classNameMap, customObjects, 'initializer');\n}\n\nexport function serializeInitializer(initializer) {\n  return serializeKerasObject(initializer);\n}\nexport function getInitializer(identifier) {\n  if (typeof identifier === 'string') {\n    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;\n    /* We have four 'helper' classes for common initializers that\n    all get serialized as 'VarianceScaling' and shouldn't go through\n    the deserializeInitializer pathway. */\n\n    if (className === 'GlorotNormal') {\n      return new GlorotNormal();\n    } else if (className === 'GlorotUniform') {\n      return new GlorotUniform();\n    } else if (className === 'HeNormal') {\n      return new HeNormal();\n    } else if (className === 'HeUniform') {\n      return new HeUniform();\n    } else if (className === 'LeCunNormal') {\n      return new LeCunNormal();\n    } else if (className === 'LeCunUniform') {\n      return new LeCunUniform();\n    } else {\n      const config = {};\n      config['className'] = className;\n      config['config'] = {};\n      return deserializeInitializer(config);\n    }\n  } else if (identifier instanceof Initializer) {\n    return identifier;\n  } else {\n    return deserializeInitializer(identifier);\n  }\n}","map":{"version":3,"sources":["../../../../../tfjs-layers/src/initializers.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;AAEH,SAAkB,GAAlB,EAAuB,MAAvB,EAA+B,GAA/B,EAAoC,IAApC,EAA0C,aAA1C,EAAyD,MAAzD,EAAiE,aAAjE,EAAkG,IAAlG,EAAwG,SAAxG,EAAmH,eAAnH,EAAoI,KAApI,QAAgJ,uBAAhJ;AAEA,OAAO,KAAK,CAAZ,MAAmB,wBAAnB;AACA,SAAQ,eAAR,QAA8B,UAA9B;AACA,SAAQ,mBAAR,EAA6B,UAA7B,QAA8C,UAA9C;AAEA,SAA+B,yBAA/B,EAA0D,qBAA1D,QAAsF,mCAAtF;AACA,SAAQ,yBAAR,EAAmC,sBAAnC,EAA2D,oBAA3D,QAAsF,uBAAtF;AACA,SAAQ,SAAR,QAAwB,oBAAxB;AAEA,OAAM,SAAU,YAAV,CAAuB,KAAvB,EAAqC;EACzC,yBAAyB,CAAC,qBAAD,EAAwB,SAAxB,EAAmC,KAAnC,CAAzB;AACD;AAED,OAAM,SAAU,iBAAV,CAA4B,KAA5B,EAA0C;EAC9C,yBAAyB,CAAC,yBAAD,EAA4B,cAA5B,EAA4C,KAA5C,CAAzB;AACD;AAED;;;;;AAKG;;AACH,OAAM,MAAgB,WAAhB,SAAoC,aAAa,CAAC,YAAlD,CAA8D;EAC3D,2BAA2B,GAAA;IAChC,OAAO,KAAP;EACD;;EASD,SAAS,GAAA;IACP,OAAO,EAAP;EACD;;AAdiE;AAiBpE,OAAM,MAAO,KAAP,SAAqB,WAArB,CAAgC;EAIpC,KAAK,CAAC,KAAD,EAAe,KAAf,EAA+B;IAClC,OAAO,KAAK,CAAC,KAAD,EAAQ,KAAR,CAAZ;EACD;;AANmC;AACpC;;AACO,KAAA,CAAA,SAAA,GAAY,OAAZ;AAMT,aAAa,CAAC,aAAd,CAA4B,KAA5B;AAEA,OAAM,MAAO,IAAP,SAAoB,WAApB,CAA+B;EAInC,KAAK,CAAC,KAAD,EAAe,KAAf,EAA+B;IAClC,OAAO,IAAI,CAAC,KAAD,EAAQ,KAAR,CAAX;EACD;;AANkC;AACnC;;AACO,IAAA,CAAA,SAAA,GAAY,MAAZ;AAMT,aAAa,CAAC,aAAd,CAA4B,IAA5B;AAOA,OAAM,MAAO,QAAP,SAAwB,WAAxB,CAAmC;EAIvC,WAAA,CAAY,IAAZ,EAA8B;IAC5B;;IACA,IAAI,OAAO,IAAP,KAAgB,QAApB,EAA8B;MAC5B,MAAM,IAAI,UAAJ,CACF,oDAAoD,IAAI,EADtD,CAAN;IAED;;IACD,IAAI,IAAI,CAAC,KAAL,KAAe,SAAnB,EAA8B;MAC5B,MAAM,IAAI,UAAJ,CAAe,sCAAsC,IAAI,EAAzD,CAAN;IACD;;IACD,KAAK,KAAL,GAAa,IAAI,CAAC,KAAlB;EACD;;EAED,KAAK,CAAC,KAAD,EAAe,KAAf,EAA+B;IAClC,OAAO,IAAI,CAAC,MAAM,GAAG,CAAC,MAAM,CAAC,KAAK,KAAN,CAAP,EAAqB,IAAI,CAAC,KAAD,EAAQ,KAAR,CAAzB,CAAV,CAAX;EACD;;EAED,SAAS,GAAA;IACP,OAAO;MACL,KAAK,EAAE,KAAK;IADP,CAAP;EAGD;;AAxBsC;AACvC;;AACO,QAAA,CAAA,SAAA,GAAY,UAAZ;AAwBT,aAAa,CAAC,aAAd,CAA4B,QAA5B;AAWA,OAAM,MAAO,aAAP,SAA6B,WAA7B,CAAwC;EAS5C,WAAA,CAAY,IAAZ,EAAmC;IACjC;IAPO,KAAA,cAAA,GAAiB,CAAC,IAAlB;IACA,KAAA,cAAA,GAAiB,IAAjB;IAOP,KAAK,MAAL,GAAc,IAAI,CAAC,MAAL,IAAe,KAAK,cAAlC;IACA,KAAK,MAAL,GAAc,IAAI,CAAC,MAAL,IAAe,KAAK,cAAlC;IACA,KAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;EACD;;EAED,KAAK,CAAC,KAAD,EAAe,KAAf,EAA+B;IAClC,OAAO,aAAa,CAAC,KAAD,EAAQ,KAAK,MAAb,EAAqB,KAAK,MAA1B,EAAkC,KAAlC,CAApB;EACD;;EAED,SAAS,GAAA;IACP,OAAO;MAAC,MAAM,EAAE,KAAK,MAAd;MAAsB,MAAM,EAAE,KAAK,MAAnC;MAA2C,IAAI,EAAE,KAAK;IAAtD,CAAP;EACD;;AAtB2C;AAC5C;;AACO,aAAA,CAAA,SAAA,GAAY,eAAZ;AAsBT,aAAa,CAAC,aAAd,CAA4B,aAA5B;AAWA,OAAM,MAAO,YAAP,SAA4B,WAA5B,CAAuC;EAS3C,WAAA,CAAY,IAAZ,EAAkC;IAChC;IAPO,KAAA,YAAA,GAAe,EAAf;IACA,KAAA,cAAA,GAAiB,IAAjB;IAOP,KAAK,IAAL,GAAY,IAAI,CAAC,IAAL,IAAa,KAAK,YAA9B;IACA,KAAK,MAAL,GAAc,IAAI,CAAC,MAAL,IAAe,KAAK,cAAlC;IACA,KAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;EACD;;EAED,KAAK,CAAC,KAAD,EAAe,KAAf,EAA+B;IAClC,KAAK,GAAG,KAAK,IAAI,SAAjB;;IACA,IAAI,KAAK,KAAK,SAAV,IAAuB,KAAK,KAAK,OAArC,EAA8C;MAC5C,MAAM,IAAI,mBAAJ,CACF,uCAAuC,KAAK,GAD1C,CAAN;IAED;;IAED,OAAO,CAAC,CAAC,YAAF,CAAe,KAAf,EAAsB,KAAK,IAA3B,EAAiC,KAAK,MAAtC,EAA8C,KAA9C,EAAqD,KAAK,IAA1D,CAAP;EACD;;EAED,SAAS,GAAA;IACP,OAAO;MAAC,IAAI,EAAE,KAAK,IAAZ;MAAkB,MAAM,EAAE,KAAK,MAA/B;MAAuC,IAAI,EAAE,KAAK;IAAlD,CAAP;EACD;;AA5B0C;AAC3C;;AACO,YAAA,CAAA,SAAA,GAAY,cAAZ;AA4BT,aAAa,CAAC,aAAd,CAA4B,YAA5B;AAWA,OAAM,MAAO,eAAP,SAA+B,WAA/B,CAA0C;EAU9C,WAAA,CAAY,IAAZ,EAAqC;IACnC;IAPO,KAAA,YAAA,GAAe,EAAf;IACA,KAAA,cAAA,GAAiB,IAAjB;IAOP,KAAK,IAAL,GAAY,IAAI,CAAC,IAAL,IAAa,KAAK,YAA9B;IACA,KAAK,MAAL,GAAc,IAAI,CAAC,MAAL,IAAe,KAAK,cAAlC;IACA,KAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;EACD;;EAED,KAAK,CAAC,KAAD,EAAe,KAAf,EAA+B;IAClC,KAAK,GAAG,KAAK,IAAI,SAAjB;;IACA,IAAI,KAAK,KAAK,SAAV,IAAuB,KAAK,KAAK,OAArC,EAA8C;MAC5C,MAAM,IAAI,mBAAJ,CACF,0CAA0C,KAAK,GAD7C,CAAN;IAED;;IACD,OAAO,eAAe,CAAC,KAAD,EAAQ,KAAK,IAAb,EAAmB,KAAK,MAAxB,EAAgC,KAAhC,EAAuC,KAAK,IAA5C,CAAtB;EACD;;EAED,SAAS,GAAA;IACP,OAAO;MAAC,IAAI,EAAE,KAAK,IAAZ;MAAkB,MAAM,EAAE,KAAK,MAA/B;MAAuC,IAAI,EAAE,KAAK;IAAlD,CAAP;EACD;;AA5B6C;AAC9C;;AACO,eAAA,CAAA,SAAA,GAAY,iBAAZ;AA4BT,aAAa,CAAC,aAAd,CAA4B,eAA5B;AASA,OAAM,MAAO,QAAP,SAAwB,WAAxB,CAAmC;EAIvC,WAAA,CAAY,IAAZ,EAA8B;IAC5B;IACA,KAAK,IAAL,GAAY,IAAI,CAAC,IAAL,IAAa,IAAb,GAAoB,IAAI,CAAC,IAAzB,GAAgC,GAA5C;EACD;;EAED,KAAK,CAAC,KAAD,EAAe,KAAf,EAA+B;IAClC,OAAO,IAAI,CAAC,MAAK;MACf,IAAI,KAAK,CAAC,MAAN,KAAiB,CAAjB,IAAsB,KAAK,CAAC,CAAD,CAAL,KAAa,KAAK,CAAC,CAAD,CAA5C,EAAiD;QAC/C,MAAM,IAAI,UAAJ,CACF,qDACA,sBAFE,CAAN;MAGD,CAJD,MAIO;QACL,OAAO,GAAG,CAAC,KAAK,IAAN,EAAY,GAAG,CAAC,KAAK,CAAC,CAAD,CAAN,CAAf,CAAV;MACD;IACF,CARU,CAAX;EASD;;EAED,SAAS,GAAA;IACP,OAAO;MAAC,IAAI,EAAE,KAAK;IAAZ,CAAP;EACD;;AAvBsC;AACvC;;AACO,QAAA,CAAA,SAAA,GAAY,UAAZ;AAuBT,aAAa,CAAC,aAAd,CAA4B,QAA5B;AAEA;;;;;;;AAOG;;AACH,SAAS,WAAT,CACI,KADJ,EACyD;EAAA,IAAvC,UAAuC,uEAAd,cAAc;EACvD,IAAI,KAAJ;EACA,IAAI,MAAJ;EACA,eAAe,CAAC,UAAD,CAAf;;EACA,IAAI,KAAK,CAAC,MAAN,KAAiB,CAArB,EAAwB;IACtB,KAAK,GAAG,KAAK,CAAC,CAAD,CAAb;IACA,MAAM,GAAG,KAAK,CAAC,CAAD,CAAd;EACD,CAHD,MAGO,IAAI,CAAC,CAAD,EAAI,CAAJ,EAAO,CAAP,EAAU,OAAV,CAAkB,KAAK,CAAC,MAAxB,MAAoC,CAAC,CAAzC,EAA4C;IACjD,IAAI,UAAU,KAAK,eAAnB,EAAoC;MAClC,MAAM,kBAAkB,GAAG,SAAS,CAAC,KAAD,EAAQ,CAAR,CAApC;MACA,KAAK,GAAG,KAAK,CAAC,CAAD,CAAL,GAAW,kBAAnB;MACA,MAAM,GAAG,KAAK,CAAC,CAAD,CAAL,GAAW,kBAApB;IACD,CAJD,MAIO,IAAI,UAAU,KAAK,cAAnB,EAAmC;MACxC,MAAM,kBAAkB,GAAG,SAAS,CAAC,KAAD,EAAQ,CAAR,EAAW,KAAK,CAAC,MAAN,GAAe,CAA1B,CAApC;MACA,KAAK,GAAG,KAAK,CAAC,KAAK,CAAC,MAAN,GAAe,CAAhB,CAAL,GAA0B,kBAAlC;MACA,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,MAAN,GAAe,CAAhB,CAAL,GAA0B,kBAAnC;IACD;EACF,CAVM,MAUA;IACL,MAAM,SAAS,GAAG,SAAS,CAAC,KAAD,CAA3B;IACA,KAAK,GAAG,IAAI,CAAC,IAAL,CAAU,SAAV,CAAR;IACA,MAAM,GAAG,IAAI,CAAC,IAAL,CAAU,SAAV,CAAT;EACD;;EAED,OAAO,CAAC,KAAD,EAAQ,MAAR,CAAP;AACD;;AAgBD,OAAM,MAAO,eAAP,SAA+B,WAA/B,CAA0C;EAQ9C;;;AAGG;EACH,WAAA,CAAY,IAAZ,EAAqC;IACnC;;IACA,IAAI,IAAI,CAAC,KAAL,GAAa,GAAjB,EAAsB;MACpB,MAAM,IAAI,UAAJ,CACF,wCAAwC,IAAI,CAAC,KAAK,EADhD,CAAN;IAED;;IACD,KAAK,KAAL,GAAa,IAAI,CAAC,KAAL,IAAc,IAAd,GAAqB,GAArB,GAA2B,IAAI,CAAC,KAA7C;IACA,KAAK,IAAL,GAAY,IAAI,CAAC,IAAL,IAAa,IAAb,GAAoB,OAApB,GAA8B,IAAI,CAAC,IAA/C;IACA,YAAY,CAAC,KAAK,IAAN,CAAZ;IACA,KAAK,YAAL,GACI,IAAI,CAAC,YAAL,IAAqB,IAArB,GAA4B,QAA5B,GAAuC,IAAI,CAAC,YADhD;IAEA,iBAAiB,CAAC,KAAK,YAAN,CAAjB;IACA,KAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;EACD;;EAED,KAAK,CAAC,KAAD,EAAe,KAAf,EAA+B;IAClC,MAAM,IAAI,GAAG,WAAW,CAAC,KAAD,CAAxB;IACA,MAAM,KAAK,GAAG,IAAI,CAAC,CAAD,CAAlB;IACA,MAAM,MAAM,GAAG,IAAI,CAAC,CAAD,CAAnB;IACA,IAAI,KAAK,GAAG,KAAK,KAAjB;;IACA,IAAI,KAAK,IAAL,KAAc,OAAlB,EAA2B;MACzB,KAAK,IAAI,IAAI,CAAC,GAAL,CAAS,CAAT,EAAY,KAAZ,CAAT;IACD,CAFD,MAEO,IAAI,KAAK,IAAL,KAAc,QAAlB,EAA4B;MACjC,KAAK,IAAI,IAAI,CAAC,GAAL,CAAS,CAAT,EAAY,MAAZ,CAAT;IACD,CAFM,MAEA;MACL,KAAK,IAAI,IAAI,CAAC,GAAL,CAAS,CAAT,EAAY,CAAC,KAAK,GAAG,MAAT,IAAmB,CAA/B,CAAT;IACD;;IAED,IAAI,KAAK,YAAL,KAAsB,QAA1B,EAAoC;MAClC,MAAM,MAAM,GAAG,IAAI,CAAC,IAAL,CAAU,KAAV,CAAf;MACA,KAAK,GAAG,KAAK,IAAI,SAAjB;;MACA,IAAI,KAAK,KAAK,SAAV,IAAuB,KAAK,KAAK,OAArC,EAA8C;QAC5C,MAAM,IAAI,mBAAJ,CACF,GAAG,KAAK,YAAL,EAAmB,2BAA2B,KAAK,GADpD,CAAN;MAED;;MACD,OAAO,eAAe,CAAC,KAAD,EAAQ,CAAR,EAAW,MAAX,EAAmB,KAAnB,EAA0B,KAAK,IAA/B,CAAtB;IACD,CARD,MAQO;MACL,MAAM,KAAK,GAAG,IAAI,CAAC,IAAL,CAAU,IAAI,KAAd,CAAd;MACA,OAAO,aAAa,CAAC,KAAD,EAAQ,CAAC,KAAT,EAAgB,KAAhB,EAAuB,KAAvB,CAApB;IACD;EACF;;EAED,SAAS,GAAA;IACP,OAAO;MACL,KAAK,EAAE,KAAK,KADP;MAEL,IAAI,EAAE,KAAK,IAFN;MAGL,YAAY,EAAE,KAAK,YAHd;MAIL,IAAI,EAAE,KAAK;IAJN,CAAP;EAMD;;AA7D6C;AAC9C;;AACO,eAAA,CAAA,SAAA,GAAY,iBAAZ;AA6DT,aAAa,CAAC,aAAd,CAA4B,eAA5B;AAOA,OAAM,MAAO,aAAP,SAA6B,eAA7B,CAA4C;EAIhD;;;;;;AAMG;EACH,WAAA,CAAY,IAAZ,EAA0C;IACxC,MAAM;MACJ,KAAK,EAAE,GADH;MAEJ,IAAI,EAAE,QAFF;MAGJ,YAAY,EAAE,SAHV;MAIJ,IAAI,EAAE,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsB,IAAI,CAAC;IAJ7B,CAAN;EAMD;;EAED,YAAY,GAAA;IACV;IACA;IACA;IACA,OAAO,eAAe,CAAC,SAAvB;EACD;;AAzB+C;AAChD;;AACO,aAAA,CAAA,SAAA,GAAY,eAAZ;AAyBT,aAAa,CAAC,aAAd,CAA4B,aAA5B;AAEA,OAAM,MAAO,YAAP,SAA4B,eAA5B,CAA2C;EAI/C;;;;;;AAMG;EACH,WAAA,CAAY,IAAZ,EAA0C;IACxC,MAAM;MACJ,KAAK,EAAE,GADH;MAEJ,IAAI,EAAE,QAFF;MAGJ,YAAY,EAAE,QAHV;MAIJ,IAAI,EAAE,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsB,IAAI,CAAC;IAJ7B,CAAN;EAMD;;EAED,YAAY,GAAA;IACV;IACA;IACA;IACA,OAAO,eAAe,CAAC,SAAvB;EACD;;AAzB8C;AAC/C;;AACO,YAAA,CAAA,SAAA,GAAY,cAAZ;AAyBT,aAAa,CAAC,aAAd,CAA4B,YAA5B;AAEA,OAAM,MAAO,QAAP,SAAwB,eAAxB,CAAuC;EAI3C,WAAA,CAAY,IAAZ,EAA0C;IACxC,MAAM;MACJ,KAAK,EAAE,GADH;MAEJ,IAAI,EAAE,OAFF;MAGJ,YAAY,EAAE,QAHV;MAIJ,IAAI,EAAE,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsB,IAAI,CAAC;IAJ7B,CAAN;EAMD;;EAED,YAAY,GAAA;IACV;IACA;IACA;IACA,OAAO,eAAe,CAAC,SAAvB;EACD;;AAlB0C;AAC3C;;AACO,QAAA,CAAA,SAAA,GAAY,UAAZ;AAkBT,aAAa,CAAC,aAAd,CAA4B,QAA5B;AAEA,OAAM,MAAO,SAAP,SAAyB,eAAzB,CAAwC;EAI5C,WAAA,CAAY,IAAZ,EAA0C;IACxC,MAAM;MACJ,KAAK,EAAE,GADH;MAEJ,IAAI,EAAE,OAFF;MAGJ,YAAY,EAAE,SAHV;MAIJ,IAAI,EAAE,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsB,IAAI,CAAC;IAJ7B,CAAN;EAMD;;EAED,YAAY,GAAA;IACV;IACA;IACA;IACA,OAAO,eAAe,CAAC,SAAvB;EACD;;AAlB2C;AAC5C;;AACO,SAAA,CAAA,SAAA,GAAY,WAAZ;AAkBT,aAAa,CAAC,aAAd,CAA4B,SAA5B;AAEA,OAAM,MAAO,WAAP,SAA2B,eAA3B,CAA0C;EAI9C,WAAA,CAAY,IAAZ,EAA0C;IACxC,MAAM;MACJ,KAAK,EAAE,GADH;MAEJ,IAAI,EAAE,OAFF;MAGJ,YAAY,EAAE,QAHV;MAIJ,IAAI,EAAE,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsB,IAAI,CAAC;IAJ7B,CAAN;EAMD;;EAED,YAAY,GAAA;IACV;IACA;IACA;IACA,OAAO,eAAe,CAAC,SAAvB;EACD;;AAlB6C;AAC9C;;AACO,WAAA,CAAA,SAAA,GAAY,aAAZ;AAkBT,aAAa,CAAC,aAAd,CAA4B,WAA5B;AAEA,OAAM,MAAO,YAAP,SAA4B,eAA5B,CAA2C;EAI/C,WAAA,CAAY,IAAZ,EAA0C;IACxC,MAAM;MACJ,KAAK,EAAE,GADH;MAEJ,IAAI,EAAE,OAFF;MAGJ,YAAY,EAAE,SAHV;MAIJ,IAAI,EAAE,IAAI,IAAI,IAAR,GAAe,IAAf,GAAsB,IAAI,CAAC;IAJ7B,CAAN;EAMD;;EAED,YAAY,GAAA;IACV;IACA;IACA;IACA,OAAO,eAAe,CAAC,SAAvB;EACD;;AAlB8C;AAC/C;;AACO,YAAA,CAAA,SAAA,GAAY,aAAZ;AAkBT,aAAa,CAAC,aAAd,CAA4B,YAA5B;AASA,OAAM,MAAO,UAAP,SAA0B,WAA1B,CAAqC;EAOzC,WAAA,CAAY,IAAZ,EAAiC;IAC/B;IALO,KAAA,YAAA,GAAe,CAAf;IAMP,KAAK,IAAL,GAAY,IAAI,CAAC,IAAL,IAAa,IAAb,GAAoB,KAAK,YAAzB,GAAwC,IAAI,CAAC,IAAzD;IACA,KAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;;IAEA,IAAI,KAAK,IAAL,IAAa,IAAjB,EAAuB;MACrB,MAAM,IAAI,mBAAJ,CACF,gEADE,CAAN;IAED;EACF;;EAED,KAAK,CAAC,KAAD,EAAe,KAAf,EAA+B;IAClC,OAAO,IAAI,CAAC,MAAK;MACf,IAAI,KAAK,CAAC,MAAN,GAAe,CAAnB,EAAsB;QACpB,MAAM,IAAI,mBAAJ,CAAwB,4BAAxB,CAAN;MACD;;MACD,IAAI,KAAK,CAAC,CAAD,CAAL,GAAW,KAAK,CAAC,CAAD,CAAhB,GAAsB,IAA1B,EAAgC;QAC9B,OAAO,CAAC,IAAR,CACI,+DAAA,GACA,cAAc,KAAK,CAAC,CAAD,CAAL,GAAW,KAAK,CAAC,CAAD,CAAG,cADjC,GAEA,sBAHJ;MAID,CATc,CAWf;;;MACA,MAAM,eAAe,GACjB,KAAK,CAAC,CAAD,CAAL,GAAW,KAAK,CAAC,CAAD,CAAhB,GAAsB,CAAC,KAAK,CAAC,CAAD,CAAN,EAAW,KAAK,CAAC,CAAD,CAAhB,CAAtB,GAA6C,KADjD;MAEA,MAAM,CAAC,GAAG,CAAC,CAAC,YAAF,CAAe,eAAf,EAAgC,CAAhC,EAAmC,CAAnC,EAAsC,SAAtC,CAAV;MACA,IAAI,CAAC,GAAG,MAAM,CAAC,WAAP,CAAmB,CAAnB,CAAR;;MACA,IAAI,KAAK,CAAC,CAAD,CAAL,GAAW,KAAK,CAAC,CAAD,CAApB,EAAyB;QACvB,CAAC,GAAG,SAAS,CAAC,CAAD,CAAb;MACD;;MACD,OAAO,GAAG,CAAC,KAAK,IAAN,EAAY,CAAZ,CAAV;IACD,CApBU,CAAX;EAqBD;;EAED,SAAS,GAAA;IACP,OAAO;MACL,IAAI,EAAE,KAAK,IADN;MAEL,IAAI,EAAE,KAAK;IAFN,CAAP;EAID;;AA/CwC;AACzC;;AACO,UAAA,CAAA,SAAA,GAAY,YAAZ;AA+CT,aAAa,CAAC,aAAd,CAA4B,UAA5B,E,CAQA;AACA;;AACA,OAAO,MAAM,0CAA0C,GACD;EAChD,YAAY,UADoC;EAEhD,gBAAgB,cAFgC;EAGhD,iBAAiB,eAH+B;EAIhD,YAAY,UAJoC;EAKhD,aAAa,WALmC;EAMhD,YAAY,UANoC;EAOhD,eAAe,aAPiC;EAQhD,gBAAgB,cARgC;EAShD,QAAQ,MATwC;EAUhD,cAAc,YAVkC;EAWhD,gBAAgB,cAXgC;EAYhD,iBAAiB,eAZ+B;EAahD,mBAAmB,iBAb6B;EAchD,mBAAmB,iBAd6B;EAehD,SAAS;AAfuC,CAD/C;;AAmBP,SAAS,sBAAT,CACI,MADJ,EAEgD;EAAA,IAA5C,aAA4C,uEAAF,EAAE;EAC9C,OAAO,sBAAsB,CACzB,MADyB,EACjB,aAAa,CAAC,gBAAd,CAA+B,MAA/B,GAAwC,YADvB,EAEzB,aAFyB,EAEV,aAFU,CAA7B;AAGD;;AAED,OAAM,SAAU,oBAAV,CAA+B,WAA/B,EAAuD;EAE3D,OAAO,oBAAoB,CAAC,WAAD,CAA3B;AACD;AAED,OAAM,SAAU,cAAV,CAAyB,UAAzB,EACiD;EACrD,IAAI,OAAO,UAAP,KAAsB,QAA1B,EAAoC;IAClC,MAAM,SAAS,GAAG,UAAU,IAAI,0CAAd,GACd,0CAA0C,CAAC,UAAD,CAD5B,GAEd,UAFJ;IAGA;;AAEsC;;IACtC,IAAI,SAAS,KAAK,cAAlB,EAAkC;MAChC,OAAO,IAAI,YAAJ,EAAP;IACD,CAFD,MAEO,IAAI,SAAS,KAAK,eAAlB,EAAmC;MACxC,OAAO,IAAI,aAAJ,EAAP;IACD,CAFM,MAEA,IAAI,SAAS,KAAK,UAAlB,EAA8B;MACnC,OAAO,IAAI,QAAJ,EAAP;IACD,CAFM,MAEA,IAAI,SAAS,KAAK,WAAlB,EAA+B;MACpC,OAAO,IAAI,SAAJ,EAAP;IACD,CAFM,MAEA,IAAI,SAAS,KAAK,aAAlB,EAAiC;MACtC,OAAO,IAAI,WAAJ,EAAP;IACD,CAFM,MAEA,IAAI,SAAS,KAAK,cAAlB,EAAkC;MACvC,OAAO,IAAI,YAAJ,EAAP;IACD,CAFM,MAEA;MACL,MAAM,MAAM,GAA6B,EAAzC;MACA,MAAM,CAAC,WAAD,CAAN,GAAsB,SAAtB;MACA,MAAM,CAAC,QAAD,CAAN,GAAmB,EAAnB;MACA,OAAO,sBAAsB,CAAC,MAAD,CAA7B;IACD;EACF,CAzBD,MAyBO,IAAI,UAAU,YAAY,WAA1B,EAAuC;IAC5C,OAAO,UAAP;EACD,CAFM,MAEA;IACL,OAAO,sBAAsB,CAAC,UAAD,CAA7B;EACD;AACF","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {DataType, eye, linalg, mul, ones, randomUniform, scalar, serialization, Tensor, Tensor2D, tidy, transpose, truncatedNormal, zeros} from '@tensorflow/tfjs-core';\n\nimport * as K from './backend/tfjs_backend';\nimport {checkDataFormat} from './common';\nimport {NotImplementedError, ValueError} from './errors';\nimport {DataFormat, Shape} from './keras_format/common';\nimport {Distribution, FanMode, VALID_DISTRIBUTION_VALUES, VALID_FAN_MODE_VALUES} from './keras_format/initializer_config';\nimport {checkStringTypeUnionValue, deserializeKerasObject, serializeKerasObject} from './utils/generic_utils';\nimport {arrayProd} from './utils/math_utils';\n\nexport function checkFanMode(value?: string): void {\n  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, 'FanMode', value);\n}\n\nexport function checkDistribution(value?: string): void {\n  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, 'Distribution', value);\n}\n\n/**\n * Initializer base class.\n *\n * @doc {\n *   heading: 'Initializers', subheading: 'Classes', namespace: 'initializers'}\n */\nexport abstract class Initializer extends serialization.Serializable {\n  public fromConfigUsesCustomObjects(): boolean {\n    return false;\n  }\n  /**\n   * Generate an initial value.\n   * @param shape\n   * @param dtype\n   * @return The init value.\n   */\n  abstract apply(shape: Shape, dtype?: DataType): Tensor;\n\n  getConfig(): serialization.ConfigDict {\n    return {};\n  }\n}\n\nexport class Zeros extends Initializer {\n  /** @nocollapse */\n  static className = 'Zeros';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return zeros(shape, dtype);\n  }\n}\nserialization.registerClass(Zeros);\n\nexport class Ones extends Initializer {\n  /** @nocollapse */\n  static className = 'Ones';\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return ones(shape, dtype);\n  }\n}\nserialization.registerClass(Ones);\n\nexport interface ConstantArgs {\n  /** The value for each element in the variable. */\n  value: number;\n}\n\nexport class Constant extends Initializer {\n  /** @nocollapse */\n  static className = 'Constant';\n  private value: number;\n  constructor(args: ConstantArgs) {\n    super();\n    if (typeof args !== 'object') {\n      throw new ValueError(\n          `Expected argument of type ConstantConfig but got ${args}`);\n    }\n    if (args.value === undefined) {\n      throw new ValueError(`config must have value set but got ${args}`);\n    }\n    this.value = args.value;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => mul(scalar(this.value), ones(shape, dtype)));\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {\n      value: this.value,\n    };\n  }\n}\nserialization.registerClass(Constant);\n\nexport interface RandomUniformArgs {\n  /** Lower bound of the range of random values to generate. */\n  minval?: number;\n  /** Upper bound of the range of random values to generate. */\n  maxval?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomUniform extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomUniform';\n  readonly DEFAULT_MINVAL = -0.05;\n  readonly DEFAULT_MAXVAL = 0.05;\n  private minval: number;\n  private maxval: number;\n  private seed: number;\n\n  constructor(args: RandomUniformArgs) {\n    super();\n    this.minval = args.minval || this.DEFAULT_MINVAL;\n    this.maxval = args.maxval || this.DEFAULT_MAXVAL;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return randomUniform(shape, this.minval, this.maxval, dtype);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {minval: this.minval, maxval: this.maxval, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomUniform);\n\nexport interface RandomNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class RandomNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'RandomNormal';\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: RandomNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `randomNormal does not support dType ${dtype}.`);\n    }\n\n    return K.randomNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(RandomNormal);\n\nexport interface TruncatedNormalArgs {\n  /** Mean of the random values to generate. */\n  mean?: number;\n  /** Standard deviation of the random values to generate. */\n  stddev?: number;\n  /** Used to seed the random generator. */\n  seed?: number;\n}\n\nexport class TruncatedNormal extends Initializer {\n  /** @nocollapse */\n  static className = 'TruncatedNormal';\n\n  readonly DEFAULT_MEAN = 0.;\n  readonly DEFAULT_STDDEV = 0.05;\n  private mean: number;\n  private stddev: number;\n  private seed: number;\n\n  constructor(args: TruncatedNormalArgs) {\n    super();\n    this.mean = args.mean || this.DEFAULT_MEAN;\n    this.stddev = args.stddev || this.DEFAULT_STDDEV;\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n      throw new NotImplementedError(\n          `truncatedNormal does not support dType ${dtype}.`);\n    }\n    return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {mean: this.mean, stddev: this.stddev, seed: this.seed};\n  }\n}\nserialization.registerClass(TruncatedNormal);\n\nexport interface IdentityArgs {\n  /**\n   * Multiplicative factor to apply to the identity matrix.\n   */\n  gain?: number;\n}\n\nexport class Identity extends Initializer {\n  /** @nocollapse */\n  static className = 'Identity';\n  private gain: number;\n  constructor(args: IdentityArgs) {\n    super();\n    this.gain = args.gain != null ? args.gain : 1.0;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length !== 2 || shape[0] !== shape[1]) {\n        throw new ValueError(\n            'Identity matrix initializer can only be used for' +\n            ' 2D square matrices.');\n      } else {\n        return mul(this.gain, eye(shape[0]));\n      }\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {gain: this.gain};\n  }\n}\nserialization.registerClass(Identity);\n\n/**\n * Computes the number of input and output units for a weight shape.\n * @param shape Shape of weight.\n * @param dataFormat data format to use for convolution kernels.\n *   Note that all kernels in Keras are standardized on the\n *   CHANNEL_LAST ordering (even when inputs are set to CHANNEL_FIRST).\n * @return An length-2 array: fanIn, fanOut.\n */\nfunction computeFans(\n    shape: Shape, dataFormat: DataFormat = 'channelsLast'): number[] {\n  let fanIn: number;\n  let fanOut: number;\n  checkDataFormat(dataFormat);\n  if (shape.length === 2) {\n    fanIn = shape[0];\n    fanOut = shape[1];\n  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {\n    if (dataFormat === 'channelsFirst') {\n      const receptiveFieldSize = arrayProd(shape, 2);\n      fanIn = shape[1] * receptiveFieldSize;\n      fanOut = shape[0] * receptiveFieldSize;\n    } else if (dataFormat === 'channelsLast') {\n      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);\n      fanIn = shape[shape.length - 2] * receptiveFieldSize;\n      fanOut = shape[shape.length - 1] * receptiveFieldSize;\n    }\n  } else {\n    const shapeProd = arrayProd(shape);\n    fanIn = Math.sqrt(shapeProd);\n    fanOut = Math.sqrt(shapeProd);\n  }\n\n  return [fanIn, fanOut];\n}\n\nexport interface VarianceScalingArgs {\n  /** Scaling factor (positive float). */\n  scale?: number;\n\n  /** Fanning mode for inputs and outputs. */\n  mode?: FanMode;\n\n  /** Probabilistic distribution of the values. */\n  distribution?: Distribution;\n\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class VarianceScaling extends Initializer {\n  /** @nocollapse */\n  static className = 'VarianceScaling';\n  private scale: number;\n  private mode: FanMode;\n  private distribution: Distribution;\n  private seed: number;\n\n  /**\n   * Constructor of VarianceScaling.\n   * @throws ValueError for invalid value in scale.\n   */\n  constructor(args: VarianceScalingArgs) {\n    super();\n    if (args.scale < 0.0) {\n      throw new ValueError(\n          `scale must be a positive float. Got: ${args.scale}`);\n    }\n    this.scale = args.scale == null ? 1.0 : args.scale;\n    this.mode = args.mode == null ? 'fanIn' : args.mode;\n    checkFanMode(this.mode);\n    this.distribution =\n        args.distribution == null ? 'normal' : args.distribution;\n    checkDistribution(this.distribution);\n    this.seed = args.seed;\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    const fans = computeFans(shape);\n    const fanIn = fans[0];\n    const fanOut = fans[1];\n    let scale = this.scale;\n    if (this.mode === 'fanIn') {\n      scale /= Math.max(1, fanIn);\n    } else if (this.mode === 'fanOut') {\n      scale /= Math.max(1, fanOut);\n    } else {\n      scale /= Math.max(1, (fanIn + fanOut) / 2);\n    }\n\n    if (this.distribution === 'normal') {\n      const stddev = Math.sqrt(scale);\n      dtype = dtype || 'float32';\n      if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(\n            `${this.getClassName()} does not support dType ${dtype}.`);\n      }\n      return truncatedNormal(shape, 0, stddev, dtype, this.seed);\n    } else {\n      const limit = Math.sqrt(3 * scale);\n      return randomUniform(shape, -limit, limit, dtype);\n    }\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {\n      scale: this.scale,\n      mode: this.mode,\n      distribution: this.distribution,\n      seed: this.seed\n    };\n  }\n}\nserialization.registerClass(VarianceScaling);\n\nexport interface SeedOnlyInitializerArgs {\n  /** Random number generator seed. */\n  seed?: number;\n}\n\nexport class GlorotUniform extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'GlorotUniform';\n\n  /**\n   * Constructor of GlorotUniform\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, GlorotUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotUniform);\n\nexport class GlorotNormal extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'GlorotNormal';\n\n  /**\n   * Constructor of GlorotNormal.\n   * @param scale\n   * @param mode\n   * @param distribution\n   * @param seed\n   */\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanAvg',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, GlorotNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(GlorotNormal);\n\nexport class HeNormal extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'HeNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, HeNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeNormal);\n\nexport class HeUniform extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'HeUniform';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 2.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, HeUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(HeUniform);\n\nexport class LeCunNormal extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'LeCunNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'normal',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, LeCunNormal is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunNormal);\n\nexport class LeCunUniform extends VarianceScaling {\n  /** @nocollapse */\n  static className = 'LeCunNormal';\n\n  constructor(args?: SeedOnlyInitializerArgs) {\n    super({\n      scale: 1.0,\n      mode: 'fanIn',\n      distribution: 'uniform',\n      seed: args == null ? null : args.seed\n    });\n  }\n\n  getClassName(): string {\n    // In Python Keras, LeCunUniform is not a class, but a helper method\n    // that creates a VarianceScaling object. Use 'VarianceScaling' as\n    // class name to be compatible with that.\n    return VarianceScaling.className;\n  }\n}\nserialization.registerClass(LeCunUniform);\n\nexport interface OrthogonalArgs extends SeedOnlyInitializerArgs {\n  /**\n   * Multiplicative factor to apply to the orthogonal matrix. Defaults to 1.\n   */\n  gain?: number;\n}\n\nexport class Orthogonal extends Initializer {\n  /** @nocollapse */\n  static className = 'Orthogonal';\n  readonly DEFAULT_GAIN = 1;\n  protected readonly gain: number;\n  protected readonly seed: number;\n\n  constructor(args?: OrthogonalArgs) {\n    super();\n    this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;\n    this.seed = args.seed;\n\n    if (this.seed != null) {\n      throw new NotImplementedError(\n          'Random seed is not implemented for Orthogonal Initializer yet.');\n    }\n  }\n\n  apply(shape: Shape, dtype?: DataType): Tensor {\n    return tidy(() => {\n      if (shape.length < 2) {\n        throw new NotImplementedError('Shape must be at least 2D.');\n      }\n      if (shape[0] * shape[1] > 2000) {\n        console.warn(\n            `Orthogonal initializer is being called on a matrix with more ` +\n            `than 2000 (${shape[0] * shape[1]}) elements: ` +\n            `Slowness may result.`);\n      }\n\n      // TODO(cais): Add seed support.\n      const normalizedShape =\n          shape[0] > shape[1] ? [shape[1], shape[0]] : shape;\n      const a = K.randomNormal(normalizedShape, 0, 1, 'float32') as Tensor2D;\n      let q = linalg.gramSchmidt(a) as Tensor2D;\n      if (shape[0] > shape[1]) {\n        q = transpose(q);\n      }\n      return mul(this.gain, q);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    return {\n      gain: this.gain,\n      seed: this.seed,\n    };\n  }\n}\nserialization.registerClass(Orthogonal);\n\n/** @docinline */\nexport type InitializerIdentifier =\n    'constant'|'glorotNormal'|'glorotUniform'|'heNormal'|'heUniform'|'identity'|\n    'leCunNormal'|'leCunUniform'|'ones'|'orthogonal'|'randomNormal'|\n    'randomUniform'|'truncatedNormal'|'varianceScaling'|'zeros'|string;\n\n// Maps the JavaScript-like identifier keys to the corresponding registry\n// symbols.\nexport const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP:\n    {[identifier in InitializerIdentifier]: string} = {\n      'constant': 'Constant',\n      'glorotNormal': 'GlorotNormal',\n      'glorotUniform': 'GlorotUniform',\n      'heNormal': 'HeNormal',\n      'heUniform': 'HeUniform',\n      'identity': 'Identity',\n      'leCunNormal': 'LeCunNormal',\n      'leCunUniform': 'LeCunUniform',\n      'ones': 'Ones',\n      'orthogonal': 'Orthogonal',\n      'randomNormal': 'RandomNormal',\n      'randomUniform': 'RandomUniform',\n      'truncatedNormal': 'TruncatedNormal',\n      'varianceScaling': 'VarianceScaling',\n      'zeros': 'Zeros'\n    };\n\nfunction deserializeInitializer(\n    config: serialization.ConfigDict,\n    customObjects: serialization.ConfigDict = {}): Initializer {\n  return deserializeKerasObject(\n      config, serialization.SerializationMap.getMap().classNameMap,\n      customObjects, 'initializer');\n}\n\nexport function serializeInitializer(initializer: Initializer):\n    serialization.ConfigDictValue {\n  return serializeKerasObject(initializer);\n}\n\nexport function getInitializer(identifier: InitializerIdentifier|Initializer|\n                               serialization.ConfigDict): Initializer {\n  if (typeof identifier === 'string') {\n    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ?\n        INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] :\n        identifier;\n    /* We have four 'helper' classes for common initializers that\n    all get serialized as 'VarianceScaling' and shouldn't go through\n    the deserializeInitializer pathway. */\n    if (className === 'GlorotNormal') {\n      return new GlorotNormal();\n    } else if (className === 'GlorotUniform') {\n      return new GlorotUniform();\n    } else if (className === 'HeNormal') {\n      return new HeNormal();\n    } else if (className === 'HeUniform') {\n      return new HeUniform();\n    } else if (className === 'LeCunNormal') {\n      return new LeCunNormal();\n    } else if (className === 'LeCunUniform') {\n      return new LeCunUniform();\n    } else {\n      const config: serialization.ConfigDict = {};\n      config['className'] = className;\n      config['config'] = {};\n      return deserializeInitializer(config);\n    }\n  } else if (identifier instanceof Initializer) {\n    return identifier;\n  } else {\n    return deserializeInitializer(identifier);\n  }\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}