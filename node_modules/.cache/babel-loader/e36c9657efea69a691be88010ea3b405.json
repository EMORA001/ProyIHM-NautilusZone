{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until is has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\n\nfunction broadcastTo_(x, shape) {\n  let input = convertToTensor(x, 'broadcastTo', 'x');\n  const xShape = input.shape;\n\n  if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n    throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n  }\n\n  if (shape.length < input.rank) {\n    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);\n  }\n\n  if (shape.length > input.rank) {\n    const newShape = input.shape.slice();\n\n    while (newShape.length < shape.length) {\n      newShape.unshift(1);\n    }\n\n    input = reshape(input, newShape);\n  }\n\n  const inputShape = input.shape;\n  const reps = Array.from(shape);\n\n  for (let i = shape.length - 1; i >= 0; i--) {\n    if (inputShape[i] === shape[i]) {\n      reps[i] = 1;\n    } else if (input.shape[i] !== 1) {\n      throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n    }\n  }\n\n  const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n\n  if (axes.length === 0) {\n    return clone(input);\n  } // TODO call broadcastTo kernel directly once backends implement broadcstTo\n\n\n  const inputs = {\n    x: input\n  };\n  const attrs = {\n    reps\n  };\n  return ENGINE.runKernel(Tile, inputs, attrs);\n}\n\nexport const broadcastTo = op({\n  broadcastTo_\n});","map":{"version":3,"sources":["../../../../../../tfjs-core/src/ops/broadcast_to.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,MAAR,QAAqB,WAArB;AACA,SAAQ,IAAR,QAA0C,iBAA1C;AAIA,SAAQ,eAAR,QAA8B,oBAA9B;AAGA,SAAQ,KAAR,QAAoB,SAApB;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AAEA;;;;;;;;;;;;;AAaG;;AACH,SAAS,YAAT,CACI,CADJ,EAC0B,KAD1B,EAC4C;EAC1C,IAAI,KAAK,GAAG,eAAe,CAAC,CAAD,EAAI,aAAJ,EAAmB,GAAnB,CAA3B;EACA,MAAM,MAAM,GAAG,KAAK,CAAC,KAArB;;EAEA,IAAI,KAAK,CAAC,IAAN,CAAW,CAAC,IAAI,EAAE,CAAC,GAAG,CAAN,KAAY,CAAC,GAAG,CAAJ,KAAU,CAAtC,CAAJ,EAA8C;IAC5C,MAAM,IAAI,KAAJ,CAAU,2CAA2C,KAAK,IAA1D,CAAN;EACD;;EAED,IAAI,KAAK,CAAC,MAAN,GAAe,KAAK,CAAC,IAAzB,EAA+B;IAC7B,MAAM,IAAI,KAAJ,CAAU,+BAA+B,KAAK,CAAC,MAAM,iBACvD,KAAK,CAAC,IAAI,GADR,CAAN;EAED;;EAED,IAAI,KAAK,CAAC,MAAN,GAAe,KAAK,CAAC,IAAzB,EAA+B;IAC7B,MAAM,QAAQ,GAAG,KAAK,CAAC,KAAN,CAAY,KAAZ,EAAjB;;IACA,OAAO,QAAQ,CAAC,MAAT,GAAkB,KAAK,CAAC,MAA/B,EAAuC;MACrC,QAAQ,CAAC,OAAT,CAAiB,CAAjB;IACD;;IACD,KAAK,GAAG,OAAO,CAAC,KAAD,EAAQ,QAAR,CAAf;EACD;;EAED,MAAM,UAAU,GAAG,KAAK,CAAC,KAAzB;EACA,MAAM,IAAI,GAAa,KAAK,CAAC,IAAN,CAAW,KAAX,CAAvB;;EACA,KAAK,IAAI,CAAC,GAAG,KAAK,CAAC,MAAN,GAAe,CAA5B,EAA+B,CAAC,IAAI,CAApC,EAAuC,CAAC,EAAxC,EAA4C;IAC1C,IAAI,UAAU,CAAC,CAAD,CAAV,KAAkB,KAAK,CAAC,CAAD,CAA3B,EAAgC;MAC9B,IAAI,CAAC,CAAD,CAAJ,GAAU,CAAV;IACD,CAFD,MAEO,IAAI,KAAK,CAAC,KAAN,CAAY,CAAZ,MAAmB,CAAvB,EAA0B;MAC/B,MAAM,IAAI,KAAJ,CACF,mBAAmB,MAAM,6BAA6B,KAAK,IADzD,CAAN;IAED;EACF;;EACD,MAAM,IAAI,GAAG,IAAI,CAAC,GAAL,CAAS,CAAC,CAAD,EAAI,CAAJ,KAAU,CAAC,GAAG,CAAJ,GAAQ,CAAR,GAAY,CAAC,CAAhC,EAAmC,MAAnC,CAA0C,CAAC,IAAI,CAAC,IAAI,CAApD,CAAb;;EAEA,IAAI,IAAI,CAAC,MAAL,KAAgB,CAApB,EAAuB;IACrB,OAAO,KAAK,CAAC,KAAD,CAAZ;EACD,CAnCyC,CAqC1C;;;EACA,MAAM,MAAM,GAAe;IAAC,CAAC,EAAE;EAAJ,CAA3B;EACA,MAAM,KAAK,GAAc;IAAC;EAAD,CAAzB;EACA,OAAO,MAAM,CAAC,SAAP,CACH,IADG,EACG,MADH,EACmC,KADnC,CAAP;AAED;;AAED,OAAO,MAAM,WAAW,GAAG,EAAE,CAAC;EAAC;AAAD,CAAD,CAAtB","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Tile, TileAttrs, TileInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {Rank, ShapeMap, TensorLike} from '../types';\n\nimport {clone} from './clone';\nimport {op} from './operation';\nimport {reshape} from './reshape';\n\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until is has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastTo_<R extends Rank>(\n    x: Tensor|TensorLike, shape: ShapeMap[R]): Tensor<R> {\n  let input = convertToTensor(x, 'broadcastTo', 'x');\n  const xShape = input.shape;\n\n  if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n    throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n  }\n\n  if (shape.length < input.rank) {\n    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${\n        input.rank}.`);\n  }\n\n  if (shape.length > input.rank) {\n    const newShape = input.shape.slice();\n    while (newShape.length < shape.length) {\n      newShape.unshift(1);\n    }\n    input = reshape(input, newShape);\n  }\n\n  const inputShape = input.shape;\n  const reps: number[] = Array.from(shape);\n  for (let i = shape.length - 1; i >= 0; i--) {\n    if (inputShape[i] === shape[i]) {\n      reps[i] = 1;\n    } else if (input.shape[i] !== 1) {\n      throw new Error(\n          `broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n    }\n  }\n  const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n\n  if (axes.length === 0) {\n    return clone(input) as Tensor<R>;\n  }\n\n  // TODO call broadcastTo kernel directly once backends implement broadcstTo\n  const inputs: TileInputs = {x: input};\n  const attrs: TileAttrs = {reps};\n  return ENGINE.runKernel(\n      Tile, inputs as {} as NamedTensorMap, attrs as unknown as NamedAttrMap);\n}\n\nexport const broadcastTo = op({broadcastTo_});\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}