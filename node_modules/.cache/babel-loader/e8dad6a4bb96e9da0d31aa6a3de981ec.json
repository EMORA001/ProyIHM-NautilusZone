{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Merge Layers.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy, util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { Layer } from '../engine/topology';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { l2Normalize } from '../losses';\nimport * as generic_utils from '../utils/generic_utils';\nimport * as mathUtils from '../utils/math_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\n/**\n * Generic Merge layer for element-wise merge functions.\n *\n * Used to implement `Sum`, `Average`, `Concatenate`, etc.\n */\n\nexport class Merge extends Layer {\n  constructor(args) {\n    super(args || {});\n    this.supportsMasking = true;\n  }\n  /**\n   * Logic for merging multiple tensors, to be overridden by subclasses.\n   * @param inputs\n   */\n\n\n  mergeFunction(inputs) {\n    throw new NotImplementedError();\n  }\n  /**\n   * Computes the shape of the result of an elementwise operation.\n   *\n   * @param shape1: Shape of the first tensor.\n   * @param shape2: Shape of the second tensor.\n   * @returns Expected output shape when an elementwise operation is carried\n   *   out on 2 tensors with shapes `shape1` and `shape2`.\n   * @throws ValueError: If `shape1` and `shape2` are not compatible for\n   *   element-wise operations.\n   */\n\n\n  computeElementwiseOpOutputShape(shape1, shape2) {\n    if (shape1 == null || shape2 == null) {\n      return null;\n    } else if (shape1.length < shape2.length) {\n      return this.computeElementwiseOpOutputShape(shape2, shape1);\n    } else if (shape2.length === 0) {\n      return shape1;\n    }\n\n    const outputShape = shape1.slice(0, shape1.length - shape2.length);\n\n    for (let k = 0; k < shape2.length; ++k) {\n      const i = shape1[shape1.length - shape2.length + k];\n      const j = shape2[k];\n\n      if (i == null || j == null || i < 0 || j < 0) {\n        outputShape.push(null);\n      } else if (i === 1) {\n        outputShape.push(j);\n      } else if (j === 1) {\n        outputShape.push(i);\n      } else {\n        if (i !== j) {\n          throw new ValueError('Operands could not be broadcast together with shapes ' + JSON.stringify(shape1) + ' ' + JSON.stringify(shape2));\n        }\n\n        outputShape.push(i);\n      }\n    }\n\n    return outputShape;\n  }\n\n  build(inputShape) {\n    // Used purely for shape validation.\n    if (Array.isArray(inputShape) && !Array.isArray(inputShape[0])) {\n      // Make sure that inputShape is an Array of shape.\n      inputShape = [getExactlyOneShape(inputShape)];\n    }\n\n    inputShape = inputShape;\n\n    if (inputShape.length < 2) {\n      throw new ValueError('A merge layer should be called on an Array of at least 2 inputs.' + ` Got ${inputShape.length} input(s).`);\n    } // Make sure that there is at most one unique batch size among the input\n    // shapes.\n\n\n    let batchSizes = [];\n\n    for (const shape of inputShape) {\n      if (shape != null && shape[0] !== null) {\n        batchSizes.push(shape[0]);\n      }\n    }\n\n    batchSizes = generic_utils.unique(batchSizes);\n\n    if (batchSizes.length > 1) {\n      throw new ValueError(`Can not merge tensors with different batch sizes. ` + `Got tensors with shapes: ${JSON.stringify(inputShape)}.`);\n    }\n\n    let outputShape = inputShape[0] == null ? null : inputShape[0].slice(1);\n\n    for (let i = 1; i < inputShape.length; ++i) {\n      const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n      outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n    } // If the inputs have different ranks, we have to reshape them to make them\n    // broadcastable.\n\n\n    const allRanks = inputShape.map(shape => shape.length);\n\n    if (inputShape.indexOf(null) === -1 && generic_utils.unique(allRanks).length === 1) {\n      this.reshapeRequired = false;\n    } else {\n      this.reshapeRequired = true;\n    }\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      inputs = inputs;\n\n      if (this.reshapeRequired) {\n        const reshapedInputs = [];\n        const inputDims = inputs.map(input => input.rank);\n\n        if (inputDims.indexOf(null) === -1) {\n          // If ranks of all inputs are available, we simply expand each of them\n          // at axis=1 until all of them have the same rank.\n          const maxNDim = mathUtils.max(inputDims);\n\n          for (let x of inputs) {\n            const xNDim = x.rank;\n\n            for (let k = 0; k < maxNDim - xNDim; ++k) {\n              x = K.expandDims(x, 1);\n            }\n\n            reshapedInputs.push(x);\n          }\n\n          return this.mergeFunction(reshapedInputs);\n        } else {\n          // Transpose all inputs so that batch size is the last dimension.\n          // [batchSize, dim1, dim2, ...] -> [dim1, dim2, ..., batchSize]\n          let transposed = false;\n\n          for (const x of inputs) {\n            const xNDim = x.rank;\n\n            if (xNDim == null) {\n              const xShape = x.shape;\n              const batchSize = xShape[0];\n              const newShape = xShape.slice(1).concat([batchSize]);\n              let xTransposed = tfc.reshape(x, [batchSize].concat(mathUtils.arrayProd(xShape.slice(1))));\n              xTransposed = tfc.transpose(xTransposed, [1, 0]);\n              xTransposed = tfc.reshape(xTransposed, newShape);\n              reshapedInputs.push(xTransposed);\n              transposed = true;\n            } else if (xNDim > 1) {\n              const dims = mathUtils.range(1, xNDim).concat([0]);\n              reshapedInputs.push(tfc.transpose(x, dims));\n              transposed = true;\n            } else {\n              // We don't transpose inputs if they are 1D vectors or scalars.\n              reshapedInputs.push(x);\n            }\n          }\n\n          let y = this.mergeFunction(reshapedInputs);\n          const yNDim = y.rank;\n\n          if (transposed) {\n            // If inputs have been transposed, we have to transpose the output\n            // too.\n            if (yNDim == null) {\n              const yShape = y.shape;\n              const yNDim = yShape.length;\n              const batchSize = yShape[yNDim - 1];\n              const newShape = [batchSize].concat(yShape.slice(0, yShape.length - 1));\n              y = tfc.reshape(tfc.transpose(tfc.reshape(y, [-1, batchSize]), [1, 0]), newShape);\n            } else if (yNDim > 1) {\n              const dims = [yNDim - 1].concat(mathUtils.range(0, yNDim - 1));\n              y = tfc.transpose(y, dims);\n            }\n          }\n\n          return y;\n        }\n      } else {\n        return this.mergeFunction(inputs);\n      }\n    });\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = inputShape;\n    let outputShape;\n\n    if (inputShape[0] == null) {\n      outputShape = null;\n    } else {\n      outputShape = inputShape[0].slice(1);\n    }\n\n    for (let i = 1; i < inputShape.length; ++i) {\n      const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n      outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n    }\n\n    let batchSizes = [];\n\n    for (const shape of inputShape) {\n      if (shape != null && shape[0] !== null) {\n        batchSizes.push(shape[0]);\n      }\n    }\n\n    batchSizes = generic_utils.unique(batchSizes);\n\n    if (batchSizes.length === 1) {\n      outputShape = batchSizes.concat(outputShape);\n    } else {\n      outputShape = [null].concat(outputShape);\n    }\n\n    return outputShape;\n  }\n\n  computeMask(inputs, mask) {\n    return tfc.tidy(() => {\n      if (mask == null) {\n        return null;\n      }\n\n      if (!Array.isArray(mask)) {\n        throw new ValueError('`mask` should be an Array');\n      }\n\n      if (!Array.isArray(inputs)) {\n        throw new ValueError('`inputs` should be an Array');\n      }\n\n      if (mask.length !== inputs.length) {\n        throw new ValueError(`The Array 'inputs' and 'mask' are expected to have the same ` + `length, but have different lengths ` + `(${inputs.length} vs ${mask.length})`);\n      }\n\n      if (mask.every(m => m == null)) {\n        return null;\n      }\n\n      mask = mask.map(m => m == null ? m : tfc.expandDims(m, 0));\n      let output = mask[0];\n\n      for (let i = 1; i < mask.length - 1; ++i) {\n        output = tfc.logicalAnd(output, mask[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\nexport class Add extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0].clone();\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.add(output, inputs[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nAdd.className = 'Add';\nserialization.registerClass(Add);\n/**\n * Calculate the element-wise sum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Add` layer, by using no input argument\n *    or a single configuration argument. The resultant `Add` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const addLayer = tf.layers.add();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = addLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.add([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.add([input1, input2]).print();\n * // Gives [[11, 22], [33, 44]].\n *\n */\n\nexport function add(config) {\n  if (Array.isArray(config)) {\n    const layer = new Add({});\n    return layer.apply(config);\n  } else {\n    return new Add(config);\n  }\n}\nexport class Multiply extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0].clone();\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.mul(output, inputs[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nMultiply.className = 'Multiply';\nserialization.registerClass(Multiply);\n/**\n * Calculate the element-wise product of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Multiply` layer, by using no input argument\n *    or a single configuration argument. The resultant `Multiply` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const multiplyLayer = tf.layers.multiply();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = multiplyLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.multiply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.multiply([input1, input2]).print();\n * // Gives [[10, 40], [90, 160]].\n *\n */\n\nexport function multiply(config) {\n  if (Array.isArray(config)) {\n    const layer = new Multiply({});\n    return layer.apply(config);\n  } else {\n    return new Multiply(config);\n  }\n}\nexport class Average extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0].clone();\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.add(output, inputs[i]);\n      }\n\n      return tfc.mul(1 / inputs.length, output);\n    });\n  }\n\n}\n/** @nocollapse */\n\nAverage.className = 'Average';\nserialization.registerClass(Average);\n/**\n * Calculate the element-wise arithmetic mean of inputs, which all have the same\n * shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Average` layer, by using no input argument\n *    or a single configuration argument. The resultant `Average` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const averageLayer = tf.layers.average();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = averageLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.average([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.average([input1, input2]).print();\n * // Gives [[5.5, 11], [16.5, 22]].\n *\n */\n\nexport function average(config) {\n  if (Array.isArray(config)) {\n    const layer = new Average({});\n    return layer.apply(config);\n  } else {\n    return new Average(config);\n  }\n}\nexport class Maximum extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0];\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.maximum(output, inputs[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nMaximum.className = 'Maximum';\nserialization.registerClass(Maximum);\n/**\n * Calculate the element-wise maximum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Maximum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Maximum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const maximumLayer = tf.layers.maximum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = maximumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.maximum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.maximum([input1, input2]).print();\n * // Gives [[10, 20], [30, 40]].\n *\n */\n\nexport function maximum(config) {\n  if (Array.isArray(config)) {\n    const layer = new Maximum({});\n    return layer.apply(config);\n  } else {\n    return new Maximum(config);\n  }\n}\nexport class Minimum extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0];\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.minimum(output, inputs[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nMinimum.className = 'Minimum';\nserialization.registerClass(Minimum);\n/**\n * Calculate the element-wise minimum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Minimum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Minimum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const minimumLayer = tf.layers.minimum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = minimumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.minimum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.minimum([input1, input2]).print();\n * // Gives [[1, 2], [3, 4]].\n *\n */\n\nexport function minimum(config) {\n  if (Array.isArray(config)) {\n    const layer = new Minimum({});\n    return layer.apply(config);\n  } else {\n    return new Minimum(config);\n  }\n}\nexport class Concatenate extends Merge {\n  constructor(args) {\n    super(args);\n    this.DEFAULT_AXIS = -1;\n\n    if (args == null) {\n      args = {};\n    }\n\n    this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;\n    this.supportsMasking = true;\n    this.reshapeRequired = false;\n  }\n\n  build(inputShape) {\n    // Used purely for shape validation.]\n    if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0])) || inputShape.length === 1) {\n      throw new ValueError('A `Concatenate` layer should be called on a list of at least 2 ' + 'inputs');\n    }\n\n    inputShape = inputShape;\n    let allNoneShape = true;\n\n    for (const shape of inputShape) {\n      if (shape != null) {\n        allNoneShape = false;\n        break;\n      }\n    }\n\n    if (allNoneShape) {\n      return;\n    }\n\n    const shapeSet = [];\n\n    for (let i = 0; i < inputShape.length; ++i) {\n      const shapeWithoutConcatAxis = inputShape[i].slice();\n      shapeWithoutConcatAxis.splice(this.axis, 1);\n      let exists = false;\n\n      for (const shape of shapeSet) {\n        if (util.arraysEqual(shape, shapeWithoutConcatAxis)) {\n          exists = true;\n          break;\n        }\n      }\n\n      if (!exists) {\n        shapeSet.push(shapeWithoutConcatAxis);\n      }\n    }\n\n    if (shapeSet.length > 1) {\n      throw new ValueError('A `Concatenate` layer requires inputs with matching shapes ' + 'except for the concat axis. Got input shapes: ' + JSON.stringify(inputShape));\n    }\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      return K.concatenate(inputs, this.axis);\n    });\n  }\n\n  computeOutputShape(inputShape) {\n    if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0]))) {\n      throw new ValueError('A `Concatenate` layer should be called on a list of inputs.');\n    }\n\n    const inputShapes = inputShape;\n    const outputShape = inputShapes[0].slice();\n    const axis = this.axis < 0 ? outputShape.length + this.axis : this.axis; // Porting Note: the line above is because TypeScript doesn't support\n    //   negative indices.\n\n    for (const shape of inputShapes.slice(1)) {\n      if (outputShape[axis] == null || shape[axis] == null) {\n        outputShape[axis] = null;\n        break;\n      }\n\n      outputShape[axis] += shape[axis];\n    }\n\n    return outputShape;\n  }\n\n  computeMask(inputs, mask) {\n    if (mask == null) {\n      return null;\n    }\n\n    if (!Array.isArray(mask)) {\n      throw new ValueError('`mask` should be an array for Concatenate');\n    }\n\n    if (!Array.isArray(inputs)) {\n      throw new ValueError('`inputs` should be an array for Concatenate');\n    }\n\n    if (mask.length !== inputs.length) {\n      throw new ValueError(`Mismatch in the length of mask (${mask.length}) ` + `and the legnth of inputs (${inputs.length})`);\n    }\n\n    return tfc.tidy(() => {\n      let allNullMasks = true;\n      mask.forEach(m => {\n        if (m != null) {\n          allNullMasks = false;\n          return;\n        }\n      });\n\n      if (allNullMasks) {\n        return null;\n      }\n\n      const outputMasks = [];\n\n      for (let i = 0; i < inputs.length; ++i) {\n        if (mask[i] == null) {\n          // Input is unmasked. Append all 1's to masks.\n          outputMasks.push(tfc.cast(tfc.onesLike(inputs[i]), 'bool'));\n        } else if (mask[i].rank < inputs[i].rank) {\n          // Mask is smaller than the input, expand it.\n          outputMasks.push(tfc.expandDims(mask[i], -1));\n        } else {\n          outputMasks.push(mask[i]);\n        }\n      }\n\n      const concatenatedMasks = tfc.concat(outputMasks, this.axis);\n      return tfc.all(concatenatedMasks, -1, false);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      'axis': this.axis\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nConcatenate.className = 'Concatenate';\nserialization.registerClass(Concatenate);\n/**\n * Concatenate an `Array` of inputs.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Concatenate` layer, by using no input argument\n *    or a single configuration argument. The resultant `Concatenate` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const concatLayer = tf.layers.concatenate();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = concatLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 7], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = tf.layers.concatenate([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([[1, 2], [3, 4]], [2, 2]);\n * const input2 = tf.tensor2d([[10, 20], [30, 40]], [2, 2]);\n * tf.layers.concatenate([input1, input2]).print();\n * // Gives [[1, 2, 10, 20], [3, 4, 30, 40]].\n *\n */\n\nexport function concatenate(config) {\n  if (Array.isArray(config)) {\n    const layer = new Concatenate({});\n    return layer.apply(config);\n  } else {\n    return new Concatenate(config);\n  }\n}\n/**\n * Interpretable potentially negative axis index.\n *\n * For example, given axis = -1, and dim = 3, this function will return 2.\n *\n * @param axis The axis index, may be a positive, zero or negative integer.\n * @param dim Total number of dimensions, a positive integer.\n * @returns A non-negative axis index equivalent to the input `axis`.\n */\n\nfunction interpretAxis(axis, dim) {\n  while (axis < 0) {\n    axis += dim;\n  }\n\n  return axis;\n}\n\nfunction batchDot(x, y, axes) {\n  if (x.shape.length > 3 || y.shape.length > 3) {\n    throw new NotImplementedError('batchDot is not implemented for tensors of 4D or higher rank yet');\n  }\n\n  tfc.util.assert(x.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, ` + `but got ${x.shape.length}`);\n  tfc.util.assert(x.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, ` + `but got ${y.shape.length}`);\n\n  if (typeof axes === 'number') {\n    axes = [axes, axes];\n  }\n\n  if (x.dtype === 'complex64' || y.dtype === 'complex64') {\n    throw new NotImplementedError('batchDot is not implemented for complex64-type Tensors yet.');\n  }\n\n  const xNDim = x.shape.length;\n  const yNDim = y.shape.length;\n\n  if (axes == null) {\n    // Behave like batchMatmul by default.\n    axes = [xNDim - 1, yNDim - 2];\n  }\n\n  const axesArray = axes;\n  return tfc.tidy(() => {\n    let diff;\n\n    if (xNDim > yNDim) {\n      diff = xNDim - yNDim;\n      const diffShape = [];\n\n      for (let i = 0; i < diff; ++i) {\n        diffShape.push(1);\n      }\n\n      y = tfc.reshape(y, y.shape.concat(diffShape));\n    } else if (yNDim > xNDim) {\n      diff = yNDim - xNDim;\n      const diffShape = [];\n\n      for (let i = 0; i < diff; ++i) {\n        diffShape.push(1);\n      }\n\n      x = tfc.reshape(x, x.shape.concat(diffShape));\n    } else {\n      diff = 0;\n    }\n\n    let out;\n\n    if (x.shape.length === 2 && y.shape.length === 2) {\n      if (axesArray[0] === axesArray[1]) {\n        out = tfc.sum(tfc.mul(x, y), axesArray[0]);\n      } else {\n        out = tfc.sum(tfc.mul(tfc.transpose(x, [1, 0]), y), axesArray[1]);\n      }\n    } else {\n      const adjX = axesArray[0] !== x.shape.length - 1;\n      const adjY = axesArray[1] === y.shape.length - 1;\n      out = tfc.matMul(x, y, adjX, adjY);\n    }\n\n    if (diff > 0) {\n      let idx;\n\n      if (xNDim > yNDim) {\n        idx = xNDim + yNDim - 3;\n      } else {\n        idx = xNDim - 1;\n      }\n\n      const squeezeAxes = [];\n\n      for (let i = idx; i < idx + diff; ++i) {\n        squeezeAxes.push(i);\n      }\n\n      out = tfc.squeeze(out, squeezeAxes);\n    }\n\n    if (out.shape.length === 1) {\n      out = tfc.expandDims(out, 1);\n    }\n\n    return out;\n  });\n}\n\nexport class Dot extends Merge {\n  constructor(args) {\n    super(args);\n    this.axes = args.axes;\n    this.normalize = args.normalize == null ? false : args.normalize;\n    this.supportsMasking = true;\n    this.reshapeRequired = false;\n  }\n\n  build(inputShape) {\n    tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n    const shape1 = inputShape[0];\n    const shape2 = inputShape[1];\n\n    if (shape1.length > 3 || shape2.length > 3) {\n      throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n    }\n\n    const axes = this.interpretAxes(shape1, shape2);\n\n    if (shape1[axes[0]] !== shape2[axes[1]]) {\n      throw new ValueError(`Dimension incompatibility: ` + `${shape1[axes[0]]} !== ${shape2[axes[1]]}`);\n    }\n  }\n\n  mergeFunction(inputs) {\n    if (inputs.length !== 2) {\n      throw new ValueError('A `Dot` layer must be called on exactly 2 inputs, ' + `but received ${inputs.length} input(s).`);\n    }\n\n    let x1 = inputs[0];\n    let x2 = inputs[1];\n    let axes;\n\n    if (!Array.isArray(this.axes)) {\n      axes = [interpretAxis(this.axes, x1.shape.length), interpretAxis(this.axes, x2.shape.length)];\n    } else {\n      axes = this.axes.map((axis, i) => interpretAxis(axis, inputs[i].shape.length));\n    }\n\n    if (this.normalize) {\n      x1 = l2Normalize(x1, axes[0]);\n      x2 = l2Normalize(x2, axes[1]);\n    }\n\n    return batchDot(x1, x2, axes);\n  }\n\n  interpretAxes(shape1, shape2) {\n    let axes;\n\n    if (!Array.isArray(this.axes)) {\n      // `this.axes` is a single integer.\n      axes = [interpretAxis(this.axes, shape1.length), interpretAxis(this.axes, shape2.length)];\n    } else {\n      // `this.axes` is an Array of integers.\n      axes = this.axes;\n    }\n\n    return axes;\n  }\n\n  computeOutputShape(inputShape) {\n    tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n    const shape1 = inputShape[0].slice();\n    const shape2 = inputShape[1].slice();\n\n    if (shape1.length > 3 || shape2.length > 3) {\n      throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n    }\n\n    const axes = this.interpretAxes(shape1, shape2);\n    shape1.splice(axes[0], 1);\n    shape2.splice(axes[1], 1);\n    shape2.splice(0, 1);\n    const outputShape = shape1.concat(shape2);\n\n    if (outputShape.length === 1) {\n      outputShape.push(1);\n    }\n\n    return outputShape;\n  }\n\n  computeMask(inputs, mask) {\n    return null;\n  }\n\n  getConfig() {\n    const config = {\n      'axes': this.axes,\n      'normalize': this.normalize\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nDot.className = 'Dot';\nserialization.registerClass(Dot); // TODO(cais): Add functional interfaces for the merge layers.","map":{"version":3,"sources":["../../../../../../tfjs-layers/src/layers/merge.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;;AAEH;;AAEG;AAEH,OAAO,KAAK,GAAZ,MAAqB,uBAArB;AACA,SAAQ,aAAR,EAA+B,IAA/B,EAAqC,IAArC,QAAgD,uBAAhD;AACA,OAAO,KAAK,CAAZ,MAAmB,yBAAnB;AACA,SAAQ,KAAR,QAA+C,oBAA/C;AACA,SAAQ,mBAAR,EAA6B,UAA7B,QAA8C,WAA9C;AAEA,SAAQ,WAAR,QAA0B,WAA1B;AAEA,OAAO,KAAK,aAAZ,MAA+B,wBAA/B;AACA,OAAO,KAAK,SAAZ,MAA2B,qBAA3B;AACA,SAAQ,kBAAR,QAAiC,sBAAjC;AAEA;;;;AAIG;;AACH,OAAM,MAAgB,KAAhB,SAA8B,KAA9B,CAAmC;EAGvC,WAAA,CAAY,IAAZ,EAA4B;IAC1B,MAAM,IAAI,IAAI,EAAd;IACA,KAAK,eAAL,GAAuB,IAAvB;EACD;EAED;;;AAGG;;;EACO,aAAa,CAAC,MAAD,EAAiB;IACtC,MAAM,IAAI,mBAAJ,EAAN;EACD;EAED;;;;;;;;;AASG;;;EACK,+BAA+B,CAAC,MAAD,EAAgB,MAAhB,EAA6B;IAClE,IAAI,MAAM,IAAI,IAAV,IAAkB,MAAM,IAAI,IAAhC,EAAsC;MACpC,OAAO,IAAP;IACD,CAFD,MAEO,IAAI,MAAM,CAAC,MAAP,GAAgB,MAAM,CAAC,MAA3B,EAAmC;MACxC,OAAO,KAAK,+BAAL,CAAqC,MAArC,EAA6C,MAA7C,CAAP;IACD,CAFM,MAEA,IAAI,MAAM,CAAC,MAAP,KAAkB,CAAtB,EAAyB;MAC9B,OAAO,MAAP;IACD;;IACD,MAAM,WAAW,GAAU,MAAM,CAAC,KAAP,CAAa,CAAb,EAAgB,MAAM,CAAC,MAAP,GAAgB,MAAM,CAAC,MAAvC,CAA3B;;IACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;MACtC,MAAM,CAAC,GAAG,MAAM,CAAC,MAAM,CAAC,MAAP,GAAgB,MAAM,CAAC,MAAvB,GAAgC,CAAjC,CAAhB;MACA,MAAM,CAAC,GAAG,MAAM,CAAC,CAAD,CAAhB;;MACA,IAAI,CAAC,IAAI,IAAL,IAAa,CAAC,IAAI,IAAlB,IAA0B,CAAC,GAAG,CAA9B,IAAmC,CAAC,GAAG,CAA3C,EAA8C;QAC5C,WAAW,CAAC,IAAZ,CAAiB,IAAjB;MACD,CAFD,MAEO,IAAI,CAAC,KAAK,CAAV,EAAa;QAClB,WAAW,CAAC,IAAZ,CAAiB,CAAjB;MACD,CAFM,MAEA,IAAI,CAAC,KAAK,CAAV,EAAa;QAClB,WAAW,CAAC,IAAZ,CAAiB,CAAjB;MACD,CAFM,MAEA;QACL,IAAI,CAAC,KAAK,CAAV,EAAa;UACX,MAAM,IAAI,UAAJ,CACF,0DACA,IAAI,CAAC,SAAL,CAAe,MAAf,CADA,GACyB,GADzB,GAC+B,IAAI,CAAC,SAAL,CAAe,MAAf,CAF7B,CAAN;QAGD;;QACD,WAAW,CAAC,IAAZ,CAAiB,CAAjB;MACD;IACF;;IACD,OAAO,WAAP;EACD;;EAED,KAAK,CAAC,UAAD,EAA0B;IAC7B;IACA,IAAI,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,CAAC,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAAlC,EAAgE;MAC9D;MACA,UAAU,GAAG,CAAC,kBAAkB,CAAC,UAAD,CAAnB,CAAb;IACD;;IACD,UAAU,GAAG,UAAb;;IACA,IAAI,UAAU,CAAC,MAAX,GAAoB,CAAxB,EAA2B;MACzB,MAAM,IAAI,UAAJ,CACF,qEACA,QAAQ,UAAU,CAAC,MAAM,YAFvB,CAAN;IAGD,CAX4B,CAa7B;IACA;;;IACA,IAAI,UAAU,GAAa,EAA3B;;IACA,KAAK,MAAM,KAAX,IAAoB,UAApB,EAAgC;MAC9B,IAAI,KAAK,IAAI,IAAT,IAAiB,KAAK,CAAC,CAAD,CAAL,KAAa,IAAlC,EAAwC;QACtC,UAAU,CAAC,IAAX,CAAgB,KAAK,CAAC,CAAD,CAArB;MACD;IACF;;IACD,UAAU,GAAG,aAAa,CAAC,MAAd,CAAqB,UAArB,CAAb;;IACA,IAAI,UAAU,CAAC,MAAX,GAAoB,CAAxB,EAA2B;MACzB,MAAM,IAAI,UAAJ,CACF,oDAAA,GACA,4BAA4B,IAAI,CAAC,SAAL,CAAe,UAAf,CAA0B,GAFpD,CAAN;IAGD;;IAED,IAAI,WAAW,GACX,UAAU,CAAC,CAAD,CAAV,IAAiB,IAAjB,GAAwB,IAAxB,GAA+B,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,CAAoB,CAApB,CADnC;;IAEA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAAU,CAAC,MAA/B,EAAuC,EAAE,CAAzC,EAA4C;MAC1C,MAAM,KAAK,GAAG,UAAU,CAAC,CAAD,CAAV,IAAiB,IAAjB,GAAwB,IAAxB,GAA+B,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,CAAoB,CAApB,CAA7C;MACA,WAAW,GAAG,KAAK,+BAAL,CAAqC,WAArC,EAAkD,KAAlD,CAAd;IACD,CAjC4B,CAkC7B;IACA;;;IACA,MAAM,QAAQ,GAAG,UAAU,CAAC,GAAX,CAAe,KAAK,IAAI,KAAK,CAAC,MAA9B,CAAjB;;IACA,IAAI,UAAU,CAAC,OAAX,CAAmB,IAAnB,MAA6B,CAAC,CAA9B,IACA,aAAa,CAAC,MAAd,CAAqB,QAArB,EAA+B,MAA/B,KAA0C,CAD9C,EACiD;MAC/C,KAAK,eAAL,GAAuB,KAAvB;IACD,CAHD,MAGO;MACL,KAAK,eAAL,GAAuB,IAAvB;IACD;EACF;;EAED,IAAI,CAAC,MAAD,EAA0B,MAA1B,EAAwC;IAC1C,OAAO,IAAI,CAAC,MAAK;MACf,MAAM,GAAG,MAAT;;MACA,IAAI,KAAK,eAAT,EAA0B;QACxB,MAAM,cAAc,GAAa,EAAjC;QACA,MAAM,SAAS,GAAG,MAAM,CAAC,GAAP,CAAW,KAAK,IAAI,KAAK,CAAC,IAA1B,CAAlB;;QACA,IAAI,SAAS,CAAC,OAAV,CAAkB,IAAlB,MAA4B,CAAC,CAAjC,EAAoC;UAClC;UACA;UACA,MAAM,OAAO,GAAG,SAAS,CAAC,GAAV,CAAc,SAAd,CAAhB;;UACA,KAAK,IAAI,CAAT,IAAc,MAAd,EAAsB;YACpB,MAAM,KAAK,GAAG,CAAC,CAAC,IAAhB;;YACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAO,GAAG,KAA9B,EAAqC,EAAE,CAAvC,EAA0C;cACxC,CAAC,GAAG,CAAC,CAAC,UAAF,CAAa,CAAb,EAAgB,CAAhB,CAAJ;YACD;;YACD,cAAc,CAAC,IAAf,CAAoB,CAApB;UACD;;UACD,OAAO,KAAK,aAAL,CAAmB,cAAnB,CAAP;QACD,CAZD,MAYO;UACL;UACA;UACA,IAAI,UAAU,GAAG,KAAjB;;UACA,KAAK,MAAM,CAAX,IAAgB,MAAhB,EAAwB;YACtB,MAAM,KAAK,GAAG,CAAC,CAAC,IAAhB;;YACA,IAAI,KAAK,IAAI,IAAb,EAAmB;cACjB,MAAM,MAAM,GAAG,CAAC,CAAC,KAAjB;cACA,MAAM,SAAS,GAAG,MAAM,CAAC,CAAD,CAAxB;cACA,MAAM,QAAQ,GAAG,MAAM,CAAC,KAAP,CAAa,CAAb,EAAgB,MAAhB,CAAuB,CAAC,SAAD,CAAvB,CAAjB;cACA,IAAI,WAAW,GAAG,GAAG,CAAC,OAAJ,CACd,CADc,EACX,CAAC,SAAD,EAAY,MAAZ,CAAmB,SAAS,CAAC,SAAV,CAAoB,MAAM,CAAC,KAAP,CAAa,CAAb,CAApB,CAAnB,CADW,CAAlB;cAEA,WAAW,GAAG,GAAG,CAAC,SAAJ,CAAc,WAAd,EAA2B,CAAC,CAAD,EAAI,CAAJ,CAA3B,CAAd;cACA,WAAW,GAAG,GAAG,CAAC,OAAJ,CAAY,WAAZ,EAAyB,QAAzB,CAAd;cACA,cAAc,CAAC,IAAf,CAAoB,WAApB;cACA,UAAU,GAAG,IAAb;YACD,CAVD,MAUO,IAAI,KAAK,GAAG,CAAZ,EAAe;cACpB,MAAM,IAAI,GAAG,SAAS,CAAC,KAAV,CAAgB,CAAhB,EAAmB,KAAnB,EAA0B,MAA1B,CAAiC,CAAC,CAAD,CAAjC,CAAb;cACA,cAAc,CAAC,IAAf,CAAoB,GAAG,CAAC,SAAJ,CAAc,CAAd,EAAiB,IAAjB,CAApB;cACA,UAAU,GAAG,IAAb;YACD,CAJM,MAIA;cACL;cACA,cAAc,CAAC,IAAf,CAAoB,CAApB;YACD;UACF;;UACD,IAAI,CAAC,GAAG,KAAK,aAAL,CAAmB,cAAnB,CAAR;UACA,MAAM,KAAK,GAAG,CAAC,CAAC,IAAhB;;UACA,IAAI,UAAJ,EAAgB;YACd;YACA;YACA,IAAI,KAAK,IAAI,IAAb,EAAmB;cACjB,MAAM,MAAM,GAAG,CAAC,CAAC,KAAjB;cACA,MAAM,KAAK,GAAG,MAAM,CAAC,MAArB;cACA,MAAM,SAAS,GAAG,MAAM,CAAC,KAAK,GAAG,CAAT,CAAxB;cACA,MAAM,QAAQ,GACV,CAAC,SAAD,EAAY,MAAZ,CAAmB,MAAM,CAAC,KAAP,CAAa,CAAb,EAAgB,MAAM,CAAC,MAAP,GAAgB,CAAhC,CAAnB,CADJ;cAEA,CAAC,GAAG,GAAG,CAAC,OAAJ,CACA,GAAG,CAAC,SAAJ,CAAc,GAAG,CAAC,OAAJ,CAAY,CAAZ,EAAe,CAAC,CAAC,CAAF,EAAK,SAAL,CAAf,CAAd,EAA+C,CAAC,CAAD,EAAI,CAAJ,CAA/C,CADA,EAEA,QAFA,CAAJ;YAGD,CATD,MASO,IAAI,KAAK,GAAG,CAAZ,EAAe;cACpB,MAAM,IAAI,GAAG,CAAC,KAAK,GAAG,CAAT,EAAY,MAAZ,CAAmB,SAAS,CAAC,KAAV,CAAgB,CAAhB,EAAmB,KAAK,GAAG,CAA3B,CAAnB,CAAb;cACA,CAAC,GAAG,GAAG,CAAC,SAAJ,CAAc,CAAd,EAAiB,IAAjB,CAAJ;YACD;UACF;;UACD,OAAO,CAAP;QACD;MACF,CA7DD,MA6DO;QACL,OAAO,KAAK,aAAL,CAAmB,MAAnB,CAAP;MACD;IACF,CAlEU,CAAX;EAmED;;EAED,kBAAkB,CAAC,UAAD,EAA0B;IAC1C,UAAU,GAAG,UAAb;IACA,IAAI,WAAJ;;IACA,IAAI,UAAU,CAAC,CAAD,CAAV,IAAiB,IAArB,EAA2B;MACzB,WAAW,GAAG,IAAd;IACD,CAFD,MAEO;MACL,WAAW,GAAG,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,CAAoB,CAApB,CAAd;IACD;;IACD,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAAU,CAAC,MAA/B,EAAuC,EAAE,CAAzC,EAA4C;MAC1C,MAAM,KAAK,GAAG,UAAU,CAAC,CAAD,CAAV,IAAiB,IAAjB,GAAwB,IAAxB,GAA+B,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,CAAoB,CAApB,CAA7C;MACA,WAAW,GAAG,KAAK,+BAAL,CAAqC,WAArC,EAAkD,KAAlD,CAAd;IACD;;IAED,IAAI,UAAU,GAAa,EAA3B;;IACA,KAAK,MAAM,KAAX,IAAoB,UAApB,EAAgC;MAC9B,IAAI,KAAK,IAAI,IAAT,IAAiB,KAAK,CAAC,CAAD,CAAL,KAAa,IAAlC,EAAwC;QACtC,UAAU,CAAC,IAAX,CAAgB,KAAK,CAAC,CAAD,CAArB;MACD;IACF;;IACD,UAAU,GAAG,aAAa,CAAC,MAAd,CAAqB,UAArB,CAAb;;IACA,IAAI,UAAU,CAAC,MAAX,KAAsB,CAA1B,EAA6B;MAC3B,WAAW,GAAG,UAAU,CAAC,MAAX,CAAkB,WAAlB,CAAd;IACD,CAFD,MAEO;MACL,WAAW,GAAG,CAAC,IAAD,EAAO,MAAP,CAAc,WAAd,CAAd;IACD;;IACD,OAAO,WAAP;EACD;;EAED,WAAW,CAAC,MAAD,EAA0B,IAA1B,EAAgD;IACzD,OAAO,GAAG,CAAC,IAAJ,CAAS,MAAK;MACnB,IAAI,IAAI,IAAI,IAAZ,EAAkB;QAChB,OAAO,IAAP;MACD;;MACD,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,IAAd,CAAL,EAA0B;QACxB,MAAM,IAAI,UAAJ,CAAe,2BAAf,CAAN;MACD;;MACD,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,MAAd,CAAL,EAA4B;QAC1B,MAAM,IAAI,UAAJ,CAAe,6BAAf,CAAN;MACD;;MACD,IAAI,IAAI,CAAC,MAAL,KAAgB,MAAM,CAAC,MAA3B,EAAmC;QACjC,MAAM,IAAI,UAAJ,CACF,8DAAA,GACA,qCADA,GAEA,IAAI,MAAM,CAAC,MAAM,OAAO,IAAI,CAAC,MAAM,GAHjC,CAAN;MAID;;MACD,IAAI,IAAI,CAAC,KAAL,CAAW,CAAC,IAAI,CAAC,IAAI,IAArB,CAAJ,EAAgC;QAC9B,OAAO,IAAP;MACD;;MACD,IAAI,GAAG,IAAI,CAAC,GAAL,CAAS,CAAC,IAAI,CAAC,IAAI,IAAL,GAAY,CAAZ,GAAgB,GAAG,CAAC,UAAJ,CAAe,CAAf,EAAkB,CAAlB,CAA9B,CAAP;MACA,IAAI,MAAM,GAAG,IAAI,CAAC,CAAD,CAAjB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,IAAI,CAAC,MAAL,GAAc,CAAlC,EAAqC,EAAE,CAAvC,EAA0C;QACxC,MAAM,GAAG,GAAG,CAAC,UAAJ,CAAe,MAAf,EAAuB,IAAI,CAAC,CAAD,CAA3B,CAAT;MACD;;MACD,OAAO,MAAP;IACD,CAzBM,CAAP;EA0BD;;AAlOsC;AAqOzC,OAAM,MAAO,GAAP,SAAmB,KAAnB,CAAwB;EAG5B,WAAA,CAAY,IAAZ,EAA4B;IAC1B,MAAM,IAAN;EACD;;EAES,aAAa,CAAC,MAAD,EAAiB;IACtC,OAAO,IAAI,CAAC,MAAK;MACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,EAAb;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;QACtC,MAAM,GAAG,GAAG,CAAC,GAAJ,CAAQ,MAAR,EAAgB,MAAM,CAAC,CAAD,CAAtB,CAAT;MACD;;MACD,OAAO,MAAP;IACD,CANU,CAAX;EAOD;;AAf2B;AAC5B;;AACO,GAAA,CAAA,SAAA,GAAY,KAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,GAA5B;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6CG;;AACH,OAAM,SAAU,GAAV,CAAc,MAAd,EAA0D;EAE9D,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,MAAM,KAAK,GAAG,IAAI,GAAJ,CAAQ,EAAR,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,GAAJ,CAAQ,MAAR,CAAP;EACD;AACF;AAED,OAAM,MAAO,QAAP,SAAwB,KAAxB,CAA6B;EAGjC,WAAA,CAAY,IAAZ,EAA4B;IAC1B,MAAM,IAAN;EACD;;EAES,aAAa,CAAC,MAAD,EAAiB;IACtC,OAAO,IAAI,CAAC,MAAK;MACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,EAAb;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;QACtC,MAAM,GAAG,GAAG,CAAC,GAAJ,CAAQ,MAAR,EAAgB,MAAM,CAAC,CAAD,CAAtB,CAAT;MACD;;MACD,OAAO,MAAP;IACD,CANU,CAAX;EAOD;;AAfgC;AACjC;;AACO,QAAA,CAAA,SAAA,GAAY,UAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,QAA5B;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6CG;;AACH,OAAM,SAAU,QAAV,CAAmB,MAAnB,EAA+D;EAEnE,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,MAAM,KAAK,GAAG,IAAI,QAAJ,CAAa,EAAb,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,QAAJ,CAAa,MAAb,CAAP;EACD;AACF;AAED,OAAM,MAAO,OAAP,SAAuB,KAAvB,CAA4B;EAGhC,WAAA,CAAY,IAAZ,EAA4B;IAC1B,MAAM,IAAN;EACD;;EAES,aAAa,CAAC,MAAD,EAAiB;IACtC,OAAO,IAAI,CAAC,MAAK;MACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,EAAb;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;QACtC,MAAM,GAAG,GAAG,CAAC,GAAJ,CAAQ,MAAR,EAAgB,MAAM,CAAC,CAAD,CAAtB,CAAT;MACD;;MACD,OAAO,GAAG,CAAC,GAAJ,CAAQ,IAAI,MAAM,CAAC,MAAnB,EAA2B,MAA3B,CAAP;IACD,CANU,CAAX;EAOD;;AAf+B;AAChC;;AACO,OAAA,CAAA,SAAA,GAAY,SAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8CG;;AACH,OAAM,SAAU,OAAV,CAAkB,MAAlB,EAA8D;EAElE,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,MAAM,KAAK,GAAG,IAAI,OAAJ,CAAY,EAAZ,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,OAAJ,CAAY,MAAZ,CAAP;EACD;AACF;AAED,OAAM,MAAO,OAAP,SAAuB,KAAvB,CAA4B;EAGhC,WAAA,CAAY,IAAZ,EAA4B;IAC1B,MAAM,IAAN;EACD;;EAES,aAAa,CAAC,MAAD,EAAiB;IACtC,OAAO,IAAI,CAAC,MAAK;MACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAnB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;QACtC,MAAM,GAAG,GAAG,CAAC,OAAJ,CAAY,MAAZ,EAAoB,MAAM,CAAC,CAAD,CAA1B,CAAT;MACD;;MACD,OAAO,MAAP;IACD,CANU,CAAX;EAOD;;AAf+B;AAChC;;AACO,OAAA,CAAA,SAAA,GAAY,SAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6CG;;AACH,OAAM,SAAU,OAAV,CAAkB,MAAlB,EAA8D;EAElE,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,MAAM,KAAK,GAAG,IAAI,OAAJ,CAAY,EAAZ,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,OAAJ,CAAY,MAAZ,CAAP;EACD;AACF;AAED,OAAM,MAAO,OAAP,SAAuB,KAAvB,CAA4B;EAGhC,WAAA,CAAY,IAAZ,EAA4B;IAC1B,MAAM,IAAN;EACD;;EAES,aAAa,CAAC,MAAD,EAAiB;IACtC,OAAO,IAAI,CAAC,MAAK;MACf,IAAI,MAAM,GAAG,MAAM,CAAC,CAAD,CAAnB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;QACtC,MAAM,GAAG,GAAG,CAAC,OAAJ,CAAY,MAAZ,EAAoB,MAAM,CAAC,CAAD,CAA1B,CAAT;MACD;;MACD,OAAO,MAAP;IACD,CANU,CAAX;EAOD;;AAf+B;AAChC;;AACO,OAAA,CAAA,SAAA,GAAY,SAAZ;AAeT,aAAa,CAAC,aAAd,CAA4B,OAA5B;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6CG;;AACH,OAAM,SAAU,OAAV,CAAkB,MAAlB,EAA8D;EAElE,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,MAAM,KAAK,GAAG,IAAI,OAAJ,CAAY,EAAZ,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,OAAJ,CAAY,MAAZ,CAAP;EACD;AACF;AASD,OAAM,MAAO,WAAP,SAA2B,KAA3B,CAAgC;EAMpC,WAAA,CAAY,IAAZ,EAAuC;IACrC,MAAM,IAAN;IAJO,KAAA,YAAA,GAAe,CAAC,CAAhB;;IAKP,IAAI,IAAI,IAAI,IAAZ,EAAkB;MAChB,IAAI,GAAG,EAAP;IACD;;IACD,KAAK,IAAL,GAAY,IAAI,CAAC,IAAL,IAAa,IAAb,GAAoB,KAAK,YAAzB,GAAwC,IAAI,CAAC,IAAzD;IACA,KAAK,eAAL,GAAuB,IAAvB;IACA,KAAK,eAAL,GAAuB,KAAvB;EACD;;EAED,KAAK,CAAC,UAAD,EAA0B;IAC7B;IACA,IAAI,EAAE,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAA/B,KACA,UAAU,CAAC,MAAX,KAAsB,CAD1B,EAC6B;MAC3B,MAAM,IAAI,UAAJ,CACF,oEACA,QAFE,CAAN;IAGD;;IACD,UAAU,GAAG,UAAb;IAEA,IAAI,YAAY,GAAG,IAAnB;;IACA,KAAK,MAAM,KAAX,IAAoB,UAApB,EAAgC;MAC9B,IAAI,KAAK,IAAI,IAAb,EAAmB;QACjB,YAAY,GAAG,KAAf;QACA;MACD;IACF;;IACD,IAAI,YAAJ,EAAkB;MAChB;IACD;;IAED,MAAM,QAAQ,GAAY,EAA1B;;IACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,UAAU,CAAC,MAA/B,EAAuC,EAAE,CAAzC,EAA4C;MAC1C,MAAM,sBAAsB,GAAG,UAAU,CAAC,CAAD,CAAV,CAAc,KAAd,EAA/B;MACA,sBAAsB,CAAC,MAAvB,CAA8B,KAAK,IAAnC,EAAyC,CAAzC;MACA,IAAI,MAAM,GAAG,KAAb;;MACA,KAAK,MAAM,KAAX,IAAoB,QAApB,EAA8B;QAC5B,IAAI,IAAI,CAAC,WAAL,CAAiB,KAAjB,EAAwB,sBAAxB,CAAJ,EAAqD;UACnD,MAAM,GAAG,IAAT;UACA;QACD;MACF;;MACD,IAAI,CAAC,MAAL,EAAa;QACX,QAAQ,CAAC,IAAT,CAAc,sBAAd;MACD;IACF;;IACD,IAAI,QAAQ,CAAC,MAAT,GAAkB,CAAtB,EAAyB;MACvB,MAAM,IAAI,UAAJ,CACF,gEACA,gDADA,GAEA,IAAI,CAAC,SAAL,CAAe,UAAf,CAHE,CAAN;IAID;EACF;;EAES,aAAa,CAAC,MAAD,EAAiB;IACtC,OAAO,IAAI,CAAC,MAAK;MACf,OAAO,CAAC,CAAC,WAAF,CAAc,MAAd,EAAsB,KAAK,IAA3B,CAAP;IACD,CAFU,CAAX;EAGD;;EAED,kBAAkB,CAAC,UAAD,EAA0B;IAC1C,IAAI,EAAE,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAA/B,CAAJ,EAAkE;MAChE,MAAM,IAAI,UAAJ,CACF,6DADE,CAAN;IAED;;IACD,MAAM,WAAW,GAAG,UAApB;IACA,MAAM,WAAW,GAAG,WAAW,CAAC,CAAD,CAAX,CAAe,KAAf,EAApB;IACA,MAAM,IAAI,GAAG,KAAK,IAAL,GAAY,CAAZ,GAAgB,WAAW,CAAC,MAAZ,GAAqB,KAAK,IAA1C,GAAiD,KAAK,IAAnE,CAP0C,CAQ1C;IACA;;IACA,KAAK,MAAM,KAAX,IAAoB,WAAW,CAAC,KAAZ,CAAkB,CAAlB,CAApB,EAA0C;MACxC,IAAI,WAAW,CAAC,IAAD,CAAX,IAAqB,IAArB,IAA6B,KAAK,CAAC,IAAD,CAAL,IAAe,IAAhD,EAAsD;QACpD,WAAW,CAAC,IAAD,CAAX,GAAoB,IAApB;QACA;MACD;;MACD,WAAW,CAAC,IAAD,CAAX,IAAqB,KAAK,CAAC,IAAD,CAA1B;IACD;;IACD,OAAO,WAAP;EACD;;EAED,WAAW,CAAC,MAAD,EAA0B,IAA1B,EAAgD;IACzD,IAAI,IAAI,IAAI,IAAZ,EAAkB;MAChB,OAAO,IAAP;IACD;;IACD,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,IAAd,CAAL,EAA0B;MACxB,MAAM,IAAI,UAAJ,CAAe,2CAAf,CAAN;IACD;;IACD,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,MAAd,CAAL,EAA4B;MAC1B,MAAM,IAAI,UAAJ,CAAe,6CAAf,CAAN;IACD;;IACD,IAAI,IAAI,CAAC,MAAL,KAAgB,MAAM,CAAC,MAA3B,EAAmC;MACjC,MAAM,IAAI,UAAJ,CACF,mCAAmC,IAAI,CAAC,MAAM,IAA9C,GACA,6BAA6B,MAAM,CAAC,MAAM,GAFxC,CAAN;IAGD;;IACD,OAAO,GAAG,CAAC,IAAJ,CAAS,MAAK;MACnB,IAAI,YAAY,GAAG,IAAnB;MACA,IAAI,CAAC,OAAL,CAAa,CAAC,IAAG;QACf,IAAI,CAAC,IAAI,IAAT,EAAe;UACb,YAAY,GAAG,KAAf;UACA;QACD;MACF,CALD;;MAMA,IAAI,YAAJ,EAAkB;QAChB,OAAO,IAAP;MACD;;MACD,MAAM,WAAW,GAAa,EAA9B;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,EAAE,CAArC,EAAwC;QACtC,IAAI,IAAI,CAAC,CAAD,CAAJ,IAAW,IAAf,EAAqB;UACnB;UACA,WAAW,CAAC,IAAZ,CAAiB,GAAG,CAAC,IAAJ,CAAS,GAAG,CAAC,QAAJ,CAAa,MAAM,CAAC,CAAD,CAAnB,CAAT,EAAkC,MAAlC,CAAjB;QACD,CAHD,MAGO,IAAI,IAAI,CAAC,CAAD,CAAJ,CAAQ,IAAR,GAAe,MAAM,CAAC,CAAD,CAAN,CAAU,IAA7B,EAAmC;UACxC;UACA,WAAW,CAAC,IAAZ,CAAiB,GAAG,CAAC,UAAJ,CAAe,IAAI,CAAC,CAAD,CAAnB,EAAwB,CAAC,CAAzB,CAAjB;QACD,CAHM,MAGA;UACL,WAAW,CAAC,IAAZ,CAAiB,IAAI,CAAC,CAAD,CAArB;QACD;MACF;;MACD,MAAM,iBAAiB,GAAG,GAAG,CAAC,MAAJ,CAAW,WAAX,EAAwB,KAAK,IAA7B,CAA1B;MACA,OAAO,GAAG,CAAC,GAAJ,CAAQ,iBAAR,EAA2B,CAAC,CAA5B,EAA+B,KAA/B,CAAP;IACD,CAzBM,CAAP;EA0BD;;EAED,SAAS,GAAA;IACP,MAAM,MAAM,GAA6B;MACvC,QAAQ,KAAK;IAD0B,CAAzC;IAGA,MAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;IACA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;IACA,OAAO,MAAP;EACD;;AAxImC;AACpC;;AACO,WAAA,CAAA,SAAA,GAAY,aAAZ;AAwIT,aAAa,CAAC,aAAd,CAA4B,WAA5B;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+CG;;AACH,OAAM,SAAU,WAAV,CAAsB,MAAtB,EAC0C;EAC9C,IAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;IACzB,MAAM,KAAK,GAAG,IAAI,WAAJ,CAAgB,EAAhB,CAAd;IACA,OAAO,KAAK,CAAC,KAAN,CAAY,MAAZ,CAAP;EACD,CAHD,MAGO;IACL,OAAO,IAAI,WAAJ,CAAgB,MAAhB,CAAP;EACD;AACF;AAoBD;;;;;;;;AAQG;;AACH,SAAS,aAAT,CAAuB,IAAvB,EAAqC,GAArC,EAAgD;EAC9C,OAAO,IAAI,GAAG,CAAd,EAAiB;IACf,IAAI,IAAI,GAAR;EACD;;EACD,OAAO,IAAP;AACD;;AAED,SAAS,QAAT,CAAkB,CAAlB,EAA6B,CAA7B,EAAwC,IAAxC,EAAqE;EACnE,IAAI,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAAjB,IAAsB,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAA3C,EAA8C;IAC5C,MAAM,IAAI,mBAAJ,CACF,kEADE,CAAN;EAED;;EACD,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,CAAC,CAAC,KAAF,CAAQ,MAAR,IAAkB,CADtB,EAEI,MAAM,8CAAA,GACF,WAAW,CAAC,CAAC,KAAF,CAAQ,MAAM,EAHjC;EAIA,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,CAAC,CAAC,KAAF,CAAQ,MAAR,IAAkB,CADtB,EAEI,MAAM,8CAAA,GACF,WAAW,CAAC,CAAC,KAAF,CAAQ,MAAM,EAHjC;;EAKA,IAAI,OAAO,IAAP,KAAgB,QAApB,EAA8B;IAC5B,IAAI,GAAG,CAAC,IAAD,EAAO,IAAP,CAAP;EACD;;EAED,IAAI,CAAC,CAAC,KAAF,KAAY,WAAZ,IAA2B,CAAC,CAAC,KAAF,KAAY,WAA3C,EAAwD;IACtD,MAAM,IAAI,mBAAJ,CACF,6DADE,CAAN;EAED;;EAED,MAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;EACA,MAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;;EACA,IAAI,IAAI,IAAI,IAAZ,EAAkB;IAChB;IACA,IAAI,GAAG,CAAC,KAAK,GAAG,CAAT,EAAY,KAAK,GAAG,CAApB,CAAP;EACD;;EACD,MAAM,SAAS,GAAG,IAAlB;EAEA,OAAO,GAAG,CAAC,IAAJ,CAAS,MAAK;IACnB,IAAI,IAAJ;;IACA,IAAI,KAAK,GAAG,KAAZ,EAAmB;MACjB,IAAI,GAAG,KAAK,GAAG,KAAf;MACA,MAAM,SAAS,GAAU,EAAzB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,IAApB,EAA0B,EAAE,CAA5B,EAA+B;QAC7B,SAAS,CAAC,IAAV,CAAe,CAAf;MACD;;MACD,CAAC,GAAG,GAAG,CAAC,OAAJ,CAAY,CAAZ,EAAe,CAAC,CAAC,KAAF,CAAQ,MAAR,CAAe,SAAf,CAAf,CAAJ;IACD,CAPD,MAOO,IAAI,KAAK,GAAG,KAAZ,EAAmB;MACxB,IAAI,GAAG,KAAK,GAAG,KAAf;MACA,MAAM,SAAS,GAAU,EAAzB;;MACA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,IAApB,EAA0B,EAAE,CAA5B,EAA+B;QAC7B,SAAS,CAAC,IAAV,CAAe,CAAf;MACD;;MACD,CAAC,GAAG,GAAG,CAAC,OAAJ,CAAY,CAAZ,EAAe,CAAC,CAAC,KAAF,CAAQ,MAAR,CAAe,SAAf,CAAf,CAAJ;IACD,CAPM,MAOA;MACL,IAAI,GAAG,CAAP;IACD;;IAED,IAAI,GAAJ;;IACA,IAAI,CAAC,CAAC,KAAF,CAAQ,MAAR,KAAmB,CAAnB,IAAwB,CAAC,CAAC,KAAF,CAAQ,MAAR,KAAmB,CAA/C,EAAkD;MAChD,IAAI,SAAS,CAAC,CAAD,CAAT,KAAiB,SAAS,CAAC,CAAD,CAA9B,EAAmC;QACjC,GAAG,GAAG,GAAG,CAAC,GAAJ,CAAQ,GAAG,CAAC,GAAJ,CAAQ,CAAR,EAAW,CAAX,CAAR,EAAuB,SAAS,CAAC,CAAD,CAAhC,CAAN;MACD,CAFD,MAEO;QACL,GAAG,GAAG,GAAG,CAAC,GAAJ,CAAQ,GAAG,CAAC,GAAJ,CAAQ,GAAG,CAAC,SAAJ,CAAc,CAAd,EAAiB,CAAC,CAAD,EAAI,CAAJ,CAAjB,CAAR,EAAkC,CAAlC,CAAR,EAA8C,SAAS,CAAC,CAAD,CAAvD,CAAN;MACD;IACF,CAND,MAMO;MACL,MAAM,IAAI,GAAG,SAAS,CAAC,CAAD,CAAT,KAAiB,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAA/C;MACA,MAAM,IAAI,GAAG,SAAS,CAAC,CAAD,CAAT,KAAiB,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAA/C;MACA,GAAG,GAAG,GAAG,CAAC,MAAJ,CAAW,CAAX,EAAc,CAAd,EAAiB,IAAjB,EAAuB,IAAvB,CAAN;IACD;;IAED,IAAI,IAAI,GAAG,CAAX,EAAc;MACZ,IAAI,GAAJ;;MACA,IAAI,KAAK,GAAG,KAAZ,EAAmB;QACjB,GAAG,GAAG,KAAK,GAAG,KAAR,GAAgB,CAAtB;MACD,CAFD,MAEO;QACL,GAAG,GAAG,KAAK,GAAG,CAAd;MACD;;MACD,MAAM,WAAW,GAAa,EAA9B;;MACA,KAAK,IAAI,CAAC,GAAG,GAAb,EAAkB,CAAC,GAAG,GAAG,GAAG,IAA5B,EAAkC,EAAE,CAApC,EAAuC;QACrC,WAAW,CAAC,IAAZ,CAAiB,CAAjB;MACD;;MACD,GAAG,GAAG,GAAG,CAAC,OAAJ,CAAY,GAAZ,EAAiB,WAAjB,CAAN;IACD;;IACD,IAAI,GAAG,CAAC,KAAJ,CAAU,MAAV,KAAqB,CAAzB,EAA4B;MAC1B,GAAG,GAAG,GAAG,CAAC,UAAJ,CAAe,GAAf,EAAoB,CAApB,CAAN;IACD;;IACD,OAAO,GAAP;EACD,CAlDM,CAAP;AAmDD;;AAED,OAAM,MAAO,GAAP,SAAmB,KAAnB,CAAwB;EAO5B,WAAA,CAAY,IAAZ,EAA8B;IAC5B,MAAM,IAAN;IACA,KAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;IACA,KAAK,SAAL,GAAiB,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,KAAzB,GAAiC,IAAI,CAAC,SAAvD;IACA,KAAK,eAAL,GAAuB,IAAvB;IACA,KAAK,eAAL,GAAuB,KAAvB;EACD;;EAED,KAAK,CAAC,UAAD,EAA0B;IAC7B,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,UAAU,CAAC,MAAX,KAAsB,CAAnD,IACI,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CADJ,IACoC,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAFxC,EAGI,MAAM,+DAHV;IAIA,MAAM,MAAM,GAAG,UAAU,CAAC,CAAD,CAAzB;IACA,MAAM,MAAM,GAAG,UAAU,CAAC,CAAD,CAAzB;;IACA,IAAI,MAAM,CAAC,MAAP,GAAgB,CAAhB,IAAqB,MAAM,CAAC,MAAP,GAAgB,CAAzC,EAA4C;MAC1C,MAAM,IAAI,mBAAJ,CACF,8DADE,CAAN;IAED;;IAED,MAAM,IAAI,GAAG,KAAK,aAAL,CAAmB,MAAnB,EAA2B,MAA3B,CAAb;;IACA,IAAI,MAAM,CAAC,IAAI,CAAC,CAAD,CAAL,CAAN,KAAoB,MAAM,CAAC,IAAI,CAAC,CAAD,CAAL,CAA9B,EAAyC;MACvC,MAAM,IAAI,UAAJ,CACF,6BAAA,GACA,GAAG,MAAM,CAAC,IAAI,CAAC,CAAD,CAAL,CAAS,QAAQ,MAAM,CAAC,IAAI,CAAC,CAAD,CAAL,CAAS,EAFvC,CAAN;IAGD;EACF;;EAES,aAAa,CAAC,MAAD,EAAiB;IACtC,IAAI,MAAM,CAAC,MAAP,KAAkB,CAAtB,EAAyB;MACvB,MAAM,IAAI,UAAJ,CACF,uDACA,gBAAgB,MAAM,CAAC,MAAM,YAF3B,CAAN;IAGD;;IAED,IAAI,EAAE,GAAG,MAAM,CAAC,CAAD,CAAf;IACA,IAAI,EAAE,GAAG,MAAM,CAAC,CAAD,CAAf;IACA,IAAI,IAAJ;;IACA,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,KAAK,IAAnB,CAAL,EAA+B;MAC7B,IAAI,GAAG,CACL,aAAa,CAAC,KAAK,IAAN,EAAY,EAAE,CAAC,KAAH,CAAS,MAArB,CADR,EAEL,aAAa,CAAC,KAAK,IAAN,EAAY,EAAE,CAAC,KAAH,CAAS,MAArB,CAFR,CAAP;IAID,CALD,MAKO;MACL,IAAI,GAAG,KAAK,IAAL,CAAU,GAAV,CACI,CAAC,IAAD,EAAO,CAAP,KAAa,aAAa,CACtB,IADsB,EAChB,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,MADA,CAD9B,CAAP;IAGD;;IACD,IAAI,KAAK,SAAT,EAAoB;MAClB,EAAE,GAAG,WAAW,CAAC,EAAD,EAAK,IAAI,CAAC,CAAD,CAAT,CAAhB;MACA,EAAE,GAAG,WAAW,CAAC,EAAD,EAAK,IAAI,CAAC,CAAD,CAAT,CAAhB;IACD;;IACD,OAAO,QAAQ,CAAC,EAAD,EAAK,EAAL,EAAS,IAAT,CAAf;EACD;;EAEO,aAAa,CAAC,MAAD,EAAgB,MAAhB,EAA6B;IAChD,IAAI,IAAJ;;IACA,IAAI,CAAC,KAAK,CAAC,OAAN,CAAc,KAAK,IAAnB,CAAL,EAA+B;MAC7B;MACA,IAAI,GAAG,CACL,aAAa,CAAC,KAAK,IAAN,EAAY,MAAM,CAAC,MAAnB,CADR,EAEL,aAAa,CAAC,KAAK,IAAN,EAAY,MAAM,CAAC,MAAnB,CAFR,CAAP;IAID,CAND,MAMO;MACL;MACA,IAAI,GAAG,KAAK,IAAZ;IACD;;IACD,OAAO,IAAP;EACD;;EAED,kBAAkB,CAAC,UAAD,EAA0B;IAC1C,GAAG,CAAC,IAAJ,CAAS,MAAT,CACI,KAAK,CAAC,OAAN,CAAc,UAAd,KAA6B,UAAU,CAAC,MAAX,KAAsB,CAAnD,IACI,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CADJ,IACoC,KAAK,CAAC,OAAN,CAAc,UAAU,CAAC,CAAD,CAAxB,CAFxC,EAGI,MAAM,+DAHV;IAIA,MAAM,MAAM,GAAI,UAAU,CAAC,CAAD,CAAV,CAAwB,KAAxB,EAAhB;IACA,MAAM,MAAM,GAAI,UAAU,CAAC,CAAD,CAAV,CAAwB,KAAxB,EAAhB;;IACA,IAAI,MAAM,CAAC,MAAP,GAAgB,CAAhB,IAAqB,MAAM,CAAC,MAAP,GAAgB,CAAzC,EAA4C;MAC1C,MAAM,IAAI,mBAAJ,CACF,8DADE,CAAN;IAED;;IAED,MAAM,IAAI,GAAG,KAAK,aAAL,CAAmB,MAAnB,EAA2B,MAA3B,CAAb;IACA,MAAM,CAAC,MAAP,CAAc,IAAI,CAAC,CAAD,CAAlB,EAAuB,CAAvB;IACA,MAAM,CAAC,MAAP,CAAc,IAAI,CAAC,CAAD,CAAlB,EAAuB,CAAvB;IACA,MAAM,CAAC,MAAP,CAAc,CAAd,EAAiB,CAAjB;IACA,MAAM,WAAW,GAAG,MAAM,CAAC,MAAP,CAAc,MAAd,CAApB;;IACA,IAAI,WAAW,CAAC,MAAZ,KAAuB,CAA3B,EAA8B;MAC5B,WAAW,CAAC,IAAZ,CAAiB,CAAjB;IACD;;IACD,OAAO,WAAP;EACD;;EAED,WAAW,CAAC,MAAD,EAA0B,IAA1B,EAAgD;IACzD,OAAO,IAAP;EACD;;EAED,SAAS,GAAA;IACP,MAAM,MAAM,GAA6B;MACvC,QAAQ,KAAK,IAD0B;MAEvC,aAAa,KAAK;IAFqB,CAAzC;IAIA,MAAM,UAAU,GAAG,MAAM,SAAN,EAAnB;IACA,MAAM,CAAC,MAAP,CAAc,MAAd,EAAsB,UAAtB;IACA,OAAO,MAAP;EACD;;AAhH2B;AAC5B;;AACO,GAAA,CAAA,SAAA,GAAY,KAAZ;AAgHT,aAAa,CAAC,aAAd,CAA4B,GAA5B,E,CAEA","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Merge Layers.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {serialization, Tensor, tidy, util} from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport {Layer, LayerArgs, SymbolicTensor} from '../engine/topology';\nimport {NotImplementedError, ValueError} from '../errors';\nimport {Shape} from '../keras_format/common';\nimport {l2Normalize} from '../losses';\nimport {Kwargs} from '../types';\nimport * as generic_utils from '../utils/generic_utils';\nimport * as mathUtils from '../utils/math_utils';\nimport {getExactlyOneShape} from '../utils/types_utils';\n\n/**\n * Generic Merge layer for element-wise merge functions.\n *\n * Used to implement `Sum`, `Average`, `Concatenate`, etc.\n */\nexport abstract class Merge extends Layer {\n  protected reshapeRequired: boolean;\n\n  constructor(args?: LayerArgs) {\n    super(args || {});\n    this.supportsMasking = true;\n  }\n\n  /**\n   * Logic for merging multiple tensors, to be overridden by subclasses.\n   * @param inputs\n   */\n  protected mergeFunction(inputs: Tensor[]): Tensor {\n    throw new NotImplementedError();\n  }\n\n  /**\n   * Computes the shape of the result of an elementwise operation.\n   *\n   * @param shape1: Shape of the first tensor.\n   * @param shape2: Shape of the second tensor.\n   * @returns Expected output shape when an elementwise operation is carried\n   *   out on 2 tensors with shapes `shape1` and `shape2`.\n   * @throws ValueError: If `shape1` and `shape2` are not compatible for\n   *   element-wise operations.\n   */\n  private computeElementwiseOpOutputShape(shape1: Shape, shape2: Shape): Shape {\n    if (shape1 == null || shape2 == null) {\n      return null;\n    } else if (shape1.length < shape2.length) {\n      return this.computeElementwiseOpOutputShape(shape2, shape1);\n    } else if (shape2.length === 0) {\n      return shape1;\n    }\n    const outputShape: Shape = shape1.slice(0, shape1.length - shape2.length);\n    for (let k = 0; k < shape2.length; ++k) {\n      const i = shape1[shape1.length - shape2.length + k];\n      const j = shape2[k];\n      if (i == null || j == null || i < 0 || j < 0) {\n        outputShape.push(null);\n      } else if (i === 1) {\n        outputShape.push(j);\n      } else if (j === 1) {\n        outputShape.push(i);\n      } else {\n        if (i !== j) {\n          throw new ValueError(\n              'Operands could not be broadcast together with shapes ' +\n              JSON.stringify(shape1) + ' ' + JSON.stringify(shape2));\n        }\n        outputShape.push(i);\n      }\n    }\n    return outputShape;\n  }\n\n  build(inputShape: Shape|Shape[]): void {\n    // Used purely for shape validation.\n    if (Array.isArray(inputShape) && !Array.isArray(inputShape[0])) {\n      // Make sure that inputShape is an Array of shape.\n      inputShape = [getExactlyOneShape(inputShape)];\n    }\n    inputShape = inputShape as Shape[];\n    if (inputShape.length < 2) {\n      throw new ValueError(\n          'A merge layer should be called on an Array of at least 2 inputs.' +\n          ` Got ${inputShape.length} input(s).`);\n    }\n\n    // Make sure that there is at most one unique batch size among the input\n    // shapes.\n    let batchSizes: number[] = [];\n    for (const shape of inputShape) {\n      if (shape != null && shape[0] !== null) {\n        batchSizes.push(shape[0]);\n      }\n    }\n    batchSizes = generic_utils.unique(batchSizes);\n    if (batchSizes.length > 1) {\n      throw new ValueError(\n          `Can not merge tensors with different batch sizes. ` +\n          `Got tensors with shapes: ${JSON.stringify(inputShape)}.`);\n    }\n\n    let outputShape: Shape =\n        inputShape[0] == null ? null : inputShape[0].slice(1);\n    for (let i = 1; i < inputShape.length; ++i) {\n      const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n      outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n    }\n    // If the inputs have different ranks, we have to reshape them to make them\n    // broadcastable.\n    const allRanks = inputShape.map(shape => shape.length);\n    if (inputShape.indexOf(null) === -1 &&\n        generic_utils.unique(allRanks).length === 1) {\n      this.reshapeRequired = false;\n    } else {\n      this.reshapeRequired = true;\n    }\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = inputs as Tensor[];\n      if (this.reshapeRequired) {\n        const reshapedInputs: Tensor[] = [];\n        const inputDims = inputs.map(input => input.rank);\n        if (inputDims.indexOf(null) === -1) {\n          // If ranks of all inputs are available, we simply expand each of them\n          // at axis=1 until all of them have the same rank.\n          const maxNDim = mathUtils.max(inputDims);\n          for (let x of inputs) {\n            const xNDim = x.rank;\n            for (let k = 0; k < maxNDim - xNDim; ++k) {\n              x = K.expandDims(x, 1);\n            }\n            reshapedInputs.push(x);\n          }\n          return this.mergeFunction(reshapedInputs);\n        } else {\n          // Transpose all inputs so that batch size is the last dimension.\n          // [batchSize, dim1, dim2, ...] -> [dim1, dim2, ..., batchSize]\n          let transposed = false;\n          for (const x of inputs) {\n            const xNDim = x.rank;\n            if (xNDim == null) {\n              const xShape = x.shape;\n              const batchSize = xShape[0];\n              const newShape = xShape.slice(1).concat([batchSize]);\n              let xTransposed = tfc.reshape(\n                  x, [batchSize].concat(mathUtils.arrayProd(xShape.slice(1))));\n              xTransposed = tfc.transpose(xTransposed, [1, 0]);\n              xTransposed = tfc.reshape(xTransposed, newShape);\n              reshapedInputs.push(xTransposed);\n              transposed = true;\n            } else if (xNDim > 1) {\n              const dims = mathUtils.range(1, xNDim).concat([0]);\n              reshapedInputs.push(tfc.transpose(x, dims));\n              transposed = true;\n            } else {\n              // We don't transpose inputs if they are 1D vectors or scalars.\n              reshapedInputs.push(x);\n            }\n          }\n          let y = this.mergeFunction(reshapedInputs);\n          const yNDim = y.rank;\n          if (transposed) {\n            // If inputs have been transposed, we have to transpose the output\n            // too.\n            if (yNDim == null) {\n              const yShape = y.shape;\n              const yNDim = yShape.length;\n              const batchSize = yShape[yNDim - 1];\n              const newShape =\n                  [batchSize].concat(yShape.slice(0, yShape.length - 1));\n              y = tfc.reshape(\n                  tfc.transpose(tfc.reshape(y, [-1, batchSize]), [1, 0]),\n                  newShape);\n            } else if (yNDim > 1) {\n              const dims = [yNDim - 1].concat(mathUtils.range(0, yNDim - 1));\n              y = tfc.transpose(y, dims);\n            }\n          }\n          return y;\n        }\n      } else {\n        return this.mergeFunction(inputs);\n      }\n    });\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = inputShape as Shape[];\n    let outputShape: Shape;\n    if (inputShape[0] == null) {\n      outputShape = null;\n    } else {\n      outputShape = inputShape[0].slice(1);\n    }\n    for (let i = 1; i < inputShape.length; ++i) {\n      const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n      outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n    }\n\n    let batchSizes: number[] = [];\n    for (const shape of inputShape) {\n      if (shape != null && shape[0] !== null) {\n        batchSizes.push(shape[0]);\n      }\n    }\n    batchSizes = generic_utils.unique(batchSizes);\n    if (batchSizes.length === 1) {\n      outputShape = batchSizes.concat(outputShape);\n    } else {\n      outputShape = [null].concat(outputShape);\n    }\n    return outputShape;\n  }\n\n  computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]): Tensor {\n    return tfc.tidy(() => {\n      if (mask == null) {\n        return null;\n      }\n      if (!Array.isArray(mask)) {\n        throw new ValueError('`mask` should be an Array');\n      }\n      if (!Array.isArray(inputs)) {\n        throw new ValueError('`inputs` should be an Array');\n      }\n      if (mask.length !== inputs.length) {\n        throw new ValueError(\n            `The Array 'inputs' and 'mask' are expected to have the same ` +\n            `length, but have different lengths ` +\n            `(${inputs.length} vs ${mask.length})`);\n      }\n      if (mask.every(m => m == null)) {\n        return null;\n      }\n      mask = mask.map(m => m == null ? m : tfc.expandDims(m, 0));\n      let output = mask[0];\n      for (let i = 1; i < mask.length - 1; ++i) {\n        output = tfc.logicalAnd(output, mask[i]);\n      }\n      return output;\n    });\n  }\n}\n\nexport class Add extends Merge {\n  /** @nocollapse */\n  static className = 'Add';\n  constructor(args?: LayerArgs) {\n    super(args);\n  }\n\n  protected mergeFunction(inputs: Tensor[]): Tensor {\n    return tidy(() => {\n      let output = inputs[0].clone();\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.add(output, inputs[i]);\n      }\n      return output;\n    });\n  }\n}\nserialization.registerClass(Add);\n\n/**\n * Calculate the element-wise sum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Add` layer, by using no input argument\n *    or a single configuration argument. The resultant `Add` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const addLayer = tf.layers.add();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = addLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.add([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.add([input1, input2]).print();\n * // Gives [[11, 22], [33, 44]].\n *\n */\nexport function add(config?: SymbolicTensor[]|Tensor[]|LayerArgs): Layer|\n    SymbolicTensor|Tensor {\n  if (Array.isArray(config)) {\n    const layer = new Add({});\n    return layer.apply(config) as SymbolicTensor | Tensor;\n  } else {\n    return new Add(config);\n  }\n}\n\nexport class Multiply extends Merge {\n  /** @nocollapse */\n  static className = 'Multiply';\n  constructor(args?: LayerArgs) {\n    super(args);\n  }\n\n  protected mergeFunction(inputs: Tensor[]): Tensor {\n    return tidy(() => {\n      let output = inputs[0].clone();\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.mul(output, inputs[i]);\n      }\n      return output;\n    });\n  }\n}\nserialization.registerClass(Multiply);\n\n/**\n * Calculate the element-wise product of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Multiply` layer, by using no input argument\n *    or a single configuration argument. The resultant `Multiply` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const multiplyLayer = tf.layers.multiply();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = multiplyLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.multiply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.multiply([input1, input2]).print();\n * // Gives [[10, 40], [90, 160]].\n *\n */\nexport function multiply(config?: SymbolicTensor[]|Tensor[]|LayerArgs): Layer|\n    SymbolicTensor|Tensor {\n  if (Array.isArray(config)) {\n    const layer = new Multiply({});\n    return layer.apply(config) as SymbolicTensor | Tensor;\n  } else {\n    return new Multiply(config);\n  }\n}\n\nexport class Average extends Merge {\n  /** @nocollapse */\n  static className = 'Average';\n  constructor(args?: LayerArgs) {\n    super(args);\n  }\n\n  protected mergeFunction(inputs: Tensor[]): Tensor {\n    return tidy(() => {\n      let output = inputs[0].clone();\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.add(output, inputs[i]);\n      }\n      return tfc.mul(1 / inputs.length, output);\n    });\n  }\n}\nserialization.registerClass(Average);\n\n/**\n * Calculate the element-wise arithmetic mean of inputs, which all have the same\n * shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Average` layer, by using no input argument\n *    or a single configuration argument. The resultant `Average` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const averageLayer = tf.layers.average();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = averageLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.average([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.average([input1, input2]).print();\n * // Gives [[5.5, 11], [16.5, 22]].\n *\n */\nexport function average(config?: SymbolicTensor[]|Tensor[]|LayerArgs): Layer|\n    SymbolicTensor|Tensor {\n  if (Array.isArray(config)) {\n    const layer = new Average({});\n    return layer.apply(config) as SymbolicTensor | Tensor;\n  } else {\n    return new Average(config);\n  }\n}\n\nexport class Maximum extends Merge {\n  /** @nocollapse */\n  static className = 'Maximum';\n  constructor(args?: LayerArgs) {\n    super(args);\n  }\n\n  protected mergeFunction(inputs: Tensor[]): Tensor {\n    return tidy(() => {\n      let output = inputs[0];\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.maximum(output, inputs[i]);\n      }\n      return output;\n    });\n  }\n}\nserialization.registerClass(Maximum);\n\n/**\n * Calculate the element-wise maximum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Maximum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Maximum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const maximumLayer = tf.layers.maximum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = maximumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.maximum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.maximum([input1, input2]).print();\n * // Gives [[10, 20], [30, 40]].\n *\n */\nexport function maximum(config?: SymbolicTensor[]|Tensor[]|LayerArgs): Layer|\n    SymbolicTensor|Tensor {\n  if (Array.isArray(config)) {\n    const layer = new Maximum({});\n    return layer.apply(config) as SymbolicTensor | Tensor;\n  } else {\n    return new Maximum(config);\n  }\n}\n\nexport class Minimum extends Merge {\n  /** @nocollapse */\n  static className = 'Minimum';\n  constructor(args?: LayerArgs) {\n    super(args);\n  }\n\n  protected mergeFunction(inputs: Tensor[]): Tensor {\n    return tidy(() => {\n      let output = inputs[0];\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.minimum(output, inputs[i]);\n      }\n      return output;\n    });\n  }\n}\nserialization.registerClass(Minimum);\n\n/**\n * Calculate the element-wise minimum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Minimum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Minimum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const minimumLayer = tf.layers.minimum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = minimumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.minimum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.minimum([input1, input2]).print();\n * // Gives [[1, 2], [3, 4]].\n *\n */\nexport function minimum(config?: SymbolicTensor[]|Tensor[]|LayerArgs): Layer|\n    SymbolicTensor|Tensor {\n  if (Array.isArray(config)) {\n    const layer = new Minimum({});\n    return layer.apply(config) as SymbolicTensor | Tensor;\n  } else {\n    return new Minimum(config);\n  }\n}\n\nexport declare interface ConcatenateLayerArgs extends LayerArgs {\n  /**\n   * Axis along which to concatenate.\n   */\n  axis?: number;\n}\n\nexport class Concatenate extends Merge {\n  /** @nocollapse */\n  static className = 'Concatenate';\n  readonly DEFAULT_AXIS = -1;\n  private readonly axis: number;\n\n  constructor(args?: ConcatenateLayerArgs) {\n    super(args);\n    if (args == null) {\n      args = {};\n    }\n    this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;\n    this.supportsMasking = true;\n    this.reshapeRequired = false;\n  }\n\n  build(inputShape: Shape|Shape[]): void {\n    // Used purely for shape validation.]\n    if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0])) ||\n        inputShape.length === 1) {\n      throw new ValueError(\n          'A `Concatenate` layer should be called on a list of at least 2 ' +\n          'inputs');\n    }\n    inputShape = inputShape as Shape[];\n\n    let allNoneShape = true;\n    for (const shape of inputShape) {\n      if (shape != null) {\n        allNoneShape = false;\n        break;\n      }\n    }\n    if (allNoneShape) {\n      return;\n    }\n\n    const shapeSet: Shape[] = [];\n    for (let i = 0; i < inputShape.length; ++i) {\n      const shapeWithoutConcatAxis = inputShape[i].slice();\n      shapeWithoutConcatAxis.splice(this.axis, 1);\n      let exists = false;\n      for (const shape of shapeSet) {\n        if (util.arraysEqual(shape, shapeWithoutConcatAxis)) {\n          exists = true;\n          break;\n        }\n      }\n      if (!exists) {\n        shapeSet.push(shapeWithoutConcatAxis);\n      }\n    }\n    if (shapeSet.length > 1) {\n      throw new ValueError(\n          'A `Concatenate` layer requires inputs with matching shapes ' +\n          'except for the concat axis. Got input shapes: ' +\n          JSON.stringify(inputShape));\n    }\n  }\n\n  protected mergeFunction(inputs: Tensor[]): Tensor {\n    return tidy(() => {\n      return K.concatenate(inputs, this.axis);\n    });\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0]))) {\n      throw new ValueError(\n          'A `Concatenate` layer should be called on a list of inputs.');\n    }\n    const inputShapes = inputShape as Shape[];\n    const outputShape = inputShapes[0].slice();\n    const axis = this.axis < 0 ? outputShape.length + this.axis : this.axis;\n    // Porting Note: the line above is because TypeScript doesn't support\n    //   negative indices.\n    for (const shape of inputShapes.slice(1)) {\n      if (outputShape[axis] == null || shape[axis] == null) {\n        outputShape[axis] = null;\n        break;\n      }\n      outputShape[axis] += shape[axis];\n    }\n    return outputShape;\n  }\n\n  computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]): Tensor {\n    if (mask == null) {\n      return null;\n    }\n    if (!Array.isArray(mask)) {\n      throw new ValueError('`mask` should be an array for Concatenate');\n    }\n    if (!Array.isArray(inputs)) {\n      throw new ValueError('`inputs` should be an array for Concatenate');\n    }\n    if (mask.length !== inputs.length) {\n      throw new ValueError(\n          `Mismatch in the length of mask (${mask.length}) ` +\n          `and the legnth of inputs (${inputs.length})`);\n    }\n    return tfc.tidy(() => {\n      let allNullMasks = true;\n      mask.forEach(m => {\n        if (m != null) {\n          allNullMasks = false;\n          return;\n        }\n      });\n      if (allNullMasks) {\n        return null;\n      }\n      const outputMasks: Tensor[] = [];\n      for (let i = 0; i < inputs.length; ++i) {\n        if (mask[i] == null) {\n          // Input is unmasked. Append all 1's to masks.\n          outputMasks.push(tfc.cast(tfc.onesLike(inputs[i]), 'bool'));\n        } else if (mask[i].rank < inputs[i].rank) {\n          // Mask is smaller than the input, expand it.\n          outputMasks.push(tfc.expandDims(mask[i], -1));\n        } else {\n          outputMasks.push(mask[i]);\n        }\n      }\n      const concatenatedMasks = tfc.concat(outputMasks, this.axis);\n      return tfc.all(concatenatedMasks, -1, false);\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      'axis': this.axis,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Concatenate);\n\n/**\n * Concatenate an `Array` of inputs.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Concatenate` layer, by using no input argument\n *    or a single configuration argument. The resultant `Concatenate` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const concatLayer = tf.layers.concatenate();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = concatLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 7], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = tf.layers.concatenate([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([[1, 2], [3, 4]], [2, 2]);\n * const input2 = tf.tensor2d([[10, 20], [30, 40]], [2, 2]);\n * tf.layers.concatenate([input1, input2]).print();\n * // Gives [[1, 2, 10, 20], [3, 4, 30, 40]].\n *\n */\nexport function concatenate(config?: SymbolicTensor[]|Tensor[]|\n                            ConcatenateLayerArgs): Layer|SymbolicTensor|Tensor {\n  if (Array.isArray(config)) {\n    const layer = new Concatenate({});\n    return layer.apply(config) as SymbolicTensor | Tensor;\n  } else {\n    return new Concatenate(config);\n  }\n}\n\nexport declare interface DotLayerArgs extends LayerArgs {\n  /**\n   * Axis or axes along which the dot product will be taken.\n   *\n   * Integer or an Array of integers.\n   */\n  axes: number|[number, number];\n\n  /**\n   * Whether to L2-normalize samples along the dot product axis\n   * before taking the dot product.\n   *\n   * If set to `true`, the output of the dot product isthe cosine\n   * proximity between the two samples.\n   */\n  normalize?: boolean;\n}\n\n/**\n * Interpretable potentially negative axis index.\n *\n * For example, given axis = -1, and dim = 3, this function will return 2.\n *\n * @param axis The axis index, may be a positive, zero or negative integer.\n * @param dim Total number of dimensions, a positive integer.\n * @returns A non-negative axis index equivalent to the input `axis`.\n */\nfunction interpretAxis(axis: number, dim: number): number {\n  while (axis < 0) {\n    axis += dim;\n  }\n  return axis;\n}\n\nfunction batchDot(x: Tensor, y: Tensor, axes: number|[number, number]): Tensor {\n  if (x.shape.length > 3 || y.shape.length > 3) {\n    throw new NotImplementedError(\n        'batchDot is not implemented for tensors of 4D or higher rank yet');\n  }\n  tfc.util.assert(\n      x.shape.length >= 2,\n      () => `batchDot requires the rank of x to be >= 2, ` +\n          `but got ${x.shape.length}`);\n  tfc.util.assert(\n      x.shape.length >= 2,\n      () => `batchDot requires the rank of y to be >= 2, ` +\n          `but got ${y.shape.length}`);\n\n  if (typeof axes === 'number') {\n    axes = [axes, axes];\n  }\n\n  if (x.dtype === 'complex64' || y.dtype === 'complex64') {\n    throw new NotImplementedError(\n        'batchDot is not implemented for complex64-type Tensors yet.');\n  }\n\n  const xNDim = x.shape.length;\n  const yNDim = y.shape.length;\n  if (axes == null) {\n    // Behave like batchMatmul by default.\n    axes = [xNDim - 1, yNDim - 2];\n  }\n  const axesArray = axes as [number, number];\n\n  return tfc.tidy(() => {\n    let diff: number;\n    if (xNDim > yNDim) {\n      diff = xNDim - yNDim;\n      const diffShape: Shape = [];\n      for (let i = 0; i < diff; ++i) {\n        diffShape.push(1);\n      }\n      y = tfc.reshape(y, y.shape.concat(diffShape));\n    } else if (yNDim > xNDim) {\n      diff = yNDim - xNDim;\n      const diffShape: Shape = [];\n      for (let i = 0; i < diff; ++i) {\n        diffShape.push(1);\n      }\n      x = tfc.reshape(x, x.shape.concat(diffShape));\n    } else {\n      diff = 0;\n    }\n\n    let out: Tensor;\n    if (x.shape.length === 2 && y.shape.length === 2) {\n      if (axesArray[0] === axesArray[1]) {\n        out = tfc.sum(tfc.mul(x, y), axesArray[0]);\n      } else {\n        out = tfc.sum(tfc.mul(tfc.transpose(x, [1, 0]), y), axesArray[1]);\n      }\n    } else {\n      const adjX = axesArray[0] !== x.shape.length - 1;\n      const adjY = axesArray[1] === y.shape.length - 1;\n      out = tfc.matMul(x, y, adjX, adjY);\n    }\n\n    if (diff > 0) {\n      let idx: number;\n      if (xNDim > yNDim) {\n        idx = xNDim + yNDim - 3;\n      } else {\n        idx = xNDim - 1;\n      }\n      const squeezeAxes: number[] = [];\n      for (let i = idx; i < idx + diff; ++i) {\n        squeezeAxes.push(i);\n      }\n      out = tfc.squeeze(out, squeezeAxes);\n    }\n    if (out.shape.length === 1) {\n      out = tfc.expandDims(out, 1);\n    }\n    return out;\n  });\n}\n\nexport class Dot extends Merge {\n  /** @nocollapse */\n  static className = 'Dot';\n\n  private axes: number|[number, number];\n  private normalize: boolean;\n\n  constructor(args: DotLayerArgs) {\n    super(args);\n    this.axes = args.axes;\n    this.normalize = args.normalize == null ? false : args.normalize;\n    this.supportsMasking = true;\n    this.reshapeRequired = false;\n  }\n\n  build(inputShape: Shape|Shape[]): void {\n    tfc.util.assert(\n        Array.isArray(inputShape) && inputShape.length === 2 &&\n            Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]),\n        () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n    const shape1 = inputShape[0] as Shape;\n    const shape2 = inputShape[1] as Shape;\n    if (shape1.length > 3 || shape2.length > 3) {\n      throw new NotImplementedError(\n          'Dot layer does not support tensors of 4D or higher rank yet.');\n    }\n\n    const axes = this.interpretAxes(shape1, shape2);\n    if (shape1[axes[0]] !== shape2[axes[1]]) {\n      throw new ValueError(\n          `Dimension incompatibility: ` +\n          `${shape1[axes[0]]} !== ${shape2[axes[1]]}`);\n    }\n  }\n\n  protected mergeFunction(inputs: Tensor[]): Tensor {\n    if (inputs.length !== 2) {\n      throw new ValueError(\n          'A `Dot` layer must be called on exactly 2 inputs, ' +\n          `but received ${inputs.length} input(s).`);\n    }\n\n    let x1 = inputs[0];\n    let x2 = inputs[1];\n    let axes: [number, number];\n    if (!Array.isArray(this.axes)) {\n      axes = [\n        interpretAxis(this.axes, x1.shape.length),\n        interpretAxis(this.axes, x2.shape.length)\n      ];\n    } else {\n      axes = this.axes.map(\n                 (axis, i) => interpretAxis(\n                     axis, inputs[i].shape.length)) as [number, number];\n    }\n    if (this.normalize) {\n      x1 = l2Normalize(x1, axes[0]);\n      x2 = l2Normalize(x2, axes[1]);\n    }\n    return batchDot(x1, x2, axes);\n  }\n\n  private interpretAxes(shape1: Shape, shape2: Shape): number[] {\n    let axes: number[];\n    if (!Array.isArray(this.axes)) {\n      // `this.axes` is a single integer.\n      axes = [\n        interpretAxis(this.axes, shape1.length),\n        interpretAxis(this.axes, shape2.length)\n      ];\n    } else {\n      // `this.axes` is an Array of integers.\n      axes = this.axes;\n    }\n    return axes;\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    tfc.util.assert(\n        Array.isArray(inputShape) && inputShape.length === 2 &&\n            Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]),\n        () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n    const shape1 = (inputShape[0] as Shape).slice();\n    const shape2 = (inputShape[1] as Shape).slice();\n    if (shape1.length > 3 || shape2.length > 3) {\n      throw new NotImplementedError(\n          'Dot layer does not support tensors of 4D or higher rank yet.');\n    }\n\n    const axes = this.interpretAxes(shape1, shape2);\n    shape1.splice(axes[0], 1);\n    shape2.splice(axes[1], 1);\n    shape2.splice(0, 1);\n    const outputShape = shape1.concat(shape2);\n    if (outputShape.length === 1) {\n      outputShape.push(1);\n    }\n    return outputShape;\n  }\n\n  computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]): Tensor {\n    return null;\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      'axes': this.axes,\n      'normalize': this.normalize\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Dot);\n\n// TODO(cais): Add functional interfaces for the merge layers.\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}