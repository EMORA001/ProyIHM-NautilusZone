{"ast":null,"code":"/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util } from '@tensorflow/tfjs-core';\nimport { CumProgram } from '../cum_gpu';\nimport { identity } from './Identity';\nimport { transpose } from './Transpose';\nexport function cumImpl(op, x, backend, axis, exclusive, reverse) {\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n\n  if (permutation != null) {\n    permutedX = transpose({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        perm: permutation\n      }\n    });\n  }\n\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(`WebGL cumprod shader expects an inner-most axis=${x.shape.length - 1} ` + `but got axis=${axis}`);\n  }\n\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({\n    inputs: {\n      x: permutedX\n    },\n    backend\n  }); // Use cum parallel algorithm, inspired by:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  // Note: although the algorithm is called sum, it works for any associtative\n  // operator with an identity.\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumProgram(op, permutedX.shape, false, reverse);\n    const customValues = [[i]];\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype, customValues);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  } // For exclusive cum, shift the end result in the direction of product or sum\n  // and add 1 for product or 0 for sum to the front index.\n\n\n  if (exclusive) {\n    const program = new CumProgram(op, permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose({\n      inputs: {\n        x: result\n      },\n      backend,\n      attrs: {\n        perm: reversePermutation\n      }\n    });\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo(permutedX);\n    return reverseTransposedResult;\n  }\n\n  return result;\n}","map":{"version":3,"sources":["../../../../../../tfjs-backend-webgl/src/kernels/Cum_impl.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAR,QAAuC,uBAAvC;AAGA,SAAmB,UAAnB,QAAoC,YAApC;AAEA,SAAQ,QAAR,QAAuB,YAAvB;AACA,SAAQ,SAAR,QAAwB,aAAxB;AAEA,OAAM,SAAU,OAAV,CACF,EADE,EACa,CADb,EAC4B,OAD5B,EACuD,IADvD,EAEF,SAFE,EAEkB,OAFlB,EAEkC;EACtC,MAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;EACA,MAAM,WAAW,GAAG,YAAY,CAAC,kBAAb,CAAgC,CAAC,IAAD,CAAhC,EAAwC,KAAxC,CAApB;EACA,IAAI,SAAS,GAAG,CAAhB;;EACA,IAAI,WAAW,IAAI,IAAnB,EAAyB;IACvB,SAAS,GAAG,SAAS,CAAC;MAAC,MAAM,EAAE;QAAC;MAAD,CAAT;MAAc,OAAd;MAAuB,KAAK,EAAE;QAAC,IAAI,EAAE;MAAP;IAA9B,CAAD,CAArB;EACD;;EACD,MAAM,YAAY,GAAG,YAAY,CAAC,gBAAb,CAA8B,CAA9B,EAAiC,KAAjC,EAAwC,CAAxC,CAArB;;EAEA,IAAI,YAAY,KAAK,KAAK,GAAG,CAA7B,EAAgC;IAC9B,MAAM,IAAI,KAAJ,CACF,mDACI,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAAC,GADtB,GAEA,gBAAgB,IAAI,EAHlB,CAAN;EAID;;EACD,MAAM,IAAI,GAAG,SAAS,CAAC,KAAV,CAAgB,YAAhB,CAAb;EACA,IAAI,MAAM,GAAG,QAAQ,CAAC;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAJ,CAAT;IAAyB;EAAzB,CAAD,CAArB,CAhBsC,CAiBtC;EACA;EACA;EACA;;EAEA,KAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,IAAI,IAAI,CAAC,IAAL,CAAU,IAAI,CAAC,IAAL,CAAU,IAAV,CAAV,IAA6B,CAAlD,EAAqD,CAAC,EAAtD,EAA0D;IACxD,MAAM,OAAO,GAAG,IAAI,UAAJ,CAAe,EAAf,EAAmB,SAAS,CAAC,KAA7B,EAAoC,KAApC,EAA2C,OAA3C,CAAhB;IACA,MAAM,YAAY,GAAG,CAAC,CAAC,CAAD,CAAD,CAArB;IACA,MAAM,UAAU,GAAG,MAAnB;IACA,MAAM,GACF,OAAO,CAAC,eAAR,CAAwB,OAAxB,EAAiC,CAAC,MAAD,CAAjC,EAA2C,MAAM,CAAC,KAAlD,EAAyD,YAAzD,CADJ;IAEA,OAAO,CAAC,6BAAR,CAAsC,UAAtC;EACD,CA7BqC,CA8BtC;EACA;;;EACA,IAAI,SAAJ,EAAe;IACb,MAAM,OAAO,GAAG,IAAI,UAAJ,CAAe,EAAf,EAAmB,SAAS,CAAC,KAA7B,EAAoC,SAApC,EAA+C,OAA/C,CAAhB;IACA,MAAM,UAAU,GAAG,MAAnB;IACA,MAAM,GAAG,OAAO,CAAC,eAAR,CAAwB,OAAxB,EAAiC,CAAC,MAAD,CAAjC,EAA2C,MAAM,CAAC,KAAlD,CAAT;IACA,OAAO,CAAC,6BAAR,CAAsC,UAAtC;EACD;;EAED,IAAI,WAAW,IAAI,IAAnB,EAAyB;IACvB,MAAM,kBAAkB,GAAG,YAAY,CAAC,sBAAb,CAAoC,WAApC,CAA3B;IACA,MAAM,uBAAuB,GAAG,SAAS,CACrC;MAAC,MAAM,EAAE;QAAC,CAAC,EAAE;MAAJ,CAAT;MAAsB,OAAtB;MAA+B,KAAK,EAAE;QAAC,IAAI,EAAE;MAAP;IAAtC,CADqC,CAAzC;IAGA,OAAO,CAAC,6BAAR,CAAsC,MAAtC;IACA,OAAO,CAAC,6BAAR,CAAsC,SAAtC;IAEA,OAAO,uBAAP;EACD;;EAED,OAAO,MAAP;AACD","sourcesContent":["/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {CumOpType, CumProgram} from '../cum_gpu';\n\nimport {identity} from './Identity';\nimport {transpose} from './Transpose';\n\nexport function cumImpl(\n    op: CumOpType, x: TensorInfo, backend: MathBackendWebGL, axis: number,\n    exclusive: boolean, reverse: boolean): TensorInfo {\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(\n        `WebGL cumprod shader expects an inner-most axis=${\n            x.shape.length - 1} ` +\n        `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({inputs: {x: permutedX}, backend});\n  // Use cum parallel algorithm, inspired by:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  // Note: although the algorithm is called sum, it works for any associtative\n  // operator with an identity.\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumProgram(op, permutedX.shape, false, reverse);\n    const customValues = [[i]];\n    const prevResult = result;\n    result =\n        backend.runWebGLProgram(program, [result], result.dtype, customValues);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n  // For exclusive cum, shift the end result in the direction of product or sum\n  // and add 1 for product or 0 for sum to the front index.\n  if (exclusive) {\n    const program = new CumProgram(op, permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    result = backend.runWebGLProgram(program, [result], result.dtype);\n    backend.disposeIntermediateTensorInfo(prevResult);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo(permutedX);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}