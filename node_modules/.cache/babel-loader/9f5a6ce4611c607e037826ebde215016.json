{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, upcastType } from '@tensorflow/tfjs-core';\nimport { BinaryOpProgram } from '../binaryop_gpu';\nimport { BinaryOpPackedProgram } from '../binaryop_packed_gpu';\nimport { complex } from '../kernels/Complex';\nimport { LEAKYRELU, LEAKYRELU_PACKED } from '../kernels/LeakyRelu';\nimport { PRELU, PRELU_PACKED } from '../kernels/Prelu';\nimport * as unary_op from '../unaryop_gpu';\nimport { UnaryOpProgram } from '../unaryop_gpu';\nimport * as unary_packed_op from '../unaryop_packed_gpu';\nimport { UnaryOpPackedProgram } from '../unaryop_packed_gpu';\nexport const CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;\nexport const CHECK_NAN_SNIPPET_BINARY = `\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n`;\nexport const CHECK_NAN_SNIPPET_BINARY_PACKED = `\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n`;\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opSnippet Op snippet to create `UnaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `UnaryOpPackedProgram`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\n\nexport function unaryKernelFunc(_ref) {\n  let {\n    opSnippet,\n    packedOpSnippet,\n    cpuKernelImpl,\n    dtype\n  } = _ref;\n  return _ref2 => {\n    let {\n      inputs,\n      backend\n    } = _ref2;\n    const {\n      x\n    } = inputs;\n    const webglBackend = backend;\n    const $dtype = dtype || x.dtype;\n\n    if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n      const xData = webglBackend.texData.get(x.dataId);\n      const outValues = cpuKernelImpl(xData.values, $dtype);\n      return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);\n    }\n\n    const shouldUsePackedProgram = env().getBool('WEBGL_PACK_UNARY_OPERATIONS') && packedOpSnippet != null;\n    let program;\n\n    if (shouldUsePackedProgram) {\n      program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);\n    } else {\n      program = new UnaryOpProgram(x.shape, opSnippet);\n    }\n\n    return webglBackend.runWebGLProgram(program, [x], $dtype);\n  };\n}\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opSnippet Op snippet to create `BinaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `BinaryOpPackedProgram`.\n * @param checkOutOfBoundsForPackedProgram Whether to set checkOutOfBounds=true\n *     when creating BinaryOpPackedProgram.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\n\nexport function binaryKernelFunc(_ref3) {\n  let {\n    opSnippet,\n    packedOpSnippet,\n    checkOutOfBounds = false,\n    supportsComplex = false,\n    cpuKernelImpl,\n    dtype\n  } = _ref3;\n  return _ref4 => {\n    let {\n      inputs,\n      backend\n    } = _ref4;\n    const {\n      a,\n      b\n    } = inputs;\n    const webglBackend = backend;\n\n    if (supportsComplex && a.dtype === 'complex64') {\n      const aData = webglBackend.texData.get(a.dataId);\n      const bData = webglBackend.texData.get(b.dataId);\n      const [real, imag] = [[aData.complexTensorInfos.real, bData.complexTensorInfos.real], [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]].map(complexParts => {\n        const [aPart, bPart] = complexParts;\n        const aHandle = {\n          dataId: aPart.dataId,\n          dtype: aPart.dtype,\n          shape: a.shape\n        };\n        const bHandle = {\n          dataId: bPart.dataId,\n          dtype: bPart.dtype,\n          shape: b.shape\n        };\n        const program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n        return webglBackend.runWebGLProgram(program, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));\n      });\n      const complexOutput = complex({\n        inputs: {\n          real,\n          imag\n        },\n        backend: webglBackend\n      });\n      webglBackend.disposeIntermediateTensorInfo(real);\n      webglBackend.disposeIntermediateTensorInfo(imag); // TODO(annxingyuan): Implement CPU forwarding for complex inputs.\n\n      return complexOutput;\n    }\n\n    const $dtype = dtype || upcastType(a.dtype, b.dtype);\n\n    if ((a.dtype === 'string' || b.dtype === 'string' || webglBackend.shouldExecuteOnCPU([a, b])) && cpuKernelImpl != null) {\n      const aVals = webglBackend.texData.get(a.dataId).values;\n      const bVals = webglBackend.texData.get(b.dataId).values;\n      const decodedAVals = a.dtype === 'string' ? // tslint:disable-next-line: no-any\n      backend_util.fromUint8ToStringArray(aVals) : aVals;\n      const decodedBVals = a.dtype === 'string' ? // tslint:disable-next-line: no-any\n      backend_util.fromUint8ToStringArray(bVals) : bVals;\n      const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);\n      const out = webglBackend.makeTensorInfo(outShape, $dtype);\n      const outData = webglBackend.texData.get(out.dataId);\n      outData.values = outValues;\n      return out;\n    }\n\n    const shouldUsePackedProgram = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') && packedOpSnippet != null;\n    let program;\n\n    if (shouldUsePackedProgram) {\n      program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);\n    } else {\n      program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n    }\n\n    return webglBackend.runWebGLProgram(program, [a, b], $dtype);\n  };\n}\nexport function mapActivationToShaderProgram(activation) {\n  let packed = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n\n  if (activation === 'linear') {\n    if (packed) {\n      return unary_packed_op.LINEAR;\n    }\n\n    return unary_op.LINEAR;\n  } else if (activation === 'relu') {\n    if (packed) {\n      return unary_packed_op.RELU;\n    }\n\n    return unary_op.RELU;\n  } else if (activation === 'elu') {\n    if (packed) {\n      return unary_packed_op.ELU;\n    }\n\n    return unary_op.ELU;\n  } else if (activation === 'relu6') {\n    if (packed) {\n      return unary_packed_op.RELU6;\n    }\n\n    return unary_op.RELU6;\n  } else if (activation === 'prelu') {\n    if (packed) {\n      return PRELU_PACKED;\n    }\n\n    return PRELU;\n  } else if (activation === 'leakyrelu') {\n    if (packed) {\n      return LEAKYRELU_PACKED;\n    }\n\n    return LEAKYRELU;\n  } else if (activation === 'sigmoid') {\n    if (packed) {\n      return unary_packed_op.SIGMOID;\n    }\n\n    return unary_op.SIGMOID;\n  }\n\n  throw new Error(`Activation ${activation} has not been implemented for the WebGL backend.`);\n}","map":{"version":3,"sources":["../../../../../../tfjs-backend-webgl/src/kernel_utils/kernel_funcs_utils.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAR,EAA8C,GAA9C,EAAwF,UAAxF,QAAyG,uBAAzG;AAGA,SAAQ,eAAR,QAA8B,iBAA9B;AACA,SAAQ,qBAAR,QAAoC,wBAApC;AACA,SAAQ,OAAR,QAAsB,oBAAtB;AACA,SAAQ,SAAR,EAAmB,gBAAnB,QAA0C,sBAA1C;AACA,SAAQ,KAAR,EAAe,YAAf,QAAkC,kBAAlC;AACA,OAAO,KAAK,QAAZ,MAA0B,gBAA1B;AACA,SAAQ,cAAR,QAA6B,gBAA7B;AACA,OAAO,KAAK,eAAZ,MAAiC,uBAAjC;AACA,SAAQ,oBAAR,QAAmC,uBAAnC;AAIA,OAAO,MAAM,uBAAuB,GAAG,yBAAhC;AAEP,OAAO,MAAM,wBAAwB,GAAG;;;AAGvC,CAHM;AAKP,OAAO,MAAM,+BAA+B,GAAG;;;;;AAK9C,CALM;AAcP;;;;;;;AAOG;;AACH,OAAM,SAAU,eAAV,OACuE;EAAA,IAAzE;IAAC,SAAD;IAAY,eAAZ;IAA6B,aAA7B;IAA4C;EAA5C,CAAyE;EAE3E,OAAO,SAAsB;IAAA,IAArB;MAAC,MAAD;MAAS;IAAT,CAAqB;IAC3B,MAAM;MAAC;IAAD,IAAM,MAAZ;IACA,MAAM,YAAY,GAAG,OAArB;IAEA,MAAM,MAAM,GAAG,KAAK,IAAI,CAAC,CAAC,KAA1B;;IACA,IAAI,YAAY,CAAC,kBAAb,CAAgC,CAAC,CAAD,CAAhC,KAAwC,aAAa,IAAI,IAA7D,EAAmE;MACjE,MAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;MACA,MAAM,SAAS,GAAG,aAAa,CAAC,KAAK,CAAC,MAAP,EAA6B,MAA7B,CAA/B;MACA,OAAO,YAAY,CAAC,cAAb,CAA4B,CAAC,CAAC,KAA9B,EAAqC,MAArC,EAA6C,SAA7C,CAAP;IACD;;IAED,MAAM,sBAAsB,GACxB,GAAG,GAAG,OAAN,CAAc,6BAAd,KAAgD,eAAe,IAAI,IADvE;IAEA,IAAI,OAAJ;;IACA,IAAI,sBAAJ,EAA4B;MAC1B,OAAO,GAAG,IAAI,oBAAJ,CAAyB,CAAC,CAAC,KAA3B,EAAkC,eAAlC,CAAV;IACD,CAFD,MAEO;MACL,OAAO,GAAG,IAAI,cAAJ,CAAmB,CAAC,CAAC,KAArB,EAA4B,SAA5B,CAAV;IACD;;IAED,OAAO,YAAY,CAAC,eAAb,CAA6B,OAA7B,EAAsC,CAAC,CAAD,CAAtC,EAA2C,MAA3C,CAAP;EACD,CArBD;AAsBD;AAWD;;;;;;;;;AASG;;AACH,OAAM,SAAU,gBAAV,QAOmB;EAAA,IAPQ;IAC/B,SAD+B;IAE/B,eAF+B;IAG/B,gBAAgB,GAAG,KAHY;IAI/B,eAAe,GAAG,KAJa;IAK/B,aAL+B;IAM/B;EAN+B,CAOR;EACvB,OAAO,SAAsB;IAAA,IAArB;MAAC,MAAD;MAAS;IAAT,CAAqB;IAC3B,MAAM;MAAC,CAAD;MAAI;IAAJ,IAAS,MAAf;IACA,MAAM,YAAY,GAAG,OAArB;;IAEA,IAAI,eAAe,IAAI,CAAC,CAAC,KAAF,KAAY,WAAnC,EAAgD;MAC9C,MAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;MACA,MAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,CAAd;MAEA,MAAM,CAAC,IAAD,EAAO,IAAP,IAAe,CACnB,CAAC,KAAK,CAAC,kBAAN,CAAyB,IAA1B,EAAgC,KAAK,CAAC,kBAAN,CAAyB,IAAzD,CADmB,EAEnB,CAAC,KAAK,CAAC,kBAAN,CAAyB,IAA1B,EAAgC,KAAK,CAAC,kBAAN,CAAyB,IAAzD,CAFmB,EAGnB,GAHmB,CAGf,YAAY,IAAG;QACnB,MAAM,CAAC,KAAD,EAAQ,KAAR,IAAiB,YAAvB;QAEA,MAAM,OAAO,GAAG;UACd,MAAM,EAAE,KAAK,CAAC,MADA;UAEd,KAAK,EAAE,KAAK,CAAC,KAFC;UAGd,KAAK,EAAE,CAAC,CAAC;QAHK,CAAhB;QAKA,MAAM,OAAO,GAAG;UACd,MAAM,EAAE,KAAK,CAAC,MADA;UAEd,KAAK,EAAE,KAAK,CAAC,KAFC;UAGd,KAAK,EAAE,CAAC,CAAC;QAHK,CAAhB;QAMA,MAAM,OAAO,GAAG,IAAI,eAAJ,CAAoB,SAApB,EAA+B,CAAC,CAAC,KAAjC,EAAwC,CAAC,CAAC,KAA1C,CAAhB;QACA,OAAO,YAAY,CAAC,eAAb,CACH,OADG,EACM,CAAC,OAAD,EAAU,OAAV,CADN,EAC0B,UAAU,CAAC,KAAK,CAAC,KAAP,EAAc,KAAK,CAAC,KAApB,CADpC,CAAP;MAED,CApBoB,CAArB;MAsBA,MAAM,aAAa,GACf,OAAO,CAAC;QAAC,MAAM,EAAE;UAAC,IAAD;UAAO;QAAP,CAAT;QAAuB,OAAO,EAAE;MAAhC,CAAD,CADX;MAGA,YAAY,CAAC,6BAAb,CAA2C,IAA3C;MACA,YAAY,CAAC,6BAAb,CAA2C,IAA3C,EA9B8C,CAgC9C;;MAEA,OAAO,aAAP;IACD;;IAED,MAAM,MAAM,GAAG,KAAK,IAAI,UAAU,CAAC,CAAC,CAAC,KAAH,EAAU,CAAC,CAAC,KAAZ,CAAlC;;IACA,IAAI,CAAC,CAAC,CAAC,KAAF,KAAY,QAAZ,IAAwB,CAAC,CAAC,KAAF,KAAY,QAApC,IACA,YAAY,CAAC,kBAAb,CAAgC,CAAC,CAAD,EAAI,CAAJ,CAAhC,CADD,KAEA,aAAa,IAAI,IAFrB,EAE2B;MACzB,MAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,EAAmC,MAAjD;MACA,MAAM,KAAK,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,CAAC,CAAC,MAA3B,EAAmC,MAAjD;MAEA,MAAM,YAAY,GAAG,CAAC,CAAC,KAAF,KAAY,QAAZ,GACjB;MACA,YAAY,CAAC,sBAAb,CAAoC,KAApC,CAFiB,GAGjB,KAHJ;MAIA,MAAM,YAAY,GAAG,CAAC,CAAC,KAAF,KAAY,QAAZ,GACjB;MACA,YAAY,CAAC,sBAAb,CAAoC,KAApC,CAFiB,GAGjB,KAHJ;MAIA,MAAM,CAAC,SAAD,EAAY,QAAZ,IACF,aAAa,CAAC,CAAC,CAAC,KAAH,EAAU,CAAC,CAAC,KAAZ,EAAmB,YAAnB,EAAiC,YAAjC,EAA+C,MAA/C,CADjB;MAGA,MAAM,GAAG,GAAG,YAAY,CAAC,cAAb,CAA4B,QAA5B,EAAsC,MAAtC,CAAZ;MACA,MAAM,OAAO,GAAG,YAAY,CAAC,OAAb,CAAqB,GAArB,CAAyB,GAAG,CAAC,MAA7B,CAAhB;MACA,OAAO,CAAC,MAAR,GAAiB,SAAjB;MACA,OAAO,GAAP;IACD;;IAED,MAAM,sBAAsB,GACxB,GAAG,GAAG,OAAN,CAAc,8BAAd,KACA,eAAe,IAAI,IAFvB;IAGA,IAAI,OAAJ;;IACA,IAAI,sBAAJ,EAA4B;MAC1B,OAAO,GAAG,IAAI,qBAAJ,CACN,eADM,EACW,CAAC,CAAC,KADb,EACoB,CAAC,CAAC,KADtB,EAC6B,gBAD7B,CAAV;IAED,CAHD,MAGO;MACL,OAAO,GAAG,IAAI,eAAJ,CAAoB,SAApB,EAA+B,CAAC,CAAC,KAAjC,EAAwC,CAAC,CAAC,KAA1C,CAAV;IACD;;IAED,OAAO,YAAY,CAAC,eAAb,CAA6B,OAA7B,EAAsC,CAAC,CAAD,EAAI,CAAJ,CAAtC,EAA8C,MAA9C,CAAP;EACD,CA7ED;AA8ED;AAED,OAAM,SAAU,4BAAV,CACF,UADE,EACiD;EAAA,IAAd,MAAc,uEAAL,KAAK;;EACrD,IAAI,UAAU,KAAK,QAAnB,EAA6B;IAC3B,IAAI,MAAJ,EAAY;MACV,OAAO,eAAe,CAAC,MAAvB;IACD;;IACD,OAAO,QAAQ,CAAC,MAAhB;EACD,CALD,MAKO,IAAI,UAAU,KAAK,MAAnB,EAA2B;IAChC,IAAI,MAAJ,EAAY;MACV,OAAO,eAAe,CAAC,IAAvB;IACD;;IACD,OAAO,QAAQ,CAAC,IAAhB;EACD,CALM,MAKA,IAAI,UAAU,KAAK,KAAnB,EAA0B;IAC/B,IAAI,MAAJ,EAAY;MACV,OAAO,eAAe,CAAC,GAAvB;IACD;;IACD,OAAO,QAAQ,CAAC,GAAhB;EACD,CALM,MAKA,IAAI,UAAU,KAAK,OAAnB,EAA4B;IACjC,IAAI,MAAJ,EAAY;MACV,OAAO,eAAe,CAAC,KAAvB;IACD;;IACD,OAAO,QAAQ,CAAC,KAAhB;EACD,CALM,MAKA,IAAI,UAAU,KAAK,OAAnB,EAA4B;IACjC,IAAI,MAAJ,EAAY;MACV,OAAO,YAAP;IACD;;IACD,OAAO,KAAP;EACD,CALM,MAKA,IAAI,UAAU,KAAK,WAAnB,EAAgC;IACrC,IAAI,MAAJ,EAAY;MACV,OAAO,gBAAP;IACD;;IACD,OAAO,SAAP;EACD,CALM,MAKA,IAAI,UAAU,KAAK,SAAnB,EAA8B;IACnC,IAAI,MAAJ,EAAY;MACV,OAAO,eAAe,CAAC,OAAvB;IACD;;IACD,OAAO,QAAQ,CAAC,OAAhB;EACD;;EACD,MAAM,IAAI,KAAJ,CAAU,cACZ,UAAU,kDADR,CAAN;AAED","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, env, KernelFunc, TypedArray, UnaryInputs, upcastType} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {BinaryOpProgram} from '../binaryop_gpu';\nimport {BinaryOpPackedProgram} from '../binaryop_packed_gpu';\nimport {complex} from '../kernels/Complex';\nimport {LEAKYRELU, LEAKYRELU_PACKED} from '../kernels/LeakyRelu';\nimport {PRELU, PRELU_PACKED} from '../kernels/Prelu';\nimport * as unary_op from '../unaryop_gpu';\nimport {UnaryOpProgram} from '../unaryop_gpu';\nimport * as unary_packed_op from '../unaryop_packed_gpu';\nimport {UnaryOpPackedProgram} from '../unaryop_packed_gpu';\n\nimport {SimpleBinaryKernelImplCPU, SimpleUnaryKernelImplCPU} from './shared';\n\nexport const CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;\n\nexport const CHECK_NAN_SNIPPET_BINARY = `\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n`;\n\nexport const CHECK_NAN_SNIPPET_BINARY_PACKED = `\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n`;\n\ntype UnaryKernelFuncConfig = {\n  opSnippet: string,\n  packedOpSnippet?: string,\n  cpuKernelImpl?: SimpleUnaryKernelImplCPU,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param opSnippet Op snippet to create `UnaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `UnaryOpPackedProgram`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function unaryKernelFunc(\n    {opSnippet, packedOpSnippet, cpuKernelImpl, dtype}: UnaryKernelFuncConfig):\n    KernelFunc {\n  return ({inputs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    const webglBackend = backend as MathBackendWebGL;\n\n    const $dtype = dtype || x.dtype;\n    if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {\n      const xData = webglBackend.texData.get(x.dataId);\n      const outValues = cpuKernelImpl(xData.values as TypedArray, $dtype);\n      return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);\n    }\n\n    const shouldUsePackedProgram =\n        env().getBool('WEBGL_PACK_UNARY_OPERATIONS') && packedOpSnippet != null;\n    let program: UnaryOpProgram|UnaryOpPackedProgram;\n    if (shouldUsePackedProgram) {\n      program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);\n    } else {\n      program = new UnaryOpProgram(x.shape, opSnippet);\n    }\n\n    return webglBackend.runWebGLProgram(program, [x], $dtype);\n  };\n}\n\ntype BinaryKernelFuncConfig = {\n  opSnippet: string,\n  packedOpSnippet?: string,\n  checkOutOfBounds?: boolean,\n  supportsComplex?: boolean,\n  cpuKernelImpl?: SimpleBinaryKernelImplCPU,\n  dtype?: DataType\n};\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param opSnippet Op snippet to create `BinaryOpProgram`.\n * @param packedOpSnippet Op snippet to create `BinaryOpPackedProgram`.\n * @param checkOutOfBoundsForPackedProgram Whether to set checkOutOfBounds=true\n *     when creating BinaryOpPackedProgram.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc({\n  opSnippet,\n  packedOpSnippet,\n  checkOutOfBounds = false,\n  supportsComplex = false,\n  cpuKernelImpl,\n  dtype\n}: BinaryKernelFuncConfig): KernelFunc {\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const webglBackend = backend as MathBackendWebGL;\n\n    if (supportsComplex && a.dtype === 'complex64') {\n      const aData = webglBackend.texData.get(a.dataId);\n      const bData = webglBackend.texData.get(b.dataId);\n\n      const [real, imag] = [\n        [aData.complexTensorInfos.real, bData.complexTensorInfos.real],\n        [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]\n      ].map(complexParts => {\n        const [aPart, bPart] = complexParts;\n\n        const aHandle = {\n          dataId: aPart.dataId,\n          dtype: aPart.dtype,\n          shape: a.shape\n        };\n        const bHandle = {\n          dataId: bPart.dataId,\n          dtype: bPart.dtype,\n          shape: b.shape\n        };\n\n        const program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n        return webglBackend.runWebGLProgram(\n            program, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));\n      });\n\n      const complexOutput =\n          complex({inputs: {real, imag}, backend: webglBackend});\n\n      webglBackend.disposeIntermediateTensorInfo(real);\n      webglBackend.disposeIntermediateTensorInfo(imag);\n\n      // TODO(annxingyuan): Implement CPU forwarding for complex inputs.\n\n      return complexOutput;\n    }\n\n    const $dtype = dtype || upcastType(a.dtype, b.dtype);\n    if ((a.dtype === 'string' || b.dtype === 'string' ||\n         webglBackend.shouldExecuteOnCPU([a, b])) &&\n        cpuKernelImpl != null) {\n      const aVals = webglBackend.texData.get(a.dataId).values as TypedArray;\n      const bVals = webglBackend.texData.get(b.dataId).values as TypedArray;\n\n      const decodedAVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(aVals as any as Uint8Array[]) :\n          aVals;\n      const decodedBVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(bVals as any as Uint8Array[]) :\n          bVals;\n      const [outValues, outShape] =\n          cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);\n\n      const out = webglBackend.makeTensorInfo(outShape, $dtype);\n      const outData = webglBackend.texData.get(out.dataId);\n      outData.values = outValues;\n      return out;\n    }\n\n    const shouldUsePackedProgram =\n        env().getBool('WEBGL_PACK_BINARY_OPERATIONS') &&\n        packedOpSnippet != null;\n    let program: BinaryOpProgram|BinaryOpPackedProgram;\n    if (shouldUsePackedProgram) {\n      program = new BinaryOpPackedProgram(\n          packedOpSnippet, a.shape, b.shape, checkOutOfBounds);\n    } else {\n      program = new BinaryOpProgram(opSnippet, a.shape, b.shape);\n    }\n\n    return webglBackend.runWebGLProgram(program, [a, b], $dtype);\n  };\n}\n\nexport function mapActivationToShaderProgram(\n    activation: backend_util.Activation, packed = false): string {\n  if (activation === 'linear') {\n    if (packed) {\n      return unary_packed_op.LINEAR;\n    }\n    return unary_op.LINEAR;\n  } else if (activation === 'relu') {\n    if (packed) {\n      return unary_packed_op.RELU;\n    }\n    return unary_op.RELU;\n  } else if (activation === 'elu') {\n    if (packed) {\n      return unary_packed_op.ELU;\n    }\n    return unary_op.ELU;\n  } else if (activation === 'relu6') {\n    if (packed) {\n      return unary_packed_op.RELU6;\n    }\n    return unary_op.RELU6;\n  } else if (activation === 'prelu') {\n    if (packed) {\n      return PRELU_PACKED;\n    }\n    return PRELU;\n  } else if (activation === 'leakyrelu') {\n    if (packed) {\n      return LEAKYRELU_PACKED;\n    }\n    return LEAKYRELU;\n  } else if (activation === 'sigmoid') {\n    if (packed) {\n      return unary_packed_op.SIGMOID;\n    }\n    return unary_op.SIGMOID;\n  }\n  throw new Error(`Activation ${\n      activation} has not been implemented for the WebGL backend.`);\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}