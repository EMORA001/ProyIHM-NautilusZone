{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { BatchMatMul, broadcast_util, buffer, util } from '@tensorflow/tfjs-core';\nimport { assertNotComplex } from '../cpu_util';\nimport { reshape } from './Reshape';\nexport function batchMatMul(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    a,\n    b\n  } = inputs;\n  const {\n    transposeA,\n    transposeB\n  } = attrs;\n  assertNotComplex([a, b], 'matMul');\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n  util.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (` + `${innerShapeB}) of Tensors with shapes ${a.shape} and ` + `${b.shape} and transposeA=${transposeA}` + ` and transposeB=${transposeB} must match.`);\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB]; // The rest of the implementation is designed to operate on rank-3 tensors\n\n  const a3d = reshape({\n    inputs: {\n      x: a\n    },\n    backend,\n    attrs: {\n      shape: a3dShape\n    }\n  });\n  const b3d = reshape({\n    inputs: {\n      x: b\n    },\n    backend,\n    attrs: {\n      shape: b3dShape\n    }\n  });\n  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n  const a3dValues = backend.data.get(a3d.dataId).values;\n  const b3dValues = backend.data.get(b3d.dataId).values;\n  const a3dStrides = util.computeStrides(a3d.shape);\n  const b3dStrides = util.computeStrides(b3d.shape);\n  const [aBatch, aOuterStep, aInnerStep] = transposeA ? [a3dStrides[0], 1, a3dStrides[1]] : [a3dStrides[0], a3dStrides[1], 1];\n  const [bInnerStep, bOuterStep, bBatch] = transposeB ? [1, b3dStrides[1], b3dStrides[0]] : [b3dStrides[1], 1, b3dStrides[0]];\n  const size = leftDim * rightDim;\n  const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);\n  const resVals = result.values;\n  const blockSize = backend.blockSize;\n\n  for (let bi = 0; bi < batchDim; bi++) {\n    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n        for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n          // for when blockSize doesn't evenly divide the input\n          const iBlock = Math.min(i0 + blockSize, leftDim);\n          const jBlock = Math.min(j0 + blockSize, rightDim);\n          const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n          for (let i = i0; i < iBlock; i++) {\n            for (let j = j0; j < jBlock; j++) {\n              let sum = 0.0;\n\n              for (let k = k0; k < kBlock; k++) {\n                const batchOffsetA = Math.min(bi, batchDimA - 1) * aBatch;\n                const batchOffsetB = Math.min(bi, batchDimB - 1) * bBatch;\n                const aVal = a3dValues[batchOffsetA + i * aOuterStep + k * aInnerStep];\n                const bVal = b3dValues[k * bInnerStep + j * bOuterStep + batchOffsetB];\n                sum += aVal * bVal;\n              }\n\n              resVals[bi * size + (i * rightDim + j)] += sum;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  backend.disposeIntermediateTensorInfo(a3d);\n  backend.disposeIntermediateTensorInfo(b3d); // set correct shape on output.\n\n  return backend.makeTensorInfo(outShape, result.dtype, result.values);\n}\nexport const batchMatMulConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'cpu',\n  kernelFunc: batchMatMul\n};","map":{"version":3,"sources":["../../../../../../tfjs-backend-cpu/src/kernels/BatchMatMul.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,WAAR,EAA0D,cAA1D,EAA0E,MAA1E,EAAwH,IAAxH,QAAmI,uBAAnI;AAGA,SAAQ,gBAAR,QAA+B,aAA/B;AAEA,SAAQ,OAAR,QAAsB,WAAtB;AAEA,OAAM,SAAU,WAAV,CAAsB,IAAtB,EAIL;EACC,MAAM;IAAC,MAAD;IAAS,OAAT;IAAkB;EAAlB,IAA2B,IAAjC;EACA,MAAM;IAAC,CAAD;IAAI;EAAJ,IAAS,MAAf;EACA,MAAM;IAAC,UAAD;IAAa;EAAb,IAA2B,KAAjC;EAEA,gBAAgB,CAAC,CAAC,CAAD,EAAI,CAAJ,CAAD,EAAS,QAAT,CAAhB;EAEA,MAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;EACA,MAAM,KAAK,GAAG,CAAC,CAAC,KAAF,CAAQ,MAAtB;EAEA,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAH,GAAwB,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAtD;EACA,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAH,GAAwB,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAtD;EAEA,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAH,GAAwB,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAtD;EACA,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAH,GAAwB,CAAC,CAAC,KAAF,CAAQ,KAAK,GAAG,CAAhB,CAAtD;EAEA,MAAM,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,EAAiB,CAAC,CAAlB,CAAnB;EACA,MAAM,UAAU,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,EAAiB,CAAC,CAAlB,CAAnB;EAEA,MAAM,SAAS,GAAG,IAAI,CAAC,aAAL,CAAmB,UAAnB,CAAlB;EACA,MAAM,SAAS,GAAG,IAAI,CAAC,aAAL,CAAmB,UAAnB,CAAlB;EAEA,MAAM,iBAAiB,GAAG,cAAc,CAAC,0BAAf,CACtB,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,EAAiB,CAAC,CAAlB,CADsB,EACA,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,EAAiB,CAAC,CAAlB,CADA,CAA1B;EAEA,MAAM,QAAQ,GAAG,iBAAiB,CAAC,MAAlB,CAAyB,CAAC,WAAD,EAAc,WAAd,CAAzB,CAAjB;EAEA,IAAI,CAAC,MAAL,CACI,WAAW,KAAK,WADpB,EAEI,MAAM,kCAAkC,WAAW,SAA7C,GACF,GAAG,WAAW,4BAA4B,CAAC,CAAC,KAAK,OAD/C,GAEF,GAAG,CAAC,CAAC,KAAK,mBAAmB,UAAU,EAFrC,GAGF,mBAAmB,UAAU,cALrC;EAOA,MAAM,QAAQ,GAAG,UAAU,GAAG,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAAH,GACG,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAD9B;EAEA,MAAM,QAAQ,GAAG,UAAU,GAAG,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAAH,GACG,CAAC,SAAD,EAAY,WAAZ,EAAyB,WAAzB,CAD9B,CAnCD,CAsCC;;EACA,MAAM,GAAG,GAAG,OAAO,CAAC;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAJ,CAAT;IAAiB,OAAjB;IAA0B,KAAK,EAAE;MAAC,KAAK,EAAE;IAAR;EAAjC,CAAD,CAAnB;EACA,MAAM,GAAG,GAAG,OAAO,CAAC;IAAC,MAAM,EAAE;MAAC,CAAC,EAAE;IAAJ,CAAT;IAAiB,OAAjB;IAA0B,KAAK,EAAE;MAAC,KAAK,EAAE;IAAR;EAAjC,CAAD,CAAnB;EAEA,MAAM,SAAS,GAAG,UAAU,GAAG,GAAG,CAAC,KAAJ,CAAU,CAAV,CAAH,GAAkB,GAAG,CAAC,KAAJ,CAAU,CAAV,CAA9C;EACA,MAAM,OAAO,GAAG,UAAU,GAAG,GAAG,CAAC,KAAJ,CAAU,CAAV,CAAH,GAAkB,GAAG,CAAC,KAAJ,CAAU,CAAV,CAA5C;EACA,MAAM,QAAQ,GAAG,UAAU,GAAG,GAAG,CAAC,KAAJ,CAAU,CAAV,CAAH,GAAkB,GAAG,CAAC,KAAJ,CAAU,CAAV,CAA7C;EACA,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAL,CAAS,SAAT,EAAoB,SAApB,CAAjB;EAEA,MAAM,SAAS,GAAG,OAAO,CAAC,IAAR,CAAa,GAAb,CAAiB,GAAG,CAAC,MAArB,EAA6B,MAA/C;EACA,MAAM,SAAS,GAAG,OAAO,CAAC,IAAR,CAAa,GAAb,CAAiB,GAAG,CAAC,MAArB,EAA6B,MAA/C;EAEA,MAAM,UAAU,GAAG,IAAI,CAAC,cAAL,CAAoB,GAAG,CAAC,KAAxB,CAAnB;EACA,MAAM,UAAU,GAAG,IAAI,CAAC,cAAL,CAAoB,GAAG,CAAC,KAAxB,CAAnB;EAEA,MAAM,CAAC,MAAD,EAAS,UAAT,EAAqB,UAArB,IAAmC,UAAU,GAC/C,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,CAAhB,EAAmB,UAAU,CAAC,CAAD,CAA7B,CAD+C,GAE/C,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,UAAU,CAAC,CAAD,CAA1B,EAA+B,CAA/B,CAFJ;EAGA,MAAM,CAAC,UAAD,EAAa,UAAb,EAAyB,MAAzB,IAAmC,UAAU,GAC/C,CAAC,CAAD,EAAI,UAAU,CAAC,CAAD,CAAd,EAAmB,UAAU,CAAC,CAAD,CAA7B,CAD+C,GAE/C,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,CAAhB,EAAmB,UAAU,CAAC,CAAD,CAA7B,CAFJ;EAIA,MAAM,IAAI,GAAG,OAAO,GAAG,QAAvB;EACA,MAAM,MAAM,GAAG,MAAM,CAAC,CAAC,QAAD,EAAW,OAAX,EAAoB,QAApB,CAAD,EAAgC,GAAG,CAAC,KAApC,CAArB;EAEA,MAAM,OAAO,GAAG,MAAM,CAAC,MAAvB;EACA,MAAM,SAAS,GAAG,OAAO,CAAC,SAA1B;;EAEA,KAAK,IAAI,EAAE,GAAG,CAAd,EAAiB,EAAE,GAAG,QAAtB,EAAgC,EAAE,EAAlC,EAAsC;IACpC,KAAK,IAAI,EAAE,GAAG,CAAd,EAAiB,EAAE,GAAG,OAAtB,EAA+B,EAAE,IAAI,SAArC,EAAgD;MAC9C,KAAK,IAAI,EAAE,GAAG,CAAd,EAAiB,EAAE,GAAG,QAAtB,EAAgC,EAAE,IAAI,SAAtC,EAAiD;QAC/C,KAAK,IAAI,EAAE,GAAG,CAAd,EAAiB,EAAE,GAAG,SAAtB,EAAiC,EAAE,IAAI,SAAvC,EAAkD;UAChD;UACA,MAAM,MAAM,GAAG,IAAI,CAAC,GAAL,CAAS,EAAE,GAAG,SAAd,EAAyB,OAAzB,CAAf;UACA,MAAM,MAAM,GAAG,IAAI,CAAC,GAAL,CAAS,EAAE,GAAG,SAAd,EAAyB,QAAzB,CAAf;UACA,MAAM,MAAM,GAAG,IAAI,CAAC,GAAL,CAAS,EAAE,GAAG,SAAd,EAAyB,SAAzB,CAAf;;UAEA,KAAK,IAAI,CAAC,GAAG,EAAb,EAAiB,CAAC,GAAG,MAArB,EAA6B,CAAC,EAA9B,EAAkC;YAChC,KAAK,IAAI,CAAC,GAAG,EAAb,EAAiB,CAAC,GAAG,MAArB,EAA6B,CAAC,EAA9B,EAAkC;cAChC,IAAI,GAAG,GAAG,GAAV;;cAEA,KAAK,IAAI,CAAC,GAAG,EAAb,EAAiB,CAAC,GAAG,MAArB,EAA6B,CAAC,EAA9B,EAAkC;gBAChC,MAAM,YAAY,GAAG,IAAI,CAAC,GAAL,CAAS,EAAT,EAAa,SAAS,GAAG,CAAzB,IAA8B,MAAnD;gBACA,MAAM,YAAY,GAAG,IAAI,CAAC,GAAL,CAAS,EAAT,EAAa,SAAS,GAAG,CAAzB,IAA8B,MAAnD;gBACA,MAAM,IAAI,GACN,SAAS,CAAC,YAAY,GAAG,CAAC,GAAG,UAAnB,GAAgC,CAAC,GAAG,UAArC,CADb;gBAEA,MAAM,IAAI,GACN,SAAS,CAAC,CAAC,GAAG,UAAJ,GAAiB,CAAC,GAAG,UAArB,GAAkC,YAAnC,CADb;gBAEA,GAAG,IAAI,IAAI,GAAG,IAAd;cACD;;cACD,OAAO,CAAC,EAAE,GAAG,IAAL,IAAa,CAAC,GAAG,QAAJ,GAAe,CAA5B,CAAD,CAAP,IAA2C,GAA3C;YACD;UACF;QACF;MACF;IACF;EACF;;EAED,OAAO,CAAC,6BAAR,CAAsC,GAAtC;EACA,OAAO,CAAC,6BAAR,CAAsC,GAAtC,EAjGD,CAmGC;;EACA,OAAO,OAAO,CAAC,cAAR,CACH,QADG,EACO,MAAM,CAAC,KADd,EACqB,MAAM,CAAC,MAD5B,CAAP;AAED;AAED,OAAO,MAAM,iBAAiB,GAAiB;EAC7C,UAAU,EAAE,WADiC;EAE7C,WAAW,EAAE,KAFgC;EAG7C,UAAU,EAAE;AAHiC,CAAxC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, broadcast_util, buffer, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {reshape} from './Reshape';\n\nexport function batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  attrs: BatchMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  assertNotComplex([a, b], 'matMul');\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n                                [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n                                [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n\n  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const a3dValues = backend.data.get(a3d.dataId).values as TypedArray;\n  const b3dValues = backend.data.get(b3d.dataId).values as TypedArray;\n\n  const a3dStrides = util.computeStrides(a3d.shape);\n  const b3dStrides = util.computeStrides(b3d.shape);\n\n  const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n      [a3dStrides[0], 1, a3dStrides[1]] :\n      [a3dStrides[0], a3dStrides[1], 1];\n  const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n      [1, b3dStrides[1], b3dStrides[0]] :\n      [b3dStrides[1], 1, b3dStrides[0]];\n\n  const size = leftDim * rightDim;\n  const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);\n\n  const resVals = result.values as TypedArray;\n  const blockSize = backend.blockSize;\n\n  for (let bi = 0; bi < batchDim; bi++) {\n    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n        for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n          // for when blockSize doesn't evenly divide the input\n          const iBlock = Math.min(i0 + blockSize, leftDim);\n          const jBlock = Math.min(j0 + blockSize, rightDim);\n          const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n          for (let i = i0; i < iBlock; i++) {\n            for (let j = j0; j < jBlock; j++) {\n              let sum = 0.0;\n\n              for (let k = k0; k < kBlock; k++) {\n                const batchOffsetA = Math.min(bi, batchDimA - 1) * aBatch;\n                const batchOffsetB = Math.min(bi, batchDimB - 1) * bBatch;\n                const aVal =\n                    a3dValues[batchOffsetA + i * aOuterStep + k * aInnerStep];\n                const bVal =\n                    b3dValues[k * bInnerStep + j * bOuterStep + batchOffsetB];\n                sum += aVal * bVal;\n              }\n              resVals[bi * size + (i * rightDim + j)] += sum;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  backend.disposeIntermediateTensorInfo(a3d);\n  backend.disposeIntermediateTensorInfo(b3d);\n\n  // set correct shape on output.\n  return backend.makeTensorInfo(\n      outShape, result.dtype, result.values as TypedArray);\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'cpu',\n  kernelFunc: batchMatMul as {} as KernelFunc,\n};\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}